{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Bienvenue dans la Formation Kubernetes et OpenShift","text":"<p>Bienvenue dans notre formation compl\u00e8te sur Kubernetes et OpenShift ! Ce cours est con\u00e7u pour vous fournir une compr\u00e9hension approfondie de ces deux plateformes essentielles pour la gestion des conteneurs et le d\u00e9ploiement d'applications modernes. Que vous soyez un d\u00e9butant curieux ou un professionnel cherchant \u00e0 approfondir ses comp\u00e9tences, ce cours est structur\u00e9 pour r\u00e9pondre \u00e0 vos besoins.</p>"},{"location":"#structure-du-cours","title":"Structure du Cours","text":"<p>Notre programme est soigneusement structur\u00e9 pour \u00e9quilibrer th\u00e9orie et pratique, afin de garantir une compr\u00e9hension solide et une application efficace des concepts. La r\u00e9partition est la suivante : 40% th\u00e9orie et 60% pratique. Cette approche vous permet de non seulement comprendre les concepts cl\u00e9s, mais aussi de les mettre en \u0153uvre dans des sc\u00e9narios r\u00e9els.</p>"},{"location":"#contenu-du-cours","title":"Contenu du Cours","text":"<ol> <li> <p>Introduction Pr\u00e9sentation g\u00e9n\u00e9rale de la formation et des objectifs.</p> </li> <li> <p>Pr\u00e9sentation de Kubernetes et OpenShift Comprendre les bases de Kubernetes et OpenShift, leurs architectures, et leurs fonctionnalit\u00e9s cl\u00e9s.</p> </li> <li> <p>Interface et ligne de commande Explorer les interfaces utilisateur et les commandes de base pour interagir avec Kubernetes et OpenShift.</p> </li> <li> <p>Ex\u00e9cuter des applications conteneuris\u00e9es Apprendre \u00e0 d\u00e9ployer, g\u00e9rer et surveiller des applications conteneuris\u00e9es sur ces plateformes.</p> </li> <li> <p>D\u00e9ployer des applications en r\u00e9seau Configurer et g\u00e9rer les r\u00e9seaux pour vos applications, incluant les services et les ingress.</p> </li> <li> <p>Gestion du stockage Comprendre les options de stockage disponibles et comment les configurer et les g\u00e9rer.</p> </li> <li> <p>Configuration de la fiabilit\u00e9 des applications Mettre en \u0153uvre des pratiques pour garantir la haute disponibilit\u00e9 et la r\u00e9silience de vos applications.</p> </li> <li> <p>Gestion des mises \u00e0 jour des applications Apprendre \u00e0 mettre \u00e0 jour vos applications de mani\u00e8re continue et sans interruption.</p> </li> </ol>"},{"location":"#methodologie","title":"M\u00e9thodologie","text":"<p>Notre approche p\u00e9dagogique int\u00e8gre des sessions th\u00e9oriques suivies de laboratoires pratiques. Chaque module th\u00e9orique est imm\u00e9diatement suivi d\u2019exercices pratiques pour renforcer l'apprentissage et assurer que vous pouvez appliquer les concepts dans des situations r\u00e9elles. Les sessions pratiques incluront des exercices guid\u00e9s, des projets de groupe et des \u00e9tudes de cas bas\u00e9es sur des sc\u00e9narios du monde r\u00e9el.</p>"},{"location":"#objectifs-dapprentissage","title":"Objectifs d'Apprentissage","text":"<p>\u00c0 la fin de ce cours, vous serez capable de :</p> <ul> <li>Comprendre les fondamentaux de Kubernetes et OpenShift.</li> <li>Utiliser les outils en ligne de commande pour g\u00e9rer vos clusters et applications.</li> <li>D\u00e9ployer et g\u00e9rer efficacement des applications conteneuris\u00e9es.</li> <li>Configurer des r\u00e9seaux et g\u00e9rer le stockage pour vos applications.</li> <li>Assurer la fiabilit\u00e9 et la r\u00e9silience de vos d\u00e9ploiements.</li> <li>Mettre en \u0153uvre des strat\u00e9gies de mise \u00e0 jour continue.</li> </ul> <p>Nous sommes impatients de vous accompagner dans ce voyage d'apprentissage et de vous voir progresser vers la ma\u00eetrise de Kubernetes et OpenShift. Pr\u00e9parez-vous \u00e0 plonger dans l'univers passionnant de la gestion des conteneurs et \u00e0 acqu\u00e9rir des comp\u00e9tences qui sont de plus en plus cruciales dans le paysage technologique actuel.</p> <p>Bonne formation !</p>"},{"location":"00_Introduction/00_Objectif_du_cours/","title":"Objectif du cours","text":"<p>Bienvenue dans ce cours sur OpenShift et Kubernetes. L'objectif de ce cours est de vous fournir une compr\u00e9hension compl\u00e8te et pratique de l'utilisation de Kubernetes et OpenShift pour d\u00e9ployer, g\u00e9rer et mettre \u00e0 l'\u00e9chelle des applications conteneuris\u00e9es.</p>"},{"location":"00_Introduction/00_Objectif_du_cours/#a-qui-sadresse-ce-cours","title":"\u00c0 qui s'adresse ce cours ?","text":"<p>Ce cours s'adresse \u00e0 : * Les administrateurs syst\u00e8me : qui cherchent \u00e0 automatiser la gestion des d\u00e9ploiements et des infrastructures. * Les d\u00e9veloppeurs : qui souhaitent comprendre comment leurs applications s'ex\u00e9cutent dans un environnement conteneuris\u00e9 et comment ils peuvent tirer parti de Kubernetes et OpenShift pour am\u00e9liorer leur workflow de d\u00e9veloppement. * Les ing\u00e9nieurs DevOps : qui veulent int\u00e9grer Kubernetes et OpenShift dans leur cha\u00eene d'outils CI/CD.</p>"},{"location":"00_Introduction/00_Objectif_du_cours/#objectifs-dapprentissage","title":"Objectifs d'apprentissage","text":"<p>\u00c0 la fin de ce cours, vous serez capable de :</p> <ol> <li> <p>Comprendre les concepts fondamentaux de Kubernetes et OpenShift.</p> </li> <li> <p>Naviguer et utiliser l'interface de la console OpenShift.</p> </li> <li> <p>Interagir avec OpenShift en utilisant la ligne de commande.</p> </li> <li> <p>D\u00e9ployer, g\u00e9rer et mettre \u00e0 l'\u00e9chelle des applications conteneuris\u00e9es.</p> </li> <li> <p>Configurer et g\u00e9rer le stockage pour les applications.</p> </li> <li> <p>Assurer la fiabilit\u00e9 et la disponibilit\u00e9 des applications d\u00e9ploy\u00e9es.</p> </li> <li> <p>Mettre \u00e0 jour et maintenir des applications sur OpenShift.</p> </li> </ol> <p></p>"},{"location":"00_Introduction/00_Objectif_du_cours/#structure-du-cours","title":"Structure du cours","text":"<p>Le cours est structur\u00e9 en modules qui alternent th\u00e9orie et pratique :</p> <ul> <li> <p>Th\u00e9orie : Des explications d\u00e9taill\u00e9es sur les concepts cl\u00e9s.</p> </li> <li> <p>Pratique : Des exercices guid\u00e9s pour appliquer les concepts appris.</p> </li> <li> <p>Quizz : Des \u00e9valuations pour tester vos connaissances et votre compr\u00e9hension des sujets abord\u00e9s.</p> </li> </ul>"},{"location":"00_Introduction/00_Objectif_du_cours/#pre-requis","title":"Pr\u00e9-requis","text":"<p>Avant de commencer ce cours, il est recommand\u00e9 d'avoir :</p> <ul> <li> <p>Une connaissance de base des concepts de virtualisation et de conteneurisation.</p> </li> <li> <p>Une exp\u00e9rience avec la ligne de commande Unix/Linux.</p> </li> <li> <p>Une compr\u00e9hension des principes de base des r\u00e9seaux et du stockage.</p> </li> </ul>"},{"location":"00_Introduction/00_Objectif_du_cours/#environnement-de-travail","title":"Environnement de travail","text":"<p>Pour suivre les exercices pratiques, vous aurez besoin :</p> <ul> <li> <p>D'un acc\u00e8s \u00e0 un cluster OpenShift.</p> </li> <li> <p>D'un terminal avec <code>oc</code>, le client en ligne de commande OpenShift.</p> </li> <li> <p>D'un \u00e9diteur de texte pour \u00e9crire et modifier des fichiers de configuration.</p> </li> </ul> <p>Nous esp\u00e9rons que ce cours vous sera utile et vous permettra de ma\u00eetriser l'utilisation de Kubernetes et OpenShift pour g\u00e9rer vos applications conteneuris\u00e9es. Bonne formation !</p>"},{"location":"00_Introduction/01_Organisation_de_la_formation/","title":"Organisation de la Formation","text":"<p>Pour faciliter l'apprentissage et les exercices pratiques, un cluster OpenShift a d\u00e9j\u00e0 \u00e9t\u00e9 d\u00e9ploy\u00e9 au pr\u00e9alable. Cette pr\u00e9paration permet de maximiser le temps d\u00e9di\u00e9 \u00e0 l'acquisition de comp\u00e9tences et \u00e0 la mise en pratique des concepts th\u00e9oriques.</p> <p>Chaque utilisateur dispose sur sa table d'un nom de ville. Cette ville correspond au namespace auquel il aura acc\u00e8s, avec un namespace attribu\u00e9.</p> <p>La liste des villes est la suivante:</p> <pre><code>Tokyo, Paris, Londres, Rome, Sydney, Rio, Istanbul, Berlin, Nairobi, Madrid, Toronto, Singapour, Stockholm, Ath\u00e8nes, Varsovie, Oslo, Helsinki, Lisbonne, Vienne, Brasilia, Canberra, Ottawa, S\u00e9oul, Le Cap, Budapest, Dublin, Zurich, Cardiff, Nicosie, Sofia, Suva, Riga, Vilnius, Alger, Abou Dabi, Bagdad, Bangkok, Le Caire, Freetown, Kaboul, Kinshasa, Libreville, Mexico, Reykjavik, Prague.\n</code></pre> <p>Chaque utilisateur aura des droits d'administrateur sur son propre namespace, ce qui lui permettra de g\u00e9rer les ressources et les configurations au sein de cet espace. En plus de cela, les utilisateurs auront la possibilit\u00e9 de cr\u00e9er de nouveaux namespaces sur le cluster selon leurs besoins sp\u00e9cifiques. Des limites de resources ont \u00e9galement \u00e9t\u00e9 appliqu\u00e9s sur l'ensemble des namespaces.</p> <p>Si des droits suppl\u00e9mentaires sont requis pour des actions sp\u00e9cifiques ou des configurations plus avanc\u00e9es, ces actions seront effectu\u00e9es par le formateur, assurant ainsi la s\u00e9curit\u00e9 et la bonne gestion des ressources du cluster.</p>"},{"location":"00_Introduction/01_Organisation_de_la_formation/#acces-au-cluster-openshift","title":"Acc\u00e8s au cluster OpenShift","text":"<p>Pour acc\u00e9der au cluster, les participants utiliseront l'URL suivante :</p> <p>https://console-openshift-console.apps.neutron-sno-office.intraneutron.fr/dashboards.</p> <p>Le nom d'utilisateur sera bas\u00e9 sur le nom de la ville du participant. Par exemple, pour un participant ayant la ville Paris, le nom d'utilisateur sera <code>paris-user</code>. Un mot de passe sp\u00e9cifique sera fourni par le formateur pour garantir la s\u00e9curit\u00e9 de chaque compte.</p> <p></p> <p>L'API du cluster est accessible \u00e0 l'adresse suivante :</p> <p>https://api.neutron-sno-office.intraneutron.fr:6443.</p> <p>Cette API permettra aux utilisateurs de r\u00e9aliser diverses op\u00e9rations sur le cluster.</p>"},{"location":"00_Introduction/01_Organisation_de_la_formation/#deroulement-du-cours","title":"D\u00e9roulement du cours","text":"<p>Le cours est structur\u00e9 pour alterner entre des chapitres th\u00e9oriques et des sessions pratiques. Les chapitres th\u00e9oriques seront pr\u00e9sent\u00e9s par le formateur \u00e0 l'aide de slides, fournissant ainsi une base solide de connaissances sur OpenShift et ses diff\u00e9rentes fonctionnalit\u00e9s. Ces sessions th\u00e9oriques seront essentielles pour comprendre les concepts cl\u00e9s et les bonnes pratiques \u00e0 adopter.</p> <p>Apr\u00e8s chaque chapitre th\u00e9orique, une partie pratique sera organis\u00e9e. Ces sessions pratiques pourront inclure des quiz \u00e0 r\u00e9aliser, permettant ainsi aux participants de tester et de renforcer leurs connaissances de mani\u00e8re collaborative ou des manipulations pratiques qui seront effectu\u00e9es directement dans les namespaces attribu\u00e9s.</p> <p>Pour les manipulations pratiques, deux options sont possibles. Les participants pourront utiliser leur propre terminal pour interagir avec le cluster. Alternativement, ils pourront utiliser le terminal Operator, un outil int\u00e9gr\u00e9 \u00e0 OpenShift qui facilite la gestion et l'interaction avec les ressources du cluster.</p> <p>Ces sessions pratiques sont con\u00e7ues pour offrir une exp\u00e9rience d'apprentissage immersive et interactive, permettant aux participants de mettre en application les concepts th\u00e9oriques dans des sc\u00e9narios r\u00e9els. Le formateur sera pr\u00e9sent pour guider les participants, r\u00e9pondre \u00e0 leurs questions et fournir des clarifications au besoin.</p> <p>Enfin n'h\u00e9sitez pas des questions !</p> <p></p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/00_Presentation_d_Openshift/","title":"Pr\u00e9sentation d'OpenShift","text":""},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/00_Presentation_d_Openshift/#objectif","title":"Objectif","text":"<p>L'objectif de cette premi\u00e8re partie est de fournir une compr\u00e9hension solide des concepts fondamentaux qui sous-tendent l'utilisation des conteneurs, l'orchestration de ces conteneurs avec Kubernetes, et la fa\u00e7on dont OpenShift s'appuie sur Kubernetes pour offrir une plateforme de conteneurs compl\u00e8te et pr\u00eate pour les entreprises. Cette partie est divis\u00e9e en trois sections : une introduction aux conteneurs, une explication de Kubernetes et de l'orchestration de conteneurs, et une pr\u00e9sentation d'OpenShift avec ses sp\u00e9cificit\u00e9s par rapport \u00e0 Kubernetes.</p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/00_Presentation_d_Openshift/#comprendre-les-conteneurs","title":"Comprendre les Conteneurs","text":""},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/00_Presentation_d_Openshift/#quest-ce-quun-conteneur","title":"Qu'est-ce qu'un conteneur?","text":"<p>Les conteneurs repr\u00e9sentent une r\u00e9volution dans le d\u00e9veloppement logiciel et la gestion d'infrastructure. Un conteneur est une unit\u00e9 de d\u00e9ploiement autonome qui encapsule une application avec toutes ses d\u00e9pendances n\u00e9cessaires \u00e0 son ex\u00e9cution. Cela permet \u00e0 l'application de fonctionner de mani\u00e8re coh\u00e9rente et fiable quel que soit l'environnement dans lequel elle est d\u00e9ploy\u00e9e.</p> <p>Un conteneur inclut tout ce dont l'application a besoin : le code, les biblioth\u00e8ques, les variables d'environnement et les fichiers de configuration. Cette isolation assure que les applications ne partagent pas leurs d\u00e9pendances avec le syst\u00e8me d'exploitation h\u00f4te ou d'autres applications, r\u00e9duisant ainsi les conflits et augmentant la portabilit\u00e9.</p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/00_Presentation_d_Openshift/#avantages-des-conteneurs","title":"Avantages des conteneurs","text":"<ol> <li> <p>Portabilit\u00e9 accrue: Les conteneurs fonctionnent de la m\u00eame mani\u00e8re sur n'importe quel environnement, qu'il s'agisse d'un ordinateur portable, d'un serveur ou d'un cloud, facilitant ainsi le d\u00e9placement des applications entre les diff\u00e9rents environnements de d\u00e9veloppement, de test et de production.</p> </li> <li> <p>Isolation: Chaque conteneur fonctionne de mani\u00e8re isol\u00e9e, ce qui signifie qu'une application contenue ne sera pas affect\u00e9e par les modifications ou les erreurs des autres applications ou du syst\u00e8me d'exploitation.</p> </li> <li> <p>Efficacit\u00e9 des ressources: Compar\u00e9s aux machines virtuelles, les conteneurs utilisent les ressources de mani\u00e8re plus efficace car ils partagent le m\u00eame noyau du syst\u00e8me d'exploitation h\u00f4te, ce qui permet d'ex\u00e9cuter plusieurs conteneurs sur une seule machine physique ou virtuelle sans le surco\u00fbt des hyperviseurs.</p> </li> <li> <p>D\u00e9marrage rapide: Les conteneurs d\u00e9marrent presque instantan\u00e9ment, ce qui acc\u00e9l\u00e8re consid\u00e9rablement les cycles de d\u00e9veloppement, de test et de d\u00e9ploiement des applications.</p> </li> <li> <p>Gestion simplifi\u00e9e des d\u00e9pendances: Toutes les d\u00e9pendances d'une application sont empaquet\u00e9es dans le conteneur, ce qui \u00e9limine les probl\u00e8mes de version et de compatibilit\u00e9 qui peuvent survenir lorsqu'une application d\u00e9pend des biblioth\u00e8ques du syst\u00e8me h\u00f4te.</p> </li> </ol> <p></p> <p>Alors que les conteneurs offrent de nombreux avantages pour le d\u00e9veloppement et le d\u00e9ploiement d'applications, leur gestion \u00e0 grande \u00e9chelle n\u00e9cessite des outils et des processus robustes. C'est l\u00e0 que Kubernetes entre en jeu.</p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/00_Presentation_d_Openshift/#introduction-a-kubernetes","title":"Introduction \u00e0 Kubernetes","text":""},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/00_Presentation_d_Openshift/#quest-ce-que-kubernetes","title":"Qu'est-ce que Kubernetes?","text":"<p>Kubernetes est une plateforme d'orchestration de conteneurs open source qui simplifie la gestion des applications conteneuris\u00e9es \u00e0 grande \u00e9chelle. D\u00e9velopp\u00e9 \u00e0 l'origine par Google, Kubernetes est maintenant maintenu par la Cloud Native Computing Foundation (CNCF). Il fournit des m\u00e9canismes pour le d\u00e9ploiement, la mise \u00e0 l'\u00e9chelle et la gestion automatis\u00e9s des conteneurs.</p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/00_Presentation_d_Openshift/#pourquoi-un-orchestrateur-de-conteneurs-est-il-necessaire","title":"Pourquoi un orchestrateur de conteneurs est-il n\u00e9cessaire?","text":"<ol> <li> <p>Automatisation des d\u00e9ploiements: Kubernetes automatise le d\u00e9ploiement et la gestion des conteneurs, permettant aux \u00e9quipes de d\u00e9veloppement de se concentrer sur l'\u00e9criture du code plut\u00f4t que sur l'infrastructure.</p> </li> <li> <p>\u00c9quilibrage de charge et mise \u00e0 l'\u00e9chelle automatique: Kubernetes distribue automatiquement le trafic r\u00e9seau aux conteneurs afin de garantir la stabilit\u00e9 et les performances des applications. Il ajuste \u00e9galement le nombre de conteneurs en fonction de la demande, ce qui permet une utilisation optimale des ressources.</p> </li> <li> <p>Gestion des pannes: En cas de d\u00e9faillance, Kubernetes red\u00e9marre automatiquement les conteneurs d\u00e9faillants, remplace les n\u0153uds, et r\u00e9alloue les ressources n\u00e9cessaires pour maintenir les applications en fonctionnement.</p> </li> <li> <p>Gestion de la configuration et des secrets: Kubernetes facilite la gestion s\u00e9curis\u00e9e des configurations et des secrets (tels que les mots de passe et les cl\u00e9s API), en les rendant disponibles uniquement aux conteneurs qui en ont besoin.</p> </li> <li> <p>Orchestration des services: Kubernetes organise les conteneurs en unit\u00e9s appel\u00e9es pods, qui peuvent communiquer entre eux et avec d'autres services de mani\u00e8re s\u00e9curis\u00e9e et efficace.</p> </li> </ol> <p>Ainsi, Kubernetes fournit les outils n\u00e9cessaires pour g\u00e9rer des conteneurs \u00e0 grande \u00e9chelle, ce qui est crucial pour les environnements de production modernes. Pour aller encore plus loin, OpenShift offre une solution bas\u00e9e sur Kubernetes avec des fonctionnalit\u00e9s suppl\u00e9mentaires pour les entreprises.</p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/00_Presentation_d_Openshift/#section-3-decouverte-dopenshift","title":"Section 3 : D\u00e9couverte d'OpenShift","text":""},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/00_Presentation_d_Openshift/#quest-ce-quopenshift","title":"Qu'est-ce qu'OpenShift?","text":"<p>OpenShift est une plateforme de conteneurs d'entreprise d\u00e9velopp\u00e9e par Red Hat, qui repose sur Kubernetes. OpenShift ajoute une couche suppl\u00e9mentaire de fonctionnalit\u00e9s et d'outils pour faciliter la gestion, le d\u00e9veloppement et la s\u00e9curisation des applications conteneuris\u00e9es. Il est con\u00e7u pour les environnements de production d'entreprise, offrant des capacit\u00e9s suppl\u00e9mentaires telles qu'une console web intuitive, des outils de d\u00e9veloppement int\u00e9gr\u00e9s, et des services de gestion de la s\u00e9curit\u00e9.</p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/00_Presentation_d_Openshift/#differences-entre-kubernetes-et-openshift","title":"Diff\u00e9rences entre Kubernetes et OpenShift","text":"<ol> <li> <p>Interface utilisateur et exp\u00e9rience utilisateur: OpenShift fournit une console web riche et une interface utilisateur graphique qui simplifient la gestion des conteneurs et des applications. Kubernetes, bien que puissant, n\u00e9cessite souvent une gestion via des fichiers de configuration et des commandes en ligne de commande, ce qui peut \u00eatre moins intuitif pour les nouveaux utilisateurs.</p> </li> <li> <p>S\u00e9curit\u00e9: OpenShift int\u00e8gre des fonctionnalit\u00e9s de s\u00e9curit\u00e9 avanc\u00e9es par d\u00e9faut, comme SELinux (Security-Enhanced Linux) et une gestion des identit\u00e9s et des acc\u00e8s robustes. Cela garantit que les d\u00e9ploiements sont s\u00e9curis\u00e9s d\u00e8s le d\u00e9part, sans configurations suppl\u00e9mentaires complexes.</p> </li> <li> <p>Outils de d\u00e9veloppement et int\u00e9gration CI/CD: OpenShift inclut des outils pour les d\u00e9veloppeurs tels que des pipelines CI/CD int\u00e9gr\u00e9s, des services de gestion des builds et un registre d'images int\u00e9gr\u00e9. Ces outils simplifient le d\u00e9veloppement et le d\u00e9ploiement continu des applications.</p> </li> <li> <p>Support commercial et stabilit\u00e9: En tant que produit Red Hat, OpenShift b\u00e9n\u00e9ficie d'un support commercial et est con\u00e7u pour offrir une stabilit\u00e9 et une s\u00e9curit\u00e9 accrues pour les environnements de production.</p> </li> <li> <p>Op\u00e9rateurs Kubernetes: OpenShift utilise les op\u00e9rateurs Kubernetes pour automatiser la gestion des applications, facilitant ainsi l'extension des fonctionnalit\u00e9s de la plateforme. Les op\u00e9rateurs sont des extensions de Kubernetes qui simplifient la gestion des applications complexes.</p> </li> <li> <p>Options de d\u00e9ploiement flexibles: OpenShift propose diverses options de d\u00e9ploiement adapt\u00e9es aux besoins des entreprises, qu'il s'agisse de d\u00e9ploiements sur site, dans des environnements de cloud public ou hybride, ou encore de configurations autog\u00e9r\u00e9es ou enti\u00e8rement g\u00e9r\u00e9es par Red Hat.</p> </li> </ol> <p></p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/00_Presentation_d_Openshift/#conclusion","title":"Conclusion","text":"<p>En conclusion, OpenShift s'appuie sur Kubernetes pour offrir une solution de conteneurisation plus compl\u00e8te et adapt\u00e9e aux besoins des entreprises. Il combine la puissance de Kubernetes avec des outils et des fonctionnalit\u00e9s suppl\u00e9mentaires pour simplifier la gestion, renforcer la s\u00e9curit\u00e9 et am\u00e9liorer l'exp\u00e9rience utilisateur, faisant de lui un choix privil\u00e9gi\u00e9 pour les d\u00e9ploiements en production.</p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/01_Quiz_Presentation_d_Openshift/","title":"Quiz sur la Pr\u00e9sentation d'OpenShift","text":"<p>Nous allons maintenant faire un quiz pour \u00e9valuer votre compr\u00e9hension de la partie \"Pr\u00e9sentation d'OpenShift\". Ce quiz couvrira les concepts fondamentaux abord\u00e9s, tels que les conteneurs, Kubernetes et les sp\u00e9cificit\u00e9s d'OpenShift.</p> <p>Pour joindre le quiz, veuillez suivre les \u00e9tapes suivantes :</p> <ol> <li> <p>Ouvrez l'application Quizizz sur votre appareil ou rendez-vous sur : https://quizizz.com/join.</p> </li> <li> <p>Entrez le num\u00e9ro fourni par l'instructeur pour acc\u00e9der au quiz.</p> </li> </ol> <p></p> <p>Bonne chance \u00e0 tous !</p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/02_Exploration_de_la_console/","title":"Exploration de la console OpenShift","text":""},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/02_Exploration_de_la_console/#objectif","title":"Objectif","text":"<p>Dans cette section, nous allons explorer la console web d'OpenShift. La console web offre une interface graphique intuitive pour g\u00e9rer les ressources de votre cluster, d\u00e9ployer des applications, surveiller les performances et configurer les param\u00e8tres.</p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/02_Exploration_de_la_console/#introduction-a-la-console-web-red-hat-openshift","title":"Introduction \u00e0 la Console Web Red Hat OpenShift","text":"<p>La console Web Red Hat OpenShift propose une interface graphique qui simplifie de nombreuses t\u00e2ches administratives pour la gestion d'un cluster. En exploitant les API Kubernetes ainsi que les API d'extension OpenShift, cette console offre un environnement graphique performant. Bien que les menus, les t\u00e2ches et les fonctionnalit\u00e9s de la console Web soient \u00e9galement accessibles via l'interface en ligne de commande, cette console rend plus ais\u00e9es les t\u00e2ches complexes inh\u00e9rentes \u00e0 l'administration du cluster.</p> <p>Kubernetes dispose d'un tableau de bord Web qui n'est pas activ\u00e9 par d\u00e9faut dans un cluster. Ce tableau de bord offre des permissions de s\u00e9curit\u00e9 minimales et ne prend en charge que l'authentification par tokens. De plus, il n\u00e9cessite une configuration de proxy, limitant l'acc\u00e8s \u00e0 la console Web au terminal syst\u00e8me ayant cr\u00e9\u00e9 le proxy. Contrairement \u00e0 ces contraintes, la console Web d'OpenShift offre une exp\u00e9rience beaucoup plus compl\u00e8te.</p> <p>La console Web d'OpenShift est ind\u00e9pendante du tableau de bord Kubernetes et constitue un outil distinct d\u00e9di\u00e9 \u00e0 la gestion des clusters OpenShift. En outre, les op\u00e9rateurs ont la possibilit\u00e9 d'\u00e9tendre les fonctionnalit\u00e9s de cette console en ajoutant des menus, des vues et des formulaires suppl\u00e9mentaires pour simplifier encore davantage l'administration du cluster.</p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/02_Exploration_de_la_console/#connexion-a-la-console","title":"Connexion a la console","text":"<p>Pour acc\u00e9der \u00e0 la console OpenShift, commencez par ouvrir votre navigateur web et rendez-vous \u00e0 l'adresse suivante : https://console-openshift-console.apps.neutron-sno-office.intraneutron.fr/. Une fois cette URL entr\u00e9e, vous serez automatiquement redirig\u00e9 vers la page de connexion d'OpenShift \u00e0 l'adresse https://oauth-openshift.apps.neutron-sno-office.intraneutron.fr.</p> <p></p> <p>Cette redirection est normale et vous am\u00e8ne vers l'interface d'authentification s\u00e9curis\u00e9e o\u00f9 vous pourrez vous connecter \u00e0 la console OpenShift.</p> <p>Sur la page de connexion, vous verrez plusieurs options de fournisseurs d'identit\u00e9 (Identity Providers). Dans le cadre de cette formation, vous devez utiliser \"Neutron Guest Identity Management\" pour vous connecter. S\u00e9lectionnez cette option, puis entrez le nom d'utilisateur et le mot de passe qui vous ont \u00e9t\u00e9 fournis par votre formateur. Ces identifiants vous permettront d'acc\u00e9der \u00e0 la console et de commencer \u00e0 utiliser OpenShift. Assurez-vous de garder ces informations \u00e0 port\u00e9e de main pour toute la dur\u00e9e de votre formation, car elles seront n\u00e9cessaires pour toutes les sessions d'acc\u00e8s \u00e0 la console.</p> <p></p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/02_Exploration_de_la_console/#differentes-perspectives-de-la-console-web","title":"Diff\u00e9rentes Perspectives de la Console Web","text":"<p>La console Web OpenShift propose deux modes principaux : Administrator et Developer. La disposition des menus et les fonctionnalit\u00e9s disponibles varient en fonction du mode s\u00e9lectionn\u00e9. En haut du menu lat\u00e9ral, un s\u00e9lecteur de perspective permet de naviguer facilement entre les modes Administrator et Developer.</p> <p></p> <p>Chaque mode offre des pages et des cat\u00e9gories de menus sp\u00e9cifiquement con\u00e7ues pour r\u00e9pondre aux besoins de l'utilisateur. Le mode Administrator est orient\u00e9 vers la configuration, la gestion du cluster, les d\u00e9ploiements, et les op\u00e9rations courantes. En revanche, le mode Developer se concentre sur la conception et le d\u00e9ploiement d'applications.</p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/02_Exploration_de_la_console/#vue-administrateur","title":"Vue Administrateur","text":"<p>Dans la console OpenShift en mode administrateur, vous avez acc\u00e8s \u00e0 une gamme compl\u00e8te d'outils pour g\u00e9rer et superviser efficacement votre infrastructure. Voici un aper\u00e7u des principales fonctionnalit\u00e9s disponibles :</p> <ul> <li> <p>Accueil (Home) :</p> <ul> <li>Tableau de bord global avec des informations sur les alertes, l'utilisation des ressources et la sant\u00e9 du cluster.</li> </ul> </li> <li> <p>Operators :</p> <ul> <li>Gestion des op\u00e9rateurs install\u00e9s, ajout via l'OperatorHub et surveillance des mises \u00e0 jour.</li> </ul> </li> <li> <p>Workloads :</p> <ul> <li>Gestion des pods, d\u00e9ploiements, r\u00e9plicasets, daemonsets, jobs et cron jobs.</li> <li>Configuration des StatefulSets pour les applications d'\u00e9tat.</li> </ul> </li> <li> <p>Networking :</p> <ul> <li>Configuration des routes pour les applications.</li> <li>Gestion des services, des endpoints, des ingress et des politiques r\u00e9seau.</li> </ul> </li> <li> <p>Storage :</p> <ul> <li>Gestion des volumes persistants, des claims et des classes de stockage.</li> <li>Surveillance de l'utilisation du stockage.</li> </ul> </li> <li> <p>Builds :</p> <ul> <li>Surveillance et gestion des builds.</li> <li>Configuration des strat\u00e9gies de build et gestion des pipelines CI/CD.</li> </ul> </li> <li> <p>Observe :</p> <ul> <li>Acc\u00e8s aux journaux des pods.</li> <li>Surveillance des m\u00e9triques et des alertes.</li> <li>Configuration des sources de journaux.</li> </ul> </li> <li> <p>Compute :</p> <ul> <li>Gestion des n\u0153uds du cluster.</li> <li>Surveillance de l'utilisation des ressources des n\u0153uds.</li> <li>Configuration des machines et des pools de machines.</li> </ul> </li> <li> <p>User Management :</p> <ul> <li>Cr\u00e9ation et gestion des utilisateurs et des groupes.</li> <li>Attribution des r\u00f4les et des permissions.</li> <li>Configuration des fournisseurs d'identit\u00e9.</li> </ul> </li> <li> <p>Administration :</p> <ul> <li>Configuration des param\u00e8tres globaux du cluster.</li> <li>Gestion des mises \u00e0 jour du cluster.</li> <li>Configuration des politiques de s\u00e9curit\u00e9 et des quotas.</li> </ul> </li> </ul>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/02_Exploration_de_la_console/#vue-developpeur","title":"Vue D\u00e9veloppeur","text":"<p>La vue d\u00e9veloppeur de la console OpenShift est con\u00e7ue pour optimiser le d\u00e9veloppement et le d\u00e9ploiement d'applications. Voici ce que vous pouvez faire dans cette vue :</p> <ul> <li> <p>Topology (Topologie) :</p> <ul> <li>Visualisation graphique des applications et des services.</li> <li>Gestion des ressources et des relations entre les composants.</li> </ul> </li> <li> <p>Observe :</p> <ul> <li>Acc\u00e8s aux journaux des applications.</li> <li>Surveillance des m\u00e9triques sp\u00e9cifiques aux projets.</li> <li>Configuration des sources de journaux pour le d\u00e9bogage.</li> </ul> </li> <li> <p>Search (Recherche) :</p> <ul> <li>Recherche de ressources sp\u00e9cifiques dans les projets.</li> <li>Filtrage par type de ressource et par \u00e9tiquette.</li> <li>Acc\u00e8s rapide aux d\u00e9tails des ressources trouv\u00e9es.</li> </ul> </li> <li> <p>Builds :</p> <ul> <li>Gestion et surveillance des builds de projet.</li> <li>Configuration des strat\u00e9gies de build sp\u00e9cifiques au projet.</li> <li>Visualisation des pipelines CI/CD.</li> </ul> </li> <li> <p>Environments (Environnements) :</p> <ul> <li>Gestion des configurations d'environnement pour les applications.</li> <li>D\u00e9finition des variables d'environnement.</li> <li>Surveillance des configurations d'environnement.</li> </ul> </li> <li> <p>Helm :</p> <ul> <li>Acc\u00e8s \u00e0 Helm Charts pour d\u00e9ployer des applications.</li> <li>Gestion des releases Helm.</li> <li>Surveillance des applications d\u00e9ploy\u00e9es via Helm.</li> </ul> </li> <li> <p>Project (Projet) :</p> <ul> <li>Vue d'ensemble des ressources du projet.</li> <li>Gestion des quotas et des limites de ressources.</li> <li>Surveillance de l'utilisation des ressources au niveau du projet.</li> </ul> </li> <li> <p>Config Maps :</p> <ul> <li>Cr\u00e9ation et gestion des ConfigMaps.</li> <li>Utilisation des ConfigMaps pour stocker des configurations de donn\u00e9es.</li> <li>Int\u00e9gration des ConfigMaps dans les applications.</li> </ul> </li> <li> <p>Secrets :</p> <ul> <li>Cr\u00e9ation et gestion des secrets.</li> <li>Utilisation des secrets pour stocker des informations sensibles.</li> <li>Int\u00e9gration des secrets dans les applications.</li> </ul> </li> </ul>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/02_Exploration_de_la_console/#conclusion","title":"Conclusion","text":"<p>La console web d'OpenShift est un outil puissant et intuitif pour g\u00e9rer vos projets, d\u00e9ployer des applications et surveiller l'\u00e9tat de votre cluster. Familiarisez-vous avec ses fonctionnalit\u00e9s pour tirer le meilleur parti de votre environnement OpenShift. Dans la prochaine section, nous r\u00e9aliserons un exercice guid\u00e9 pour explorer la console en d\u00e9tail et effectuer des t\u00e2ches courantes. c</p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/03_Exercice_guid%C3%A9_Exploration_de_la_console/","title":"Exercice Guid\u00e9 : Exploration de la console OpenShift","text":"<p>Dans cet exercice, vous allez apprendre \u00e0 naviguer dans la console web d'OpenShift et \u00e0 effectuer des t\u00e2ches courantes. Suivez les \u00e9tapes ci-dessous pour vous familiariser avec l'interface utilisateur et ses fonctionnalit\u00e9s.</p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/03_Exercice_guid%C3%A9_Exploration_de_la_console/#objectifs-de-lexercice","title":"Objectifs de l'exercice","text":"<ul> <li>Acc\u00e9der \u00e0 la console web d'OpenShift</li> <li>Cr\u00e9er un projet</li> <li>D\u00e9ployer une application \u00e0 partir d'un template</li> <li>Surveiller les ressources du projet</li> <li>Configurer et visualiser des alertes</li> </ul>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/03_Exercice_guid%C3%A9_Exploration_de_la_console/#etape-1-acceder-a-la-console-web","title":"\u00c9tape 1 : Acc\u00e9der \u00e0 la console web","text":"<ol> <li>Ouvrez votre navigateur web.</li> <li>Entrez l'URL de la console web d'OpenShift ci-dessous :</li> </ol> <pre><code>https://console-openshift-console.apps.neutron-sno-office.intraneutron.fr/\n</code></pre> <ol> <li>Cliquez sur <code>Neutron Guest Identity Management</code></li> <li>Connectez-vous avec vos identifiants OpenShift.</li> </ol>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/03_Exercice_guid%C3%A9_Exploration_de_la_console/#etape-2-creer-un-projet-et-deployer-une-application","title":"\u00c9tape 2 : Cr\u00e9er un projet et d\u00e9ployer une application","text":"<p>Pour utiliser la perspective Developer de la console Web et cr\u00e9er votre premier projet :</p> <ol> <li>Dans la vue developer, cliquez sur votre Project en haut \u00e0 gauche puis sur  \"Create a new project\" pour ouvrir l'assistant Create Project.</li> </ol> <p></p> <p>Cr\u00e9ez un projet nomm\u00e9 \"console-exploration-YOURCITY\" \u00e0 l'aide de cet assistant et ajoutez une br\u00e8ve description du projet.</p> <ol> <li>Cliquez sur \"Create\" pour finaliser la cr\u00e9ation du projet.</li> </ol> <p></p> <ol> <li> <p>Ensuite, cliquez sur \"+Add\" pour cr\u00e9er une application.</p> </li> <li> <p>Pour d\u00e9ployer un exemple d'application dans le projet :</p> </li> <li> <p>Cliquez dans \"Create applications using samples\" sur le lien \"Basic Quarkus\".</p> </li> </ol> <p></p> <ul> <li>Examinez les valeurs par d\u00e9faut de l'exemple d'application, puis s\u00e9lectionnez \"Create\" en bas de la page.</li> </ul> <p></p> <ol> <li> <p>Une fois le d\u00e9ploiement effectu\u00e9, rendez vous dans \u00e0 la page \"Topology\" qui affiche maintenant le d\u00e9ploiement de l'application \"code-with-quarkus\".</p> </li> <li> <p>Pour afficher les d\u00e9tails de ce d\u00e9ploiement :</p> </li> <li> <p>S\u00e9lectionnez l'ic\u00f4ne correspondant \u00e0 \"code-with-quarkus\" dans le panneau \"Topology\" pour ouvrir les d\u00e9tails du d\u00e9ploiement.</p> </li> </ol> <p></p> <ul> <li>Dans la partie \"Route\" cliquez sur la location pour acc\u00e9der au deploiement de \"code-with-quarkus\".</li> </ul> <p></p> <p></p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/03_Exercice_guid%C3%A9_Exploration_de_la_console/#etape-4-gerer-et-superviser-votre-application","title":"\u00c9tape 4 : G\u00e9rer et superviser votre application","text":"<p>Pour basculer vers la perspective Administrator et examiner le d\u00e9ploiement :</p> <ol> <li> <p>Depuis la console Web OpenShift cliquez sur \"Developer\", puis sur \"Administrator\" pour passer \u00e0 la perspective Administrator. La console Web se met \u00e0 jour pour afficher la nouvelle perspective avec des informations suppl\u00e9mentaires via la barre lat\u00e9rale.</p> </li> <li> <p>Acc\u00e9dez \u00e0 \"Home\" &gt; \"Projects\" pour voir la liste des projets disponibles, y compris le projet \"console-exploration-YOURCITY\" que vous avez cr\u00e9\u00e9.</p> </li> </ol> <p></p> <p>Pour afficher le d\u00e9ploiement et les pods de \"code-with-quarkus\" :</p> <ol> <li>Acc\u00e9dez \u00e0 \"Workloads\" &gt; \"Pods\" dans le menu de la console Web OpenShift pour voir les pods de \"code-with-quarkus\".</li> </ol> <p></p> <ol> <li>Ensuite, allez \u00e0 \"Workloads\" &gt; \"Deployments\" pour voir la liste des d\u00e9ploiements dans le projet. Cliquez sur \"code-with-quarkus\" pour voir les d\u00e9tails sp\u00e9cifiques du d\u00e9ploiement.</li> </ol> <p></p> <p>Pour afficher le service et la route de \"code-with-quarkus\" :</p> <ol> <li>Acc\u00e9dez \u00e0 \"Networking\" &gt; \"Services\", puis cliquez sur \"code-with-quarkus\" pour voir les d\u00e9tails du service.</li> </ol> <p></p> <p>Pour supprimer le projet et vous d\u00e9connecter de la console Web :</p> <ol> <li> <p>Retournez \u00e0 \"Home\" &gt; \"Projects\" depuis le menu de la console Web OpenShift.</p> </li> <li> <p>S\u00e9lectionnez \"Delete Project\" dans le menu contextuel du projet \"console-exploration-YOURCITY\".</p> </li> </ol> <p></p> <ol> <li>Saisissez le nom du projet dans la zone de texte pour confirmer la suppression, puis cliquez sur \"Delete\".</li> </ol>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/03_Exercice_guid%C3%A9_Exploration_de_la_console/#conclusion","title":"Conclusion","text":"<p>Vous avez maintenant une bonne compr\u00e9hension de la console web d'OpenShift. Vous savez comment cr\u00e9er des projets, d\u00e9ployer des applications, surveiller les ressources et configurer des alertes. Continuez \u00e0 explorer les autres fonctionnalit\u00e9s de la console pour renforcer vos comp\u00e9tences. Si vous avez des questions ou des difficult\u00e9s, consultez la documentation officielle d'OpenShift ou demandez de l'aide \u00e0 votre administrateur.</p> <p>Dans la prochaine section, nous aborderons l'architecture d'OpenShift et Kubernetes, en explorant leurs composants cl\u00e9s et leur interaction.</p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/04_Architecture_Openshift_et_Kubernetes/","title":"Concepts Architecturaux de Kubernetes","text":""},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/04_Architecture_Openshift_et_Kubernetes/#objectif","title":"Objectif","text":"<p>Dans cette section, nous allons explorer l'architecture d'OpenShift.</p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/04_Architecture_Openshift_et_Kubernetes/#concepts","title":"Concepts","text":"<p>Kubernetes repose sur plusieurs serveurs, ou nodes, pour garantir la r\u00e9silience et l\u2019\u00e9volutivit\u00e9 des applications qu\u2019il g\u00e8re. Ces nodes, qu\u2019ils soient physiques ou virtuels, fournissent les ressources n\u00e9cessaires au cluster. Il y a deux types de nodes, chacun ayant un r\u00f4le distinct dans le fonctionnement du cluster. Les nodes du plan de contr\u00f4le g\u00e8rent la coordination globale du cluster, notamment la planification des charges de travail et la gestion de l\u2019\u00e9tat de configuration du cluster. Les nodes du plan de calcul ex\u00e9cutent les applications, en communiquant avec les nodes du plan de contr\u00f4le pour recevoir les demandes d\u2019ex\u00e9cution des applications.</p> <p></p> <p>La communication entre le plan de contr\u00f4le et les nodes du cluster s'effectue via le service kubelet qui fonctionne sur chaque node. Bien qu'un serveur puisse servir \u00e0 la fois de node de plan de contr\u00f4le et de calcul, ces r\u00f4les sont souvent s\u00e9par\u00e9s pour une meilleure stabilit\u00e9, s\u00e9curit\u00e9 et g\u00e9rabilit\u00e9.</p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/04_Architecture_Openshift_et_Kubernetes/#composants-du-plan-de-controle","title":"Composants du Plan de Contr\u00f4le","text":"<p>Pour comprendre comment Kubernetes assure la coordination et la gestion des clusters, diff\u00e9rents composants du plan de contr\u00f4le interviennent. Ces principaux \u00e9l\u00e9ments sont les suivant :</p> <ul> <li>etcd : Une base de donn\u00e9es distribu\u00e9e cl\u00e9-valeur qui stocke les configurations du cluster.</li> <li>kube-apiserver : Le service frontal qui expose l\u2019API Kubernetes.</li> <li>kube-scheduler : Un service qui d\u00e9termine les nodes de calcul disponibles pour les nouvelles demandes de pods.</li> </ul> <p></p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/04_Architecture_Openshift_et_Kubernetes/#composants-du-plan-de-calcul","title":"Composants du Plan de Calcul","text":"<p>Les composants du plan de calcul sont les responsables de l'ex\u00e9cution des applications. Ces composants travaillent en \u00e9troite collaboration avec le plan de contr\u00f4le pour s'assurer que les pods sont d\u00e9ploy\u00e9s et g\u00e9r\u00e9s efficacement. Les principaux sont les suivants :</p> <ul> <li>kubelet : L'agent principal sur chaque node de calcul, charg\u00e9 de l'ex\u00e9cution des pods demand\u00e9s via l'API et le planificateur.</li> <li>CRI (Container Runtime Interface) : Une interface de plug-in pour la communication entre kubelet et les configurations de pods.</li> <li>cri-o : Un moteur d\u2019ex\u00e9cution compatible OCI qui facilite la communication entre kubelet et les demandes de configuration de pods.</li> </ul>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/04_Architecture_Openshift_et_Kubernetes/#concepts-architecturaux-de-red-hat-enterprise-linux-coreos","title":"Concepts Architecturaux de Red Hat Enterprise Linux CoreOS","text":"<p>L'ensemble de ces nodes reposent sur un OS sp\u00e9cifique : Red Hat Enterprise Linux CoreOS (RHCOS).</p> <p>Red Hat Enterprise Linux CoreOS est une distribution Linux optimis\u00e9e pour ex\u00e9cuter les conteneurs \u00e0 grande \u00e9chelle. Int\u00e9gr\u00e9e \u00e0 OpenShift, elle fournit une base solide et s\u00e9curis\u00e9e pour les nodes du cluster, avec une gestion simplifi\u00e9e et automatis\u00e9e. RHCOS assure que les machines h\u00f4tes sont correctement configur\u00e9es sans n\u00e9cessiter une intervention manuelle significative de la part des administrateurs.</p> <p>L'utilisation de RHCOS est facilit\u00e9e par le Machine Configuration Operator (MCO) d'OpenShift. Le MCO est responsable de la gestion et de la configuration du syst\u00e8me d\u2019exploitation sous-jacent des nodes. Il permet non seulement l'installation initiale, mais aussi la mise \u00e0 jour et la maintenance continue des syst\u00e8mes CoreOS, garantissant que les nodes restent coh\u00e9rents avec les politiques et les configurations d\u00e9finies par les administrateurs.</p> <p>En plus de ces fonctionnalit\u00e9s, RHCOS offre plusieurs avantages cl\u00e9s pour les environnements OpenShift :</p> <ol> <li>S\u00e9curit\u00e9 Renforc\u00e9e : Gr\u00e2ce \u00e0 des mises \u00e0 jour automatiques et \u00e0 des correctifs de s\u00e9curit\u00e9 int\u00e9gr\u00e9s, RHCOS maintient un haut niveau de s\u00e9curit\u00e9 sans intervention manuelle.</li> <li>Optimisation des Performances : RHCOS est con\u00e7u pour ex\u00e9cuter des conteneurs de mani\u00e8re efficace, r\u00e9duisant les co\u00fbts et am\u00e9liorant les performances des applications h\u00e9berg\u00e9es.</li> <li>Simplification de la Gestion : Avec le MCO et d'autres outils int\u00e9gr\u00e9s, RHCOS simplifie la gestion des nodes, permettant aux \u00e9quipes DevOps de se concentrer sur le d\u00e9veloppement et le d\u00e9ploiement des applications.</li> </ol> <p>En int\u00e9grant RHCOS, OpenShift b\u00e9n\u00e9ficie d'une base fiable et performante, essentielle pour ex\u00e9cuter des charges de travail conteneuris\u00e9es \u00e0 grande \u00e9chelle tout en minimisant les efforts de gestion et en maximisant la s\u00e9curit\u00e9 et la performance.</p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/05_Quiz_Architecture_Openshift_et_Kubernetes/","title":"Quiz sur l'architecture d'Openshift","text":"<p>Nous allons maintenant faire un quiz pour \u00e9valuer votre compr\u00e9hension de la partie \"Architecture d'OpenShift\". Ce quiz couvrira les concepts  abord\u00e9s.</p> <p>Pour joindre le quiz, veuillez suivre les \u00e9tapes suivantes :</p> <ol> <li> <p>Ouvrez l'application Quizizz sur votre appareil ou rendez-vous sur : https://quizizz.com/join.</p> </li> <li> <p>Entrez le num\u00e9ro fourni par l'instructeur pour acc\u00e9der au quiz.</p> </li> </ol> <p></p> <p>Bonne chance \u00e0 tous !</p>"},{"location":"01_Pr%C3%A9sentation_de_Kubernetes_et_Openshift/06_R%C3%A9sum%C3%A9/","title":"R\u00e9sum\u00e9","text":"<p>Dans cette partie, le formateur fera une synth\u00e8se de tout ce qui a \u00e9t\u00e9 vu dans les parties pr\u00e9c\u00e9dentes. Ce sera l'occasion de revoir les points cl\u00e9s, de clarifier les concepts abord\u00e9s et de s'assurer que tous les participants ont bien assimil\u00e9 le contenu.</p> <p>C'est \u00e9galement le moment id\u00e9al pour poser toutes les questions que vous pourriez avoir. Rappelez-vous que m\u00eame les questions qui peuvent sembler simples ou \u00e9videntes sont importantes. Alors, ne soyez pas timide : comme on dit, il n'y a pas de questions b\u00eates, seulement des r\u00e9ponses... parfois un peu longues !</p> <p></p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/","title":"Interagir avec la Ligne de Commande sur OpenShift","text":""},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#objectif-de-la-section","title":"Objectif de la section","text":"<p>L'objectif de cette section est de fournir une compr\u00e9hension approfondie de l'interaction avec OpenShift via l'interface de ligne de commande (CLI). Vous apprendrez \u00e0 installer et configurer les outils n\u00e9cessaires, ainsi qu'\u00e0 utiliser des commandes pour g\u00e9rer et d\u00e9ployer des applications sur OpenShift. Cette section couvrira les concepts fondamentaux pour vous permettre d'exploiter pleinement les capacit\u00e9s de la CLI dans des environnements de d\u00e9veloppement et de production.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#introduction-aux-interfaces-de-ligne-de-commande","title":"Introduction aux Interfaces de Ligne de Commande","text":"<p>OpenShift offre deux interfaces de ligne de commande principales pour la gestion des clusters et des applications : <code>kubectl</code> et <code>oc</code>. Ces outils sont utilent pour les d\u00e9veloppeurs et les administrateurs qui pr\u00e9f\u00e8rent ou ont besoin d'interagir directement avec leurs clusters OpenShift depuis un terminal, plut\u00f4t que par la console Web.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#kubectl-et-oc-differences-et-complementarites","title":"Kubectl et OC : Diff\u00e9rences et Compl\u00e9mentarit\u00e9s","text":"<p><code>kubectl</code> est l'outil de ligne de commande natif de Kubernetes. Il offre une interface pour interagir avec les clusters Kubernetes en ex\u00e9cutant des commandes qui communiquent avec l'API Kubernetes.</p> <p><code>oc</code>, quant \u00e0 lui, est une extension de <code>kubectl</code> fournie par OpenShift. En plus des commandes de base de Kubernetes, <code>oc</code> inclut des fonctionnalit\u00e9s sp\u00e9cifiques \u00e0 OpenShift qui ne sont pas disponibles dans <code>kubectl</code>. Par exemple, <code>oc</code> ajoute des commandes pour g\u00e9rer les projets, les routes, les configurations de d\u00e9ploiement, et bien plus encore. En utilisant <code>oc</code>, les utilisateurs peuvent acc\u00e9der \u00e0 des capacit\u00e9s avanc\u00e9es d'OpenShift tout en conservant l'acc\u00e8s aux commandes standard de Kubernetes.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#installation-des-outils-de-ligne-de-commande","title":"Installation des Outils de Ligne de Commande","text":"<p>Pour interagir avec OpenShift via la ligne de commande, il est n\u00e9cessaire d'installer les outils <code>kubectl</code> et/ou <code>oc</code>. L'installation de <code>oc</code> inclut g\u00e9n\u00e9ralement <code>kubectl</code>, rendant ainsi l'ensemble du processus plus simple pour les utilisateurs d'OpenShift.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#installation-de-oc","title":"Installation de OC","text":"<p>Pour installer <code>oc</code>, suivez ces \u00e9tapes :</p> <ol> <li> <p>T\u00e9l\u00e9chargez le client OpenShift :</p> <ul> <li>Acc\u00e9dez \u00e0 la console Web OpenShift.</li> <li>Cliquez sur le point d'interrogation en haut \u00e0 droite et s\u00e9lectionnez \"Command Line Tools\".</li> </ul> <p></p> <ul> <li>T\u00e9l\u00e9chargez l'archive du client OpenShift pour votre syst\u00e8me d'exploitation.</li> </ul> <p></p> </li> <li> <p>D\u00e9compressez l'archive :</p> <ul> <li>Sous Linux ou macOS :   <code>bash   tar xvzf openshift-client-linux.tar.gz</code></li> <li>Sous Windows, utilisez un outil de d\u00e9compression comme 7-Zip pour extraire les fichiers.</li> </ul> </li> <li> <p>Ajoutez <code>oc</code> \u00e0 votre PATH :</p> <ul> <li>Sous Linux ou macOS :   <code>bash   sudo mv oc /usr/local/bin/</code></li> </ul> </li> </ol>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#authentification-et-connexion","title":"Authentification et Connexion","text":"<p>Pour interagir avec un cluster OpenShift, il est essentiel de s'authentifier correctement. OpenShift offre deux m\u00e9thodes principales pour se connecter via la ligne de commande : en utilisant <code>oc login</code> avec les identifiants de l'utilisateur ou en utilisant la commande de connexion g\u00e9n\u00e9r\u00e9e depuis la console Web.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#methode-1-connexion-avec-oc-login","title":"M\u00e9thode 1 : Connexion avec <code>oc login</code>","text":"<ol> <li>Ouvrez votre terminal.</li> <li> <p>Ex\u00e9cutez la commande <code>oc login</code> en fournissant l'URL du serveur, votre nom d'utilisateur et votre mot de passe :</p> <p><code>bash oc login https://api.ocp4.example.com:6443 Username: developer Password: developer</code></p> <p>``` Login successful.</p> <p>You have access to 58 projects, the list has been suppressed. You can list all projects with 'oc projects'</p> <p>Using project \"default\". ```</p> <p>Ce message confirme une connexion r\u00e9ussie et vous informe que vous \u00eates actuellement dans le projet \"default\".</p> </li> </ol>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#methode-2-connexion-via-la-commande-copiee-de-la-console-web","title":"M\u00e9thode 2 : Connexion via la Commande Copi\u00e9e de la Console Web","text":"<ol> <li>Acc\u00e9dez \u00e0 la console Web OpenShift.</li> <li>Cliquez sur votre nom d'utilisateur en haut \u00e0 droite.</li> <li> <p>S\u00e9lectionnez \"Copy login command\".</p> <p></p> </li> <li> <p>Cliquez sur \"Display Token\" pour afficher le token.</p> <p></p> </li> <li> <p>Copiez la commande de connexion affich\u00e9e.</p> <p><code>bash oc login --token=&lt;votre_token&gt; --server=https://api.ocp4.example.com:6443</code></p> </li> <li> <p>Collez et ex\u00e9cutez cette commande dans votre terminal.</p> <p><code>bash oc login --token=&lt;votre_token&gt; --server=https://api.ocp4.example.com:6443</code></p> <p>``` Login successful.</p> <p>You have access to 58 projects, the list has been suppressed. You can list all projects with 'oc projects'</p> <p>Using project \"default\". ```</p> <p>Cette m\u00e9thode vous permet de vous connecter rapidement et en toute s\u00e9curit\u00e9 sans avoir \u00e0 saisir manuellement vos identifiants.</p> </li> </ol> <p>En utilisant l'une ou l'autre de ces m\u00e9thodes, vous pouvez facilement vous connecter \u00e0 votre cluster OpenShift et commencer \u00e0 g\u00e9rer vos ressources et d\u00e9ployer vos applications.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#gestion-des-projets","title":"Gestion des Projets","text":"<p>Les projets dans OpenShift sont des espaces de noms Kubernetes avec des annotations suppl\u00e9mentaires. Ils permettent d'isoler les ressources de votre application et de g\u00e9rer des environnements distincts.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#creation-dun-projet","title":"Cr\u00e9ation d'un Projet","text":"<p>Pour cr\u00e9er un nouveau projet, utilisez la commande <code>oc new-project</code> :</p> <pre><code>oc new-project myapp\n</code></pre> <pre><code>Now using project \"myapp\" on server \"https://api.ocp4.example.com:6443\".\n\nYou can add applications to this project with the 'new-app' command. For example, try:\n\n    oc new-app django-psql-example\n\nto build a new example application in Python. Or use kubectl to deploy a simple Kubernetes app:\n\n    kubectl create deployment hello-node --image=k8s.gcr.io/serve_hostname\n</code></pre> <p>Ce message indique que le projet \"myapp\" a \u00e9t\u00e9 cr\u00e9\u00e9 avec succ\u00e8s et vous donne des suggestions pour ajouter des applications \u00e0 ce projet.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#commandes-pour-la-gestion-des-ressources","title":"Commandes pour la Gestion des Ressources","text":"<p>Les commandes <code>oc</code> et <code>kubectl</code> offrent un ensemble de fonctionnalit\u00e9s pour la gestion des ressources dans OpenShift. Voici quelques-unes des commandes les plus utilis\u00e9es :</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#afficher-les-ressources","title":"Afficher les Ressources","text":"<ul> <li>Lister les pods :</li> </ul> <pre><code>oc get pods\n</code></pre> <pre><code>NAME                       READY   STATUS    RESTARTS   AGE\nmyapp-1-abcde              1/1     Running   0          5m\nmyapp-2-abcde              1/1     Running   0          3m\n</code></pre> <p>Ce tableau montre les noms des pods, leur \u00e9tat de pr\u00e9paration, leur statut, le nombre de red\u00e9marrages, et leur \u00e2ge.</p> <ul> <li>Afficher les d\u00e9tails d'un pod sp\u00e9cifique :</li> </ul> <pre><code>oc describe pod &lt;nom_du_pod&gt;\n</code></pre> <pre><code>Name:           myapp-1-abcde\nNamespace:      myapp\nNode:           worker-1/192.168.1.101\nStart Time:     Fri, 15 Jul 2023 10:15:00 +0000\nLabels:         app=myapp\nStatus:         Running\nIP:             10.129.2.1\nContainers:\n  myapp:\n    Container ID:   docker://abcdef12345\n    Image:          myapp:latest\n    Image ID:       docker-pullable://myapp@sha256:123456789abcdef\n    Port:           8080/TCP\n    State:          Running\n    Ready:          True\n</code></pre> <p>Cette sortie fournit des informations d\u00e9taill\u00e9es sur le pod, y compris ses conteneurs, l'ID de l'image, l'adresse IP, et l'\u00e9tat actuel.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#creer-et-supprimer-des-ressources","title":"Cr\u00e9er et Supprimer des Ressources","text":"<ul> <li>Cr\u00e9er une ressource \u00e0 partir d'un fichier YAML :</li> </ul> <pre><code>oc create -f pod.yaml\n</code></pre> <pre><code>pod/myapp-3-abcde created\n</code></pre> <p>Ce message confirme que le pod sp\u00e9cifi\u00e9 dans le fichier \"pod.yaml\" a \u00e9t\u00e9 cr\u00e9\u00e9 avec succ\u00e8s.</p> <ul> <li>Supprimer une ressource :</li> </ul> <pre><code>oc delete pod &lt;nom_du_pod&gt;\n</code></pre> <pre><code>pod \"myapp-1-abcde\" deleted\n</code></pre> <p>Ce message confirme que le pod \"myapp-1-abcde\" a \u00e9t\u00e9 supprim\u00e9 avec succ\u00e8s.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#verifier-letat-du-cluster","title":"V\u00e9rifier l'\u00c9tat du Cluster","text":"<ul> <li>Obtenir des informations sur le cluster :</li> </ul> <pre><code>oc cluster-info\n</code></pre> <pre><code>Kubernetes master is running at https://api.ocp4.example.com:6443\n  KubeDNS is running at https://api.ocp4.example.com:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\n</code></pre> <p>Cette sortie montre l'URL du serveur API principal de Kubernetes ainsi que l'adresse du service DNS du cluster.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#deploiement-dapplications","title":"D\u00e9ploiement d'Applications","text":"<p>OpenShift facilite le d\u00e9ploiement d'applications \u00e0 travers une s\u00e9rie de commandes simples. Voici quelques commandes cl\u00e9s pour d\u00e9ployer des applications.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#creation-dune-nouvelle-application","title":"Cr\u00e9ation d'une Nouvelle Application","text":"<ul> <li>Cr\u00e9er une nouvelle application :</li> </ul> <pre><code>oc new-app &lt;image&gt;\n#oc new-app nginx\n</code></pre> <pre><code>--&gt; Found image 64b0af3 (9 days old) in image stream \"openshift/nginx\" under tag \"latest\" for \"nginx\"\n\n    * An image stream tag will be created as \"nginx:latest\" that will track this image\n    * This image will be deployed in deployment config \"nginx\"\n    * Port 8080/tcp will be load balanced by service \"nginx\"\n      * Other containers can access this service through the hostname \"nginx\"\n\n--&gt; Creating resources ...\n    imagestream.image.openshift.io \"nginx\" created\n    deploymentconfig.apps.openshift.io \"nginx\" created\n    service \"nginx\" created\n--&gt; Success\n</code></pre> <p>Ce message indique que l'application bas\u00e9e sur l'image \"nginx\" a \u00e9t\u00e9 cr\u00e9\u00e9e avec succ\u00e8s, avec les ressources associ\u00e9es comme le flux d'image, la configuration de d\u00e9ploiement, et le service.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#exposition-dun-service","title":"Exposition d'un Service","text":"<p>Pour rendre votre application accessible de l'ext\u00e9rieur du cluster, vous pouvez exposer un service en cr\u00e9ant une route.</p> <ul> <li>Exposer un service :</li> </ul> <pre><code>oc expose svc/&lt;nom_du_service&gt;\n#oc expose svc/nginx\n</code></pre> <pre><code>route.route.openshift.io/nginx exposed\n</code></pre> <p>Ce message confirme que le service \"nginx\" a \u00e9t\u00e9 expos\u00e9 avec succ\u00e8s, ce qui signifie qu'une route a \u00e9t\u00e9 cr\u00e9\u00e9e pour permettre l'acc\u00e8s externe \u00e0 l'application.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#mise-a-jour-des-applications","title":"Mise \u00e0 Jour des Applications","text":"<p>Les applications n\u00e9cessitent souvent des mises \u00e0 jour pour d\u00e9ployer de nouvelles versions ou appliquer des correctifs.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#mise-a-jour-dune-image-de-deploiement","title":"Mise \u00e0 Jour d'une Image de D\u00e9ploiement","text":"<ul> <li>Mettre \u00e0 jour une image de d\u00e9ploiement :</li> </ul> <pre><code>oc set image dc/&lt;nom_du_deploymentconfig&gt; &lt;nom_du_container&gt;=&lt;nouvelle_image&gt;\n#oc set image dc/nginx nginx=nginx:latest\n</code></pre> <pre><code>deploymentconfig.apps.openshift.io/nginx image updated\n</code></pre> <p>Ce message indique que l'image du conteneur dans la configuration de d\u00e9ploiement \"nginx\" a \u00e9t\u00e9 mise \u00e0 jour avec succ\u00e8s.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#surveillance-des-applications","title":"Surveillance des Applications","text":"<p>Une fois vos applications d\u00e9ploy\u00e9es, il est important de surveiller leur \u00e9tat pour s'assurer qu'elles fonctionnent correctement.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#afficher-les-logs-dun-pod","title":"Afficher les Logs d'un Pod","text":"<ul> <li>Afficher les logs :</li> </ul> <pre><code>oc logs &lt;nom_du_pod&gt;\n#oc logs myapp-1-abcde\n</code></pre> <pre><code>[INFO] Starting nginx...\n[INFO] nginx is running.\n</code></pre> <p>Ces logs fournissent des informations sur l'\u00e9tat du pod et les op\u00e9rations effectu\u00e9es par le conteneur.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#execution-de-commandes-dans-un-pod","title":"Ex\u00e9cution de Commandes dans un Pod","text":"<p>Pour diagnostiquer des probl\u00e8mes ou administrer des applications, il peut \u00eatre n\u00e9cessaire d'ex\u00e9cuter des commandes directement dans un pod.</p> <ul> <li>Ex\u00e9cuter une commande dans un pod :</li> </ul> <pre><code>oc exec &lt;nom_du_pod&gt; -- &lt;commande&gt;\n#oc exec myapp-1-abcde -- ls /app\n</code></pre> <pre><code>index.html\nmain.js\nstyle.css\n</code></pre> <p>Cette sortie montre les fichiers dans le r\u00e9pertoire <code>/app</code> du pod, aidant ainsi \u00e0 v\u00e9rifier que les fichiers n\u00e9cessaires sont pr\u00e9sents.</p>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#tableau-des-commandes-principales-openshift","title":"Tableau des Commandes Principales OpenShift","text":"Commande Description Exemple Installation et Configuration <code>oc login &lt;server&gt;</code> Authentifie et connecte \u00e0 un cluster OpenShift <code>oc login https://api.ocp4.example.com:6443</code> Gestion des Projets <code>oc new-project &lt;nom_du_projet&gt;</code> Cr\u00e9e un nouveau projet <code>oc new-project myapp</code> Gestion des Ressources <code>oc get pods</code> Liste tous les pods dans le projet actuel <code>oc get pods</code> <code>oc describe pod &lt;nom_du_pod&gt;</code> Affiche les d\u00e9tails d'un pod sp\u00e9cifique <code>oc describe pod myapp-1-abcde</code> <code>oc create -f &lt;fichier_yaml&gt;</code> Cr\u00e9e une ressource \u00e0 partir d'un fichier YAML <code>oc create -f pod.yaml</code> <code>oc delete pod &lt;nom_du_pod&gt;</code> Supprime un pod sp\u00e9cifique <code>oc delete pod myapp-1-abcde</code> <code>oc cluster-info</code> Affiche des informations sur le cluster <code>oc cluster-info</code> D\u00e9ploiement d'Applications <code>oc new-app &lt;image&gt;</code> Cr\u00e9e une nouvelle application bas\u00e9e sur une image <code>oc new-app nginx</code> <code>oc expose svc/&lt;nom_du_service&gt;</code> Expose un service pour permettre l'acc\u00e8s externe \u00e0 l'application <code>oc expose svc/nginx</code> Mise \u00e0 Jour des Applications <code>oc set image dc/&lt;nom_du_deploymentconfig&gt; &lt;nom_du_container&gt;=&lt;nouvelle_image&gt;</code> Met \u00e0 jour l'image d'un d\u00e9ploiement <code>oc set image dc/nginx nginx=nginx:latest</code> Surveillance des Applications <code>oc logs &lt;nom_du_pod&gt;</code> Affiche les logs d'un pod <code>oc logs myapp-1-abcde</code> <code>oc exec &lt;nom_du_pod&gt; -- &lt;commande&gt;</code> Ex\u00e9cute une commande dans un pod <code>oc exec myapp-1-abcde -- ls /app</code> Gestion des Routes et Services <code>oc get routes</code> Liste toutes les routes dans le projet actuel <code>oc get routes</code> <code>oc delete route &lt;nom_de_la_route&gt;</code> Supprime une route sp\u00e9cifique <code>oc delete route myapp-route</code> <code>oc get svc</code> Liste tous les services dans le projet actuel <code>oc get svc</code> <code>oc delete svc &lt;nom_du_service&gt;</code> Supprime un service sp\u00e9cifique <code>oc delete svc myapp-service</code> Autres Commandes Utiles <code>oc get all</code> Liste toutes les ressources dans le projet actuel <code>oc get all</code> <code>oc rollout status dc/&lt;nom_du_deploymentconfig&gt;</code> Affiche le statut du d\u00e9ploiement <code>oc rollout status dc/nginx</code> <code>oc scale --replicas=&lt;nombre&gt; dc/&lt;nom_du_deploymentconfig&gt;</code> Change le nombre de r\u00e9plicas d'un d\u00e9ploiement <code>oc scale --replicas=3 dc/nginx</code> <code>oc rollout undo dc/&lt;nom_du_deploymentconfig&gt;</code> Annule le dernier d\u00e9ploiement <code>oc rollout undo dc/nginx</code> <code>oc get events</code> Liste tous les \u00e9v\u00e9nements dans le projet actuel <code>oc get events</code>"},{"location":"02_Interface_et_ligne_de_commande/00_Int%C3%A9ragir_avec_la_ligne_de_commande/#conclusion","title":"Conclusion","text":"<p>L'utilisation de la ligne de commande avec OpenShift, via <code>kubectl</code> et <code>oc</code>, offre  une flexibilit\u00e9 consid\u00e9rables pour g\u00e9rer des clusters et des applications. En comprenant les commandes essentielles et en apprenant \u00e0 interpr\u00e9ter leurs sorties, vous serez bien \u00e9quip\u00e9 pour administrer efficacement vos environnements OpenShift, d\u00e9ployer des applications, g\u00e9rer des ressources et diagnostiquer des probl\u00e8mes. La ma\u00eetrise de ces outils est essentielle pour tout professionnel travaillant dans un environnement Kubernetes/OpenShift, offrant ainsi un contr\u00f4le granulaire et des capacit\u00e9s avanc\u00e9es pour une gestion optimale des infrastructures cloud-native.</p>"},{"location":"02_Interface_et_ligne_de_commande/01_Exerice_guid%C3%A9_Int%C3%A9ragir_avec_la_ligne_de_commande/","title":"Exercice Guid\u00e9 : Interaction avec OpenShift via la Ligne de Commande","text":""},{"location":"02_Interface_et_ligne_de_commande/01_Exerice_guid%C3%A9_Int%C3%A9ragir_avec_la_ligne_de_commande/#objectif","title":"Objectif","text":"<p>Cet exercice vous guidera \u00e0 travers les \u00e9tapes de base pour se connecter \u00e0 un cluster OpenShift, explorer les commandes disponibles, et g\u00e9rer une application simple.</p> <p>Toutes les commandes doivent \u00eatre ex\u00e9cut\u00e9es dans le terminal web d'OpenShift.</p> <p>1. Connexion au Cluster OpenShift</p> <p>Pour commencer, vous devez vous connecter \u00e0 votre cluster OpenShift :</p> <ol> <li>Acc\u00e9dez \u00e0 la console Web OpenShift.</li> <li>Cliquez sur votre nom d'utilisateur en haut \u00e0 droite.</li> <li> <p>S\u00e9lectionnez \"Copy login command\".</p> <p></p> </li> <li> <p>Cliquez sur \"Display Token\" pour afficher le token.</p> <p></p> </li> <li> <p>Copiez la commande de connexion affich\u00e9e.</p> </li> <li>Ouvrez le terminal web OpenShift en haut \u00e0 droite. </li> <li>Cliquez sur Open terminal in a new tab et selectionnez votre projet. Cliquez sur start. Le premier d\u00e9marrage peut prendre quelques secondes</li> </ol>"},{"location":"02_Interface_et_ligne_de_commande/01_Exerice_guid%C3%A9_Int%C3%A9ragir_avec_la_ligne_de_commande/#_1","title":"Exercice Guid\u00e9 : Interaction avec OpenShift via la Ligne de Commande","text":"<ol> <li>Collez et ex\u00e9cutez cette commande dans votre terminal web OpenShift.</li> </ol> <pre><code>oc login --token=&lt;votre_token&gt; --server=https://api.ocp4.example.com:6443\n</code></pre> <p>Vous devriez voir un message confirmant la connexion r\u00e9ussie :</p> <pre><code>Login successful.\n\nYou have access to 58 projects, the list has been suppressed. You can list all projects with 'oc projects'\n\nUsing project \"default\".\n</code></pre> <p>Cette \u00e9tape vous connecte \u00e0 votre cluster OpenShift en utilisant un token d'authentification. La connexion est n\u00e9cessaire pour interagir avec les ressources de votre cluster via la ligne de commande.</p> <p>2. Exploration des Commandes Disponibles</p> <p>Maintenant que vous \u00eates connect\u00e9, voyons les commandes que vous pouvez utiliser pour interagir avec votre cluster :</p> <ol> <li>Listez les commandes disponibles avec <code>kubectl</code> :</li> </ol> <pre><code>kubectl help\n</code></pre> <p>Vous verrez une liste de commandes disponibles pour interagir avec Kubernetes, par exemple :</p> <pre><code>Basic Commands (Beginner):\n  create        Create a resource from a file or from stdin.\n  expose        Take a replication controller, service, deployment or pod and expose it as a new Kubernetes Service\n  run           Run a particular image on the cluster\n  set           Set specific features on objects\n</code></pre> <ol> <li>Listez les commandes disponibles avec <code>oc</code> :</li> </ol> <pre><code>oc help\n</code></pre> <p>Vous verrez une liste de commandes disponibles pour interagir avec OpenShift, y compris les commandes sp\u00e9cifiques \u00e0 OpenShift, par exemple :</p> <pre><code>Build and Deploy Commands:\n  new-app      Create a new application\n  new-build    Create a new build configuration\n  start-build  Start a new build\n</code></pre> <p>La commande <code>oc</code> prend en charge les m\u00eames fonctionnalit\u00e9s que la commande <code>kubectl</code>. La commande <code>oc</code> fournit des commandes suppl\u00e9mentaires pour la prise en charge native d\u2019un cluster OpenShift. La commande <code>new-project</code>, par exemple, cr\u00e9e dans le cluster OpenShift un projet qui est un espace de noms Kubernetes. La commande <code>new-app</code> est sp\u00e9cifique \u00e0 la commande <code>oc</code>. Elle cr\u00e9e des applications en utilisant le code source existant ou des images pr\u00e9d\u00e9finies.</p> <p>3. Gestion des Namespaces</p> <p>Les namespaces permettent d'organiser les ressources dans votre cluster. Vous pouvez voir le namespace actuel et en changer si n\u00e9cessaire :</p> <ol> <li>Affichez le namespace actuel :</li> </ol> <pre><code>oc project\n</code></pre> <p>Vous verrez une sortie similaire \u00e0 celle-ci :</p> <pre><code>Using project \"prague-user-ns\" from context named \"prague-user-context\" on server \"https://172.30.0.1:443\".\n</code></pre> <ol> <li>Changez de namespace (si n\u00e9cessaire) :</li> </ol> <pre><code>oc project &lt;nom_du_namespace&gt;\n</code></pre> <p>Par exemple :</p> <pre><code>oc project myproject\n</code></pre> <p>Vous verrez une confirmation du changement de projet :</p> <pre><code>Now using project \"myproject\" on server \"https://api.ocp4.example.com:6443\".\n</code></pre> <p>Les namespaces (ou projets) permettent d'isoler les ressources dans un cluster. Cette commande vous permet de v\u00e9rifier et de changer le namespace actif pour organiser et acc\u00e9der aux ressources sp\u00e9cifiques \u00e0 un projet.</p> <p>4. Cr\u00e9ation d'une Nouvelle Application</p> <p>Nous allons maintenant cr\u00e9er une application simple en utilisant une image de base. Suivez ces \u00e9tapes :</p> <ol> <li>Cr\u00e9ez une nouvelle application en utilisant une image de base :</li> </ol> <pre><code>oc new-app --image=quay.io/neutron-it/p02l01-go-app\n</code></pre> <p>Vous verrez une sortie similaire \u00e0 celle-ci :</p> <pre><code>--&gt; Found container image ec997ee (10 minutes old) from quay.io for \"quay.io/neutron-it/p02l01-go-app\"\n\n    Go 1.21.11\n    ----------\n    Go Toolset available as a container is a base platform for building and running various Go applications and frameworks. Go is an easy to learn, powerful, statically typed language in the C/C++ tradition with garbage collection, concurrent programming support, and memory safety features.\n\n    Tags: builder, golang, golang121, rh-golang121, go\n\n    * An image stream tag will be created as \"p02l01-go-app:latest\" that will track this image\n\n--&gt; Creating resources ...\n    deployment.apps \"p02l01-go-app\" created\n    service \"p02l01-go-app\" created\n--&gt; Success\n    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:\n     'oc expose service/p02l01-go-app'\n    Run 'oc status' to view your app.\n</code></pre> <p>Cette commande cr\u00e9e une nouvelle application bas\u00e9e sur l'image \"p02l01-go-app\". OpenShift cr\u00e9e automatiquement les ressources n\u00e9cessaires, comme l'image stream, la configuration de d\u00e9ploiement et le service.</p> <p>5. Description de l'Application</p> <p>Pour obtenir des d\u00e9tails sur l'application que vous venez de cr\u00e9er :</p> <ol> <li>D\u00e9crivez votre application pour obtenir des d\u00e9tails :</li> </ol> <pre><code>oc describe deployment/p02l01-go-app\n</code></pre> <p>Vous verrez une sortie d\u00e9taill\u00e9e avec des informations sur la configuration de d\u00e9ploiement, les strat\u00e9gies de d\u00e9ploiement, l'\u00e9tat des r\u00e9plicas, et plus encore :</p> <pre><code>Name:                   p02l01-go-app\nNamespace:              prague-user-ns\nCreationTimestamp:      Sun, 21 Jul 2024 10:09:10 +0000\nSelector:               deployment=p02l01-go-app\nReplicas:               1 desired | 1 updated | 1 total | 1 available | 0 unavailable\nStrategyType:           RollingUpdate\nMinReadySeconds:        0\nRollingUpdateStrategy:  25% max unavailable, 25% max surge\n...\n</code></pre> <p>Cette commande fournit des informations d\u00e9taill\u00e9es sur la configuration de d\u00e9ploiement de votre application, y compris l'\u00e9tat actuel des pods, les strat\u00e9gies de d\u00e9ploiement et les s\u00e9lecteurs.</p> <p>V\u00e9rifiez que votre pod est maintenant au status Ready :</p> <pre><code>oc get po\n</code></pre> <p>Attendez que votre pod soit indiquez en Running avant de passer \u00e0 l'\u00e9tape suivante :</p> <pre><code>NAME                                         READY   STATUS    RESTARTS   AGE\np02l01-go-app-6c457d7469-vhl2q               1/1     Running   0          2m33s\nworkspacee44a9674bf734f38-56fc7fdc44-6n2nr   2/2     Running   0          26m\n</code></pre> <p>6. Affichage des Logs de l'Application</p> <p>Pour diagnostiquer les probl\u00e8mes ou v\u00e9rifier que tout fonctionne correctement :</p> <ol> <li>Affichez les logs de l'application :</li> </ol> <pre><code>oc logs deployment/p02l01-go-app\n</code></pre> <p>Vous verrez les logs g\u00e9n\u00e9r\u00e9s par les conteneurs de votre application :</p> <pre><code>Bravo, vous \u00eates dans Exercice Guid\u00e9 : Interaction avec OpenShift via la Ligne de Commande\n</code></pre> <p>Les logs sont essentiels pour diagnostiquer les probl\u00e8mes et v\u00e9rifier que l'application fonctionne comme pr\u00e9vu.</p> <p>7. Ex\u00e9cution de Commandes dans un Pod</p> <p>Pour interagir avec les conteneurs de votre application, vous pouvez ex\u00e9cuter des commandes directement dans un pod en utilisant <code>oc exec</code> :</p> <ol> <li>Obtenez la liste des pods :</li> </ol> <pre><code>oc get pods\n</code></pre> <p>Vous verrez une liste des pods en cours d'ex\u00e9cution, par exemple :</p> <pre><code>NAME                           READY   STATUS    RESTARTS   AGE\np02l01-go-app-7f5b7fdfd6-4rfsl   1/1     Running   0          2m\n</code></pre> <ol> <li>Ex\u00e9cutez une commande dans un pod : Pour obtenir un shell interactif dans un pod :</li> </ol> <pre><code>oc exec -it &lt;pod-name&gt;  -- /bin/sh\n#oc exec -it  p02l01-go-app-7f5b7fdfd6-4rfsl -- /bin/sh\n</code></pre> <p>Remplacez <code>&lt;pod-name&gt;</code> par le nom du pod obtenu \u00e0 l'\u00e9tape pr\u00e9c\u00e9dente. Cela vous permettra de vous connecter au pod et d'ex\u00e9cuter des commandes \u00e0 l'int\u00e9rieur.</p> <p>Vous pouvez maintenant \u00e9x\u00e9cutez des commandes. Exemple :</p> <pre><code>ps aux\n</code></pre> <pre><code>sh-4.4$ ps aux\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n1001540+       1  0.0  0.0  12004  2496 ?        Ss   10:09   0:00 sh -c ./main &amp;&amp; while true; do sleep 86400; done\n1001540+      12  0.0  0.0  23148  1528 ?        S    10:09   0:00 /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 86400\n1001540+      20  1.5  0.0  12136  3232 pts/0    Ss   10:20   0:00 /bin/sh\n1001540+      26  0.0  0.0  44784  3436 pts/0    R+   10:20   0:00 ps aux\n</code></pre> <p>Pour sortir du shell utilisez <code>exit</code></p> <pre><code>sh-4.4$ exit\n</code></pre> <p>8. Suppression de l'Application</p> <p>Enfin, pour nettoyer les ressources cr\u00e9\u00e9es :</p> <ol> <li>Supprimez l'application nouvellement cr\u00e9\u00e9e :</li> </ol> <pre><code>oc delete all -l app=p02l01-go-app\n</code></pre> <p>Vous verrez une confirmation de suppression :</p> <pre><code>service \"p02l01-go-app\" deleted\ndeployment.apps \"p02l01-go-app\" deleted\nWarning: apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+\nimagestream.image.openshift.io \"p02l01-go-app\" deleted\n</code></pre> <p>Cette commande supprime toutes les ressources associ\u00e9es \u00e0 l'application \"nginx\" en utilisant une \u00e9tiquette (label). C'est une m\u00e9thode rapide pour nettoyer les ressources cr\u00e9\u00e9es.</p>"},{"location":"02_Interface_et_ligne_de_commande/01_Exerice_guid%C3%A9_Int%C3%A9ragir_avec_la_ligne_de_commande/#conclusion","title":"Conclusion","text":"<p>En suivant ces \u00e9tapes, vous aurez appris \u00e0 vous connecter \u00e0 un cluster OpenShift, \u00e0 comparer les commandes <code>kubectl</code> et <code>oc</code>, \u00e0 obtenir des informations sur le cluster, \u00e0 g\u00e9rer des namespaces, \u00e0 cr\u00e9er et g\u00e9rer une application, et enfin \u00e0 supprimer cette application. Ces comp\u00e9tences sont essentielles pour administrer efficacement des environnements OpenShift et Kubernetes.</p>"},{"location":"02_Interface_et_ligne_de_commande/02_Examen_des_ressources_Kubernetes/","title":"Examen des Ressources Kubernetes","text":"<p>Dans cette section, nous allons apprendre comment examiner les diff\u00e9rentes ressources disponibles dans un cluster Kubernetes \u00e0 l'aide de la ligne de commande <code>oc</code>. Comprendre ces ressources est essentiel pour g\u00e9rer efficacement un environnement Kubernetes et OpenShift.</p>"},{"location":"02_Interface_et_ligne_de_commande/02_Examen_des_ressources_Kubernetes/#objectifs-de-la-section","title":"Objectifs de la Section","text":"<p>Dans cette section, nous avons pour objectifs de :</p> <ol> <li> <p>Comprendre la structure des objets Kubernetes, en particulier les champs spec et status.</p> </li> <li> <p>Identifier et d\u00e9crire les autres champs courants des ressources Kubernetes.</p> </li> <li> <p>Illustrer la configuration d'un objet Kubernetes \u00e0 l'aide d'un exemple de manifest de d\u00e9ploiement.</p> </li> <li> <p>Apprendre \u00e0 utiliser les options de sortie YAML et JSON pour analyser et \u00e9crire des scripts.</p> </li> <li> <p>Ma\u00eetriser l'utilisation du format de sortie personnalis\u00e9 pour extraire des donn\u00e9es sp\u00e9cifiques de mani\u00e8re tabulaire.</p> </li> </ol>"},{"location":"02_Interface_et_ligne_de_commande/02_Examen_des_ressources_Kubernetes/#specification-et-statut-des-objets-kubernetes","title":"Sp\u00e9cification et statut des objets Kubernetes","text":"<p>Presque tous les objets Kubernetes contiennent deux champs d\u2019objets imbriqu\u00e9s qui r\u00e9gissent la configuration de l\u2019objet : l\u2019objet spec et l\u2019objet status.</p> <ul> <li>spec : d\u00e9crit l\u2019\u00e9tat pr\u00e9vu de la ressource. Vous sp\u00e9cifiez la section spec de la ressource lors de la cr\u00e9ation de l\u2019objet.</li> <li>status : d\u00e9crit l\u2019\u00e9tat actuel de la ressource. Les contr\u00f4leurs Kubernetes mettent \u00e0 jour en continu le status de l\u2019objet pendant toute sa dur\u00e9e de vie.</li> </ul> <p>Le plan de contr\u00f4le Kubernetes g\u00e8re continuellement et activement l\u2019\u00e9tat r\u00e9el de chaque objet pour qu\u2019il corresponde \u00e0 l\u2019\u00e9tat souhait\u00e9 que vous avez indiqu\u00e9.</p> <p>Le champ status utilise une collection d\u2019objets de ressource condition avec les champs suivants.</p>"},{"location":"02_Interface_et_ligne_de_commande/02_Examen_des_ressources_Kubernetes/#formats-de-sortie-yaml-et-json","title":"Formats de sortie YAML et JSON","text":"<p>Pour analyser et \u00e9crire des scripts, Kubernetes fournit des options de sortie aux formats YAML et JSON. Utilisons la commande <code>oc</code> pour extraire ces informations.</p>"},{"location":"02_Interface_et_ligne_de_commande/02_Examen_des_ressources_Kubernetes/#exemple-avec-o-yaml","title":"Exemple avec <code>-o yaml</code>","text":"<p>La commande suivante extrait les informations d'un d\u00e9ploiement au format YAML :</p> <pre><code>oc get deployment example-deployment -o yaml\n</code></pre>"},{"location":"02_Interface_et_ligne_de_commande/02_Examen_des_ressources_Kubernetes/#exemple-doutput-yaml","title":"Exemple d'output YAML :","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: example-deployment\n  namespace: default\n  labels:\n    app: example\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: example\n  template:\n    metadata:\n      labels:\n        app: example\n    spec:\n      containers:\n      - name: example-container\n        image: nginx:1.14.2\n        ports:\n        - containerPort: 80\nstatus:\n  replicas: 3\n  updatedReplicas: 3\n  readyReplicas: 3\n  availableReplicas: 3\n  conditions:\n  - type: Available\n    status: \"True\"\n    lastUpdateTime: \"2024-07-21T12:34:56Z\"\n    lastTransitionTime: \"2024-07-21T12:34:56Z\"\n    reason: MinimumReplicasAvailable\n    message: Deployment has minimum availability.\n</code></pre>"},{"location":"02_Interface_et_ligne_de_commande/02_Examen_des_ressources_Kubernetes/#details-des-champs","title":"D\u00e9tails des Champs","text":""},{"location":"02_Interface_et_ligne_de_commande/02_Examen_des_ressources_Kubernetes/#champs","title":"Champs","text":"Champ Description apiVersion Indique la version de l\u2019API utilis\u00e9e (ici, <code>apps/v1</code>). kind Type de ressource (ici, <code>Deployment</code>). metadata - name Nom de l\u2019objet (<code>example-deployment</code>). - namespace Namespace o\u00f9 se trouve l'objet (<code>default</code>). - labels \u00c9tiquettes associ\u00e9es \u00e0 l\u2019objet (<code>app: example</code>)."},{"location":"02_Interface_et_ligne_de_commande/02_Examen_des_ressources_Kubernetes/#specification-spec","title":"Sp\u00e9cification (<code>spec</code>)","text":"Champ Description replicas Nombre de r\u00e9plicas d\u00e9sir\u00e9 (ici, <code>3</code>). selector S\u00e9lecteur pour choisir les pods contr\u00f4l\u00e9s par ce d\u00e9ploiement. - matchLabels Crit\u00e8res de s\u00e9lection des pods (<code>app: example</code>). template - metadata - labels \u00c9tiquettes appliqu\u00e9es aux pods (<code>app: example</code>). - spec - containers Liste des conteneurs d\u00e9ploy\u00e9s par ce manifest. - name Nom du conteneur (<code>example-container</code>). - image Image Docker utilis\u00e9e (<code>nginx:1.14.2</code>). - ports Ports expos\u00e9s par le conteneur. - containerPort Port utilis\u00e9 par le conteneur (<code>80</code>)."},{"location":"02_Interface_et_ligne_de_commande/02_Examen_des_ressources_Kubernetes/#statut-status","title":"Statut (<code>status</code>)","text":"Champ Description replicas Nombre de r\u00e9plicas observ\u00e9s (<code>3</code>). updatedReplicas Nombre de r\u00e9plicas mis \u00e0 jour (<code>3</code>). readyReplicas Nombre de r\u00e9plicas pr\u00eats (<code>3</code>). availableReplicas Nombre de r\u00e9plicas disponibles (<code>3</code>). conditions Conditions actuelles du d\u00e9ploiement. - type Type de condition (<code>Available</code>). - status Statut de la condition (<code>True</code>). - lastUpdateTime Derni\u00e8re mise \u00e0 jour (<code>2024-07-21T12:34:56Z</code>). - lastTransitionTime Derni\u00e8re transition (<code>2024-07-21T12:34:56Z</code>). - reason Raison de la condition (<code>MinimumReplicasAvailable</code>). - message Message d\u00e9crivant la condition (<code>Deployment has minimum availability</code>)."},{"location":"02_Interface_et_ligne_de_commande/02_Examen_des_ressources_Kubernetes/#format-de-sortie-personnalise","title":"Format de sortie personnalis\u00e9","text":"<p>Pour extraire des donn\u00e9es sp\u00e9cifiques de mani\u00e8re tabulaire, Kubernetes offre un format de sortie personnalis\u00e9. Utilisez l\u2019option <code>-o custom-columns</code> avec des paires <code>&lt;column name&gt;: &lt;jq query string&gt;</code> s\u00e9par\u00e9es par des virgules.</p>"},{"location":"02_Interface_et_ligne_de_commande/02_Examen_des_ressources_Kubernetes/#exemple","title":"Exemple :","text":"<p>La commande suivante affiche les noms et statuts des pods :</p> <pre><code>oc get pods -o custom-columns=NAME:.metadata.name,STATUS:.status.phase\n</code></pre>"},{"location":"02_Interface_et_ligne_de_commande/02_Examen_des_ressources_Kubernetes/#exemple-doutput-personnalise","title":"Exemple d'output personnalis\u00e9 :","text":"<pre><code>NAME                STATUS\nexample-pod-1       Running\nexample-pod-2       Pending\nexample-pod-3       Running\n</code></pre>"},{"location":"02_Interface_et_ligne_de_commande/02_Examen_des_ressources_Kubernetes/#creation-et-mise-a-jour-des-ressources","title":"Cr\u00e9ation et Mise \u00e0 jour des Ressources","text":"<p>Pour cr\u00e9er ou mettre \u00e0 jour des ressources dans Kubernetes, utilisez les commandes <code>oc create -f</code> et <code>oc apply -f</code>. Ces commandes vous permettent de d\u00e9ployer ou de mettre \u00e0 jour des objets en fournissant un fichier de d\u00e9finition YAML ou JSON.</p>"},{"location":"02_Interface_et_ligne_de_commande/02_Examen_des_ressources_Kubernetes/#creation-dune-ressource","title":"Cr\u00e9ation d'une Ressource","text":"<p>Pour cr\u00e9er une ressource, utilisez la commande <code>oc create -f</code> suivie du chemin vers le fichier de d\u00e9finition. Par exemple :</p> <pre><code>oc create -f deployment.yaml\n</code></pre> <p>Cette commande lit le fichier <code>deployment.yaml</code> et cr\u00e9e le d\u00e9ploiement d\u00e9crit dans le fichier.</p>"},{"location":"02_Interface_et_ligne_de_commande/02_Examen_des_ressources_Kubernetes/#mise-a-jour-dune-ressource","title":"Mise \u00e0 jour d'une Ressource","text":"<p>Pour mettre \u00e0 jour une ressource existante, utilisez la commande <code>oc apply -f</code> suivie du chemin vers le fichier de d\u00e9finition. Par exemple :</p> <pre><code>oc apply -f deployment.yaml\n</code></pre> <p>Cette commande applique les modifications d\u00e9crites dans le fichier <code>deployment.yaml</code> \u00e0 la ressource existante. Si la ressource n'existe pas encore, elle sera cr\u00e9\u00e9e.</p>"},{"location":"02_Interface_et_ligne_de_commande/02_Examen_des_ressources_Kubernetes/#conclusion","title":"Conclusion","text":"<p>Dans cette section, nous avons explor\u00e9 la structure des objets Kubernetes, en mettant l'accent sur les champs spec et status, ainsi que sur d'autres champs courants. Nous avons illustr\u00e9 ces concepts avec un exemple de manifest de d\u00e9ploiement et avons appris \u00e0 utiliser les options de sortie YAML et JSON pour faciliter l'analyse et l'\u00e9criture de scripts. Enfin, nous avons d\u00e9couvert comment utiliser le format de sortie personnalis\u00e9 pour extraire des donn\u00e9es sp\u00e9cifiques de mani\u00e8re efficace. Ces comp\u00e9tences sont essentielles pour g\u00e9rer et interroger efficacement les ressources Kubernetes dans OpenShift.</p>"},{"location":"02_Interface_et_ligne_de_commande/03_Exercice_guid%C3%A9_Examen_des_ressources_Kubernetes/","title":"Exercice Guid\u00e9 : Examen des Ressources Kubernetes","text":"<p>Dans cet exercice, nous allons explorer comment examiner et manipuler les ressources Kubernetes en utilisant <code>oc</code>, l'outil de ligne de commande pour OpenShift. Nous allons nous concentrer sur les sorties personnalis\u00e9es, l'extraction et la modification de manifestes YAML, et l'application de ces modifications.</p>"},{"location":"02_Interface_et_ligne_de_commande/03_Exercice_guid%C3%A9_Examen_des_ressources_Kubernetes/#objectifs-de-lexercice","title":"Objectifs de l'exercice","text":"<ol> <li>Utiliser un script pour afficher des informations sp\u00e9cifiques sur les pods.</li> <li>Extraire un manifeste YAML d'un d\u00e9ploiement existant.</li> <li>Modifier le nom du d\u00e9ploiement et supprimer les champs inutilis\u00e9s.</li> <li>Appliquer les modifications au cluster.</li> </ol>"},{"location":"02_Interface_et_ligne_de_commande/03_Exercice_guid%C3%A9_Examen_des_ressources_Kubernetes/#etape-1-affichage-dinformations-specifiques-sur-les-pods","title":"\u00c9tape 1 : Affichage d'informations sp\u00e9cifiques sur les Pods","text":"<p>Utilisez la commande suivante pour afficher les noms et statuts des pods dans le cluster, en utilisant un format de sortie personnalis\u00e9.</p> <pre><code>oc get pods -o custom-columns=NAME:.metadata.name,STATUS:.status.phase\n</code></pre> <p>R\u00e9sultat attendu :</p> <pre><code>NAME                STATUS\nexample-pod-1       Running\nexample-pod-2       Pending\nexample-pod-3       Running\n</code></pre>"},{"location":"02_Interface_et_ligne_de_commande/03_Exercice_guid%C3%A9_Examen_des_ressources_Kubernetes/#etape-2-extraction-dun-manifeste-yaml","title":"\u00c9tape 2 : Extraction d'un Manifeste YAML","text":"<p>Extrayez les informations d'un d\u00e9ploiement nomm\u00e9 <code>example-deployment</code> au format YAML.</p> <pre><code>oc get deployment l03p02-app -n l03p02 -oyaml &gt; deployment.yaml\n</code></pre> <p>Exemple d'output YAML dans <code>deployment.yaml</code> :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: l03p02-app\n    app.kubernetes.io/instance: l03p02\n  name: l03p02-app\n  namespace: l03p02\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: l03p02-quarkus-aap\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app: l03p02-quarkus-aap\n    spec:\n      containers:\n      - args:\n        - -c\n        - echo hello from neutron IT; while true; do sleep 10; done\n        command:\n        - /bin/bash\n        image: registry.access.redhat.com/ubi8/ubi:latest\n        name: quarkus-container\nstatus:\n  availableReplicas: 1\n  conditions:\n  - lastTransitionTime: \"2024-07-22T15:46:57Z\"\n    lastUpdateTime: \"2024-07-22T15:46:57Z\"\n    message: Deployment has minimum availability.\n    reason: MinimumReplicasAvailable\n    status: \"True\"\n    type: Available\n</code></pre>"},{"location":"02_Interface_et_ligne_de_commande/03_Exercice_guid%C3%A9_Examen_des_ressources_Kubernetes/#etape-3-modification-du-manifeste-yaml","title":"\u00c9tape 3 : Modification du Manifeste YAML","text":"<p>Ouvrez le fichier <code>deployment.yaml</code> dans un votre terminal et apportez les modifications suivantes :</p> <ol> <li><code>shell vi deployment.yaml</code></li> <li>Enlevez toutes les metadata sauf \"name\" et \"namespace\"</li> <li>Changez le nom du d\u00e9ploiement \u00e0 <code>&lt;YOUR-CITY&gt;-l03p02-app</code>.</li> <li>Changez le nom du namespace <code>&lt;YOUR-CITY&gt;-user-ns</code>.</li> <li>Supprimez le champ <code>status</code> entier.</li> </ol> <p>Manifeste YAML modifi\u00e9 :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: &lt;YOUR-CITY&gt;-l03p02-app # prague-l03p02-app\n  namespace: &lt;YOUR-CITY&gt;-user-ns # prague-user-ns\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: l03p02-quarkus-aap\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app: l03p02-quarkus-aap\n    spec:\n      containers:\n      - args:\n        - -c\n        - echo hello from neutron IT; while true; do sleep 10; done\n        command:\n        - /bin/bash\n        image: registry.access.redhat.com/ubi8/ubi:latest\n        name: quarkus-container\n</code></pre>"},{"location":"02_Interface_et_ligne_de_commande/03_Exercice_guid%C3%A9_Examen_des_ressources_Kubernetes/#etape-4-application-du-manifeste-modifie","title":"\u00c9tape 4 : Application du Manifeste Modifi\u00e9","text":"<p>Appliquez le fichier modifi\u00e9 au cluster en utilisant la commande suivante :</p> <pre><code>oc apply -f deployment.yaml\n</code></pre> <p></p> <p>Cette commande cr\u00e9era un nouveau d\u00e9ploiement nomm\u00e9 <code>prague-l03p02-app</code> avec la configuration sp\u00e9cifi\u00e9e.</p>"},{"location":"02_Interface_et_ligne_de_commande/03_Exercice_guid%C3%A9_Examen_des_ressources_Kubernetes/#conclusion","title":"Conclusion","text":"<p>Dans cet exercice, nous avons appris \u00e0 examiner les ressources Kubernetes en utilisant des formats de sortie personnalis\u00e9s pour extraire des informations sp\u00e9cifiques. Nous avons \u00e9galement extrait un manifeste YAML, modifi\u00e9 ses champs, et appliqu\u00e9 ces modifications au cluster. Ces comp\u00e9tences sont essentielles pour g\u00e9rer et interroger efficacement les ressources Kubernetes dans OpenShift.</p>"},{"location":"02_Interface_et_ligne_de_commande/04_R%C3%A9sum%C3%A9/","title":"R\u00e9sum\u00e9","text":"<p>Dans cette partie, le formateur fera une synth\u00e8se de tout ce qui a \u00e9t\u00e9 vu dans les parties pr\u00e9c\u00e9dentes. Ce sera l'occasion de revoir les points cl\u00e9s, de clarifier les concepts abord\u00e9s et de s'assurer que tous les participants ont bien assimil\u00e9 le contenu.</p> <p>C'est \u00e9galement le moment id\u00e9al pour poser toutes les questions que vous pourriez avoir. Rappelez-vous que m\u00eame les questions qui peuvent sembler simples ou \u00e9videntes sont importantes. Alors, ne soyez pas timide : comme on dit, il n'y a pas de questions b\u00eates, seulement des r\u00e9ponses... parfois un peu longues !</p> <p></p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/00_Les_Workloads_dans_Openshift/","title":"Les Workloads dans OpenShift","text":"<p>Dans cette section, nous allons explorer les diff\u00e9rents types de workloads dans OpenShift. OpenShift offre plusieurs types de ressources pour g\u00e9rer et d\u00e9ployer des applications. Ces ressources, appel\u00e9es workloads, sont essentielles pour orchestrer et maintenir les applications en production.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/00_Les_Workloads_dans_Openshift/#objectifs-de-la-section","title":"Objectifs de la Section","text":"<p>L'objectif principal est de comprendre les diff\u00e9rents types de workloads dans OpenShift, notamment les d\u00e9ploiements, les configurations de d\u00e9ploiement, les r\u00e9plicas, les ensembles de r\u00e9plicas, les daemonset et les statefulset. Nous allons \u00e9galement illustrer les concepts et les diff\u00e9rences entre ces ressources et apprendre \u00e0 les utiliser pour g\u00e9rer des applications dans un cluster OpenShift.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/00_Les_Workloads_dans_Openshift/#deployments","title":"Deployments","text":"<p>Les d\u00e9ploiements sont une ressource Kubernetes qui g\u00e8re la mise \u00e0 jour d\u00e9clarative des applications. Ils permettent de d\u00e9crire l'\u00e9tat souhait\u00e9 pour vos pods et r\u00e9plicas, et le contr\u00f4leur de d\u00e9ploiement ajuste l'\u00e9tat r\u00e9el pour correspondre \u00e0 cet \u00e9tat souhait\u00e9.</p> <p>Les d\u00e9ploiements offrent plusieurs fonctionnalit\u00e9s cl\u00e9s. Ils permettent l'utilisation de diff\u00e9rentes strat\u00e9gies de d\u00e9ploiement, telles que les d\u00e9ploiements en rollout et les d\u00e9ploiements de recr\u00e9ation, pour minimiser les temps d'arr\u00eat. En cas de probl\u00e8me, ils permettent des rollbacks faciles \u00e0 une version pr\u00e9c\u00e9dente. De plus, les mises \u00e0 jour progressives des pods assurent que l'application reste disponible pendant les mises \u00e0 jour.</p> <p></p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/00_Les_Workloads_dans_Openshift/#deploymentconfig","title":"DeploymentConfig","text":"<p>Les <code>DeploymentConfig</code> sont sp\u00e9cifiques \u00e0 OpenShift et offrent des fonctionnalit\u00e9s avanc\u00e9es pour le d\u00e9ploiement d'applications. Ces configurations permettent d'utiliser des triggers bas\u00e9s sur les modifications d'image, de configuration, etc. Cela permet de d\u00e9clencher automatiquement un nouveau d\u00e9ploiement lorsqu'une image ou une configuration est mise \u00e0 jour. De plus, les strat\u00e9gies de d\u00e9ploiement sont personnalisables selon les besoins sp\u00e9cifiques de l'application.</p> <p>Tandis que les d\u00e9ploiements et les configurations de d\u00e9ploiement se concentrent sur la gestion des versions des applications, les r\u00e9plicas et les ensembles de r\u00e9plicas jouent un r\u00f4le crucial dans la gestion de la disponibilit\u00e9 des pods.</p> <p>NOTE: Les deploymentConfig sont maintenant deprecated et seront supprim\u00e9 dans une prochaine version d'Openshift</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/00_Les_Workloads_dans_Openshift/#replicas","title":"Replicas","text":"<p>Les r\u00e9plicas garantissent qu'un nombre sp\u00e9cifi\u00e9 de pods est en cours d'ex\u00e9cution \u00e0 tout moment. Ils sont une partie int\u00e9grante des d\u00e9ploiements et des ensembles de r\u00e9plicas. Cette fonctionnalit\u00e9 est essentielle pour assurer la scalabilit\u00e9 de l'application, en permettant d'ajuster le nombre de r\u00e9plicas en fonction de la charge. Elle assure \u00e9galement une tol\u00e9rance aux pannes, en maintenant un certain nombre de pods en cours d'ex\u00e9cution m\u00eame en cas de d\u00e9faillance de certains d'entre eux.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/00_Les_Workloads_dans_Openshift/#replicasets","title":"ReplicaSets","text":"<p>Les <code>ReplicaSets</code> s'assurent qu'un nombre sp\u00e9cifi\u00e9 de r\u00e9plicas d'un pod est en cours d'ex\u00e9cution \u00e0 tout moment. Ils remplacent les <code>ReplicationControllers</code> et sont souvent utilis\u00e9s par les d\u00e9ploiements pour g\u00e9rer les r\u00e9plicas. Les <code>ReplicaSets</code> utilisent des s\u00e9lecteurs de pods pour g\u00e9rer quels pods sont surveill\u00e9s et maintenus, assurant ainsi que le bon nombre de r\u00e9plicas est toujours en cours d'ex\u00e9cution.</p> <p>Les ensembles de r\u00e9plicas sont utiles pour maintenir des instances de pods, mais qu'en est-il des applications n\u00e9cessitant un pod par n\u0153ud ? C'est l\u00e0 que les DaemonSets entrent en jeu.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/00_Les_Workloads_dans_Openshift/#daemonsets","title":"DaemonSets","text":"<p>Les <code>DaemonSets</code> garantissent qu'une copie d'un pod tourne sur chaque n\u0153ud (ou un sous-ensemble de n\u0153uds) dans le cluster. Cette fonctionnalit\u00e9 est particuli\u00e8rement utile pour des t\u00e2ches telles que le monitoring ou la gestion des logs, o\u00f9 chaque n\u0153ud doit ex\u00e9cuter un pod sp\u00e9cifique. Les DaemonSets simplifient la gestion en assurant une pr\u00e9sence uniforme des pods sur les n\u0153uds requis.</p> <p>Alors que les DaemonSets assurent une copie de pod par n\u0153ud, certaines applications n\u00e9cessitent un \u00e9tat persistant entre les r\u00e9plicas. C'est l\u00e0 que les StatefulSets interviennent.</p> <p></p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/00_Les_Workloads_dans_Openshift/#statefulsets","title":"StatefulSets","text":"<p>Les <code>StatefulSets</code> sont utilis\u00e9s pour d\u00e9ployer et g\u00e9rer des applications avec un \u00e9tat persistant, telles que des bases de donn\u00e9es. Ils offrent plusieurs fonctionnalit\u00e9s importantes. Chaque pod dans un StatefulSet a un identifiant unique et stable, ce qui est essentiel pour des applications qui n\u00e9cessitent une identit\u00e9 stable. De plus, les StatefulSets g\u00e8rent le stockage persistant en associant des volumes persistants sp\u00e9cifiques aux pods. Enfin, ils assurent une mise \u00e0 jour et un scaling contr\u00f4l\u00e9s, garantissant une s\u00e9quence ordonn\u00e9e pour le d\u00e9ploiement, la mise \u00e0 jour et la suppression des pods.</p> <p></p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/00_Les_Workloads_dans_Openshift/#tableau-recapitulatif","title":"Tableau r\u00e9capitulatif","text":"Objet Description Utilisation principale Pod Unit\u00e9 de base de d\u00e9ploiement avec un ou plusieurs conteneurs. Ex\u00e9cution directe des conteneurs. StatefulSet Contr\u00f4leur pour applications stateful avec ordonnancement et stockage stable. Bases de donn\u00e9es, syst\u00e8mes distribu\u00e9s en cluster. DaemonSet Contr\u00f4leur pour assurer qu'un Pod est ex\u00e9cut\u00e9 sur chaque n\u0153ud. Agents de logs, collecteurs de m\u00e9triques, outils de s\u00e9curit\u00e9. ReplicaSet Contr\u00f4leur pour garantir un nombre sp\u00e9cifi\u00e9 de r\u00e9pliques de Pods. Maintien d'un nombre fixe de Pods. Deployment Contr\u00f4leur pour d\u00e9ploiements d\u00e9claratifs avec mise \u00e0 jour et rollback. D\u00e9ploiement et mise \u00e0 jour d'applications. DeploymentConfig Objet OpenShift pour d\u00e9ploiements avec strat\u00e9gies et hooks suppl\u00e9mentaires. D\u00e9ploiement d'applications avec contr\u00f4le et flexibilit\u00e9 avanc\u00e9s. <p>Chaque type de contr\u00f4leur a des cas d'utilisation sp\u00e9cifiques et offre diff\u00e9rents niveaux de gestion et de flexibilit\u00e9 pour le d\u00e9ploiement et la gestion des applications conteneuris\u00e9es dans un cluster Kubernetes.</p> <p></p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/00_Les_Workloads_dans_Openshift/#conclusion","title":"Conclusion","text":"<p>Dans cette section, nous avons explor\u00e9 les diff\u00e9rents types de workloads dans OpenShift, en mettant l'accent sur les d\u00e9ploiements, les configurations de d\u00e9ploiement, les r\u00e9plicas, les ensembles de r\u00e9plicas, les ensembles de d\u00e9mons et les ensembles avec \u00e9tat. Comprendre et ma\u00eetriser ces concepts est crucial pour administrer et d\u00e9ployer des applications robustes et \u00e9volutives dans un environnement OpenShift.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/01_Quiz_Les_Workloads_dans_Openshift/","title":"Quiz : les Workloads dans Openshift","text":"<p>Nous allons maintenant faire un quiz pour \u00e9valuer votre compr\u00e9hension de la partie \"Les Workloads dans Openshift\". Ce quiz couvrira les concepts fondamentaux abord\u00e9s, tels que les conteneurs, Kubernetes et les sp\u00e9cificit\u00e9s d'OpenShift.</p> <p>Pour joindre le quiz, veuillez suivre les \u00e9tapes suivantes :</p> <ol> <li> <p>Ouvrez l'application Quizizz sur votre appareil ou rendez-vous sur : https://quizizz.com/join.</p> </li> <li> <p>Entrez le num\u00e9ro fourni par l'instructeur pour acc\u00e9der au quiz.</p> </li> </ol> <p></p> <p>Bonne chance \u00e0 tous !</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/02_Les_deployment_et_les_daemonset/","title":"D\u00e9ploiements et DaemonSets dans OpenShift","text":""},{"location":"03_Executez_des_applications_conteneuris%C3%A9/02_Les_deployment_et_les_daemonset/#introduction","title":"Introduction","text":"<p>Les d\u00e9ploiements et les DaemonSets sont des composantes essentielles de la gestion des applications conteneuris\u00e9es dans OpenShift. Tandis que les d\u00e9ploiements permettent de d\u00e9ployer, mettre \u00e0 jour et g\u00e9rer les applications de mani\u00e8re d\u00e9clarative, les DaemonSets assurent qu'un pod sp\u00e9cifique est ex\u00e9cut\u00e9 sur chaque n\u0153ud du cluster. Comprendre comment fonctionnent ces deux concepts dans OpenShift est crucial pour assurer la stabilit\u00e9, la scalabilit\u00e9 et la continuit\u00e9 des services.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/02_Les_deployment_et_les_daemonset/#objectifs-de-la-section","title":"Objectifs de la Section","text":"<p>L'objectif principal de cette section est d'explorer en profondeur les d\u00e9ploiements et les DaemonSets dans OpenShift. Nous allons d\u00e9couvrir comment ils fonctionnent, leurs fonctionnalit\u00e9s cl\u00e9s, et comment les utiliser efficacement pour g\u00e9rer des applications en production. \u00c0 la fin de cette section, vous devriez \u00eatre capable de : - Comprendre les concepts fondamentaux des d\u00e9ploiements et des DaemonSets. - Utiliser diff\u00e9rentes strat\u00e9gies de d\u00e9ploiement. - Cr\u00e9er et g\u00e9rer des DaemonSets. - Maintenir la disponibilit\u00e9 des applications et des t\u00e2ches critiques pendant les mises \u00e0 jour.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/02_Les_deployment_et_les_daemonset/#les-deploiements-dans-openshift","title":"Les D\u00e9ploiements dans OpenShift","text":""},{"location":"03_Executez_des_applications_conteneuris%C3%A9/02_Les_deployment_et_les_daemonset/#concepts-fondamentaux","title":"Concepts Fondamentaux","text":"<p>Les d\u00e9ploiements dans OpenShift, comme dans Kubernetes, sont des ressources d\u00e9claratives qui g\u00e8rent la mise \u00e0 jour des applications. Ils permettent aux utilisateurs de sp\u00e9cifier l'\u00e9tat souhait\u00e9 des applications, et le contr\u00f4leur de d\u00e9ploiement s'assure que l'\u00e9tat r\u00e9el des pods et des r\u00e9plicas correspond \u00e0 cet \u00e9tat souhait\u00e9.</p> <p>Un d\u00e9ploiement se compose de plusieurs \u00e9l\u00e9ments essentiels : - Template de Pod : D\u00e9crit les conteneurs \u00e0 ex\u00e9cuter, leurs images, ressources, et autres configurations. - Strat\u00e9gies de D\u00e9ploiement : D\u00e9terminent comment les mises \u00e0 jour des applications doivent \u00eatre effectu\u00e9es.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/02_Les_deployment_et_les_daemonset/#structure-dun-template-de-pod","title":"Structure d'un Template de Pod","text":"<p>Le template de pod est une section cruciale d'un manifest de d\u00e9ploiement. Il d\u00e9finit la configuration des pods \u00e0 d\u00e9ployer, y compris les conteneurs, les volumes, les variables d'environnement, et d'autres sp\u00e9cifications n\u00e9cessaires pour le bon fonctionnement de l'application.</p> <pre><code>template:\n  metadata:\n    labels:\n      app: my-app\n  spec:\n    containers:\n    - name: my-container\n      image: my-image:latest\n      ports:\n      - containerPort: 8080\n      resources:\n        requests:\n          memory: \"64Mi\"\n          cpu: \"250m\"\n        limits:\n          memory: \"128Mi\"\n          cpu: \"500m\"\n      env:\n      - name: ENV_VAR\n        value: \"value\"\n</code></pre> <p>Dans cet exemple, le template de pod sp\u00e9cifie un conteneur nomm\u00e9 <code>my-container</code> utilisant l'image <code>my-image:latest</code>. Le conteneur expose le port 8080 et a des ressources demand\u00e9es et limit\u00e9es pour la m\u00e9moire et le CPU. Une variable d'environnement <code>ENV_VAR</code> est \u00e9galement d\u00e9finie.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/02_Les_deployment_et_les_daemonset/#strategies-de-deploiement","title":"Strat\u00e9gies de D\u00e9ploiement","text":"<p>Les d\u00e9ploiements dans OpenShift offrent plusieurs strat\u00e9gies pour mettre \u00e0 jour les applications, chacune ayant ses avantages selon les besoins sp\u00e9cifiques :</p> <ol> <li>Rolling Updates :</li> <li>Description : Met \u00e0 jour progressivement les pods de l'application, en rempla\u00e7ant petit \u00e0 petit les anciens pods par les nouveaux.</li> <li>Avantages : Minimisation des temps d'arr\u00eat, maintien de la disponibilit\u00e9 de l'application.</li> <li> <p>Utilisation : Id\u00e9ale pour les mises \u00e0 jour incr\u00e9mentales sans interruption de service.</p> </li> <li> <p>Recreate :</p> </li> <li>Description : Arr\u00eate tous les pods existants avant de cr\u00e9er les nouveaux pods.</li> <li>Avantages : Simplicit\u00e9, utilisation dans les cas o\u00f9 les mises \u00e0 jour en place ne sont pas possibles.</li> <li>Utilisation : Adapt\u00e9e pour les mises \u00e0 jour majeures o\u00f9 une interruption temporaire est acceptable.</li> </ol>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/02_Les_deployment_et_les_daemonset/#exemple-de-manifest-de-deploiement","title":"Exemple de Manifest de D\u00e9ploiement","text":"<p>Voici un exemple complet de manifest de d\u00e9ploiement pour une application simple :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\n  labels:\n    app: my-app\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-container\n        image: my-image:latest\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            memory: \"64Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"128Mi\"\n            cpu: \"500m\"\n        env:\n        - name: ENV_VAR\n          value: \"value\"\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 1\n</code></pre> <p>Ce manifest de d\u00e9ploiement cr\u00e9e un d\u00e9ploiement nomm\u00e9 <code>my-deployment</code>, avec trois r\u00e9plicas de <code>my-container</code> utilisant l'image <code>my-image:latest</code>. La strat\u00e9gie de d\u00e9ploiement utilis\u00e9e est <code>RollingUpdate</code>, avec un maximum de 1 pod suppl\u00e9mentaire et 1 pod indisponible pendant la mise \u00e0 jour.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/02_Les_deployment_et_les_daemonset/#declencher-une-mise-a-jour","title":"D\u00e9clencher une Mise \u00e0 Jour","text":"<p>Pour d\u00e9clencher une mise \u00e0 jour d'un d\u00e9ploiement dans OpenShift, vous pouvez modifier l'image du conteneur ou d'autres param\u00e8tres dans le template de pod, puis appliquer ces modifications. Par exemple, pour mettre \u00e0 jour l'image du conteneur, vous pouvez ex\u00e9cuter la commande suivante :</p> <pre><code>oc set image deployment/my-deployment my-container=my-image:new-version\n</code></pre> <p>Cette commande met \u00e0 jour l'image de <code>my-container</code> dans le d\u00e9ploiement <code>my-deployment</code> avec <code>my-image:new-version</code>. Le contr\u00f4leur de d\u00e9ploiement commencera alors une mise \u00e0 jour progressive des pods selon la strat\u00e9gie sp\u00e9cifi\u00e9e (par exemple, RollingUpdate).</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/02_Les_deployment_et_les_daemonset/#declencher-un-rollback","title":"D\u00e9clencher un Rollback","text":"<p>En cas de probl\u00e8me avec une mise \u00e0 jour, OpenShift permet de revenir rapidement \u00e0 une version pr\u00e9c\u00e9dente du d\u00e9ploiement. Pour d\u00e9clencher un rollback, utilisez la commande suivante :</p> <pre><code>oc rollout undo deployment/my-deployment\n</code></pre> <p>Cette commande restaure le d\u00e9ploiement <code>my-deployment</code> \u00e0 la version pr\u00e9c\u00e9dente connue comme \u00e9tant stable. Le contr\u00f4leur de d\u00e9ploiement remplacera les pods actuels par ceux d\u00e9finis dans la configuration pr\u00e9c\u00e9dente.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/02_Les_deployment_et_les_daemonset/#maintien-de-la-disponibilite","title":"Maintien de la Disponibilit\u00e9","text":"<p>Les d\u00e9ploiements sont con\u00e7us pour maintenir la disponibilit\u00e9 des applications pendant les mises \u00e0 jour. Gr\u00e2ce aux strat\u00e9gies de d\u00e9ploiement comme les rolling updates, OpenShift s'assure que de nouvelles instances de pods sont cr\u00e9\u00e9es avant que les anciennes soient supprim\u00e9es, garantissant ainsi que l'application reste accessible aux utilisateurs pendant toute la dur\u00e9e de la mise \u00e0 jour.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/02_Les_deployment_et_les_daemonset/#les-daemonsets-dans-openshift","title":"Les DaemonSets dans OpenShift","text":""},{"location":"03_Executez_des_applications_conteneuris%C3%A9/02_Les_deployment_et_les_daemonset/#concepts-fondamentaux_1","title":"Concepts Fondamentaux","text":"<p>Les DaemonSets dans OpenShift, comme dans Kubernetes, sont des ressources d\u00e9claratives qui s'assurent qu'un pod sp\u00e9cifique est ex\u00e9cut\u00e9 sur tous (ou certains) n\u0153uds d'un cluster.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/02_Les_deployment_et_les_daemonset/#specificites-par-rapport-aux-deploiements","title":"Sp\u00e9cificit\u00e9s par Rapport aux D\u00e9ploiements","text":"<p>Les DaemonSets diff\u00e8rent des d\u00e9ploiements de plusieurs fa\u00e7ons : - Ciblage des N\u0153uds : Les DaemonSets s'assurent qu'un pod est ex\u00e9cut\u00e9 sur chaque n\u0153ud sp\u00e9cifi\u00e9, tandis que les d\u00e9ploiements g\u00e8rent la scalabilit\u00e9 des pods sans garantie de couverture sur tous les n\u0153uds. - Scalabilit\u00e9 : Les DaemonSets ne g\u00e8rent pas la scalabilit\u00e9 de la m\u00eame mani\u00e8re que les d\u00e9ploiements. Ils se concentrent sur l'ex\u00e9cution d'un pod par n\u0153ud. - Mises \u00e0 Jour : Les mises \u00e0 jour des DaemonSets sont appliqu\u00e9es de mani\u00e8re contr\u00f4l\u00e9e pour minimiser les interruptions sur chaque n\u0153ud. - Tol\u00e9rance aux Pannes : Les DaemonSets sont utilis\u00e9s pour des t\u00e2ches qui n\u00e9cessitent une haute disponibilit\u00e9 et tol\u00e9rance aux pannes \u00e0 l'\u00e9chelle des n\u0153uds.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/02_Les_deployment_et_les_daemonset/#exemple-de-manifest-de-daemonset","title":"Exemple de Manifest de DaemonSet","text":"<p>Voici un exemple complet de manifest de DaemonSet pour une application simple :</p> <pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: my-daemonset\n  labels:\n    app: my-daemon\nspec:\n  selector:\n    matchLabels:\n      app: my-daemon\n  template:\n    metadata:\n      labels:\n        app: my-daemon\n    spec:\n      containers:\n      - name: my-container\n        image: my-image:latest\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            memory: \"64Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"128Mi\"\n            cpu: \"500m\"\n        env:\n        - name: ENV_VAR\n          value: \"value\"\n</code></pre> <p>Ce manifest de DaemonSet cr\u00e9e un DaemonSet nomm\u00e9 <code>my-daemonset</code>, d\u00e9ployant un pod <code>my-container</code> sur chaque n\u0153ud du cluster utilisant l'image <code>my-image:latest</code>.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/02_Les_deployment_et_les_daemonset/#cas-dutilisation-des-daemonsets","title":"Cas d'Utilisation des DaemonSets","text":"<p>Les DaemonSets sont utilis\u00e9s dans des sc\u00e9narios sp\u00e9cifiques o\u00f9 il est crucial</p> <p>que des t\u00e2ches soient ex\u00e9cut\u00e9es sur chaque n\u0153ud. Voici quelques cas d'utilisation courants : - Monitoring des N\u0153uds : Utilisation de DaemonSets pour d\u00e9ployer des agents de monitoring comme Prometheus Node Exporter sur chaque n\u0153ud pour collecter des m\u00e9triques. - Collecte de Logs : D\u00e9ploiement de collecteurs de logs comme Fluentd ou Logstash pour centraliser les logs des n\u0153uds et des applications. - Configuration de R\u00e9seau : Utilisation de DaemonSets pour configurer des r\u00e9seaux avec des outils comme Calico ou Weave sur chaque n\u0153ud. - S\u00e9curit\u00e9 : D\u00e9ploiement d'outils de s\u00e9curit\u00e9 comme Falco ou d'autres syst\u00e8mes de d\u00e9tection d'intrusion pour surveiller et s\u00e9curiser chaque n\u0153ud.</p> <p></p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/02_Les_deployment_et_les_daemonset/#conclusion","title":"Conclusion","text":"<p>Les d\u00e9ploiements et les DaemonSets dans OpenShift jouent des r\u00f4les cruciaux dans la gestion efficace des applications et des t\u00e2ches critiques \u00e0 l'\u00e9chelle des n\u0153uds du cluster. En offrant des strat\u00e9gies de d\u00e9ploiement flexibles et des m\u00e9canismes robustes pour les mises \u00e0 jour et les rollbacks, OpenShift permet de maintenir la continuit\u00e9 des services et de r\u00e9duire les temps d'arr\u00eat. Ma\u00eetriser ces concepts vous permettra d'assurer une gestion fluide et stable de vos applications en production, contribuant ainsi \u00e0 la r\u00e9silience et \u00e0 la fiabilit\u00e9 de vos syst\u00e8mes.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/03_Exercice_guid%C3%A9_Les_deployment_et_les_daemonset/","title":"Exercice Guid\u00e9 : Les d\u00e9ploiements et les daemonset dans OpenShift","text":"<p>Dans cet exercice, vous allez cr\u00e9er un d\u00e9ploiement dans OpenShift et tester une strat\u00e9gie de d\u00e9ploiement en Rolling Updates. Suivez les \u00e9tapes ci-dessous pour mettre en pratique les concepts th\u00e9oriques que nous avons abord\u00e9s.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/03_Exercice_guid%C3%A9_Les_deployment_et_les_daemonset/#objectifs-de-lexercice","title":"Objectifs de l'Exercice","text":"<ul> <li>Cr\u00e9er un d\u00e9ploiement dans OpenShift.</li> <li>Appliquer une strat\u00e9gie de d\u00e9ploiement en Rolling Updates.</li> <li>Mettre \u00e0 jour l'application et observer le processus de d\u00e9ploiement.</li> <li>D\u00e9clencher un rollback en cas de probl\u00e8me.</li> </ul>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/03_Exercice_guid%C3%A9_Les_deployment_et_les_daemonset/#prerequis","title":"Pr\u00e9requis","text":"<p>Assurez-vous d'avoir acc\u00e8s \u00e0 un cluster OpenShift et les permissions n\u00e9cessaires pour cr\u00e9er des d\u00e9ploiements. Vous devez \u00e9galement avoir la CLI <code>oc</code> install\u00e9e sur votre machine.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/03_Exercice_guid%C3%A9_Les_deployment_et_les_daemonset/#etape-1-creer-un-deploiement","title":"\u00c9tape 1 : Cr\u00e9er un D\u00e9ploiement","text":"<p>Cr\u00e9ez un fichier nomm\u00e9 <code>my-deployment.yaml</code> avec le contenu suivant :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\n  labels:\n    app: my-app\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-container\n        image: registry.access.redhat.com/ubi9/httpd-24:1-3\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            memory: \"64Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"128Mi\"\n            cpu: \"500m\"\n        env:\n        - name: ENV_VAR\n          value: \"value\"\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 1\n</code></pre> <p>Ce fichier YAML d\u00e9finit un d\u00e9ploiement nomm\u00e9 <code>my-deployment</code> avec 3 r\u00e9plicas d'un conteneur Httpd. La strat\u00e9gie de d\u00e9ploiement est configur\u00e9e pour utiliser Rolling Updates.</p> <p>Appliquez ce d\u00e9ploiement avec la commande suivante :</p> <pre><code>oc apply -f my-deployment.yaml\n</code></pre>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/03_Exercice_guid%C3%A9_Les_deployment_et_les_daemonset/#etape-2-verifier-le-deploiement","title":"\u00c9tape 2 : V\u00e9rifier le D\u00e9ploiement","text":"<p>V\u00e9rifiez que le d\u00e9ploiement a \u00e9t\u00e9 cr\u00e9\u00e9 et que les pods sont en cours d'ex\u00e9cution :</p> <pre><code>oc get deployments\noc get pods\n</code></pre> <p>Vous devriez voir le d\u00e9ploiement <code>my-deployment</code> et trois pods en cours d'ex\u00e9cution.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/03_Exercice_guid%C3%A9_Les_deployment_et_les_daemonset/#etape-3-mettre-a-jour-lapplication-et-observer-le-rolling-update","title":"\u00c9tape 3 : Mettre \u00e0 Jour l'Application et Observer le Rolling Update","text":"<p>Pour simuler une mise \u00e0 jour de l'application, nous allons changer l'image utilis\u00e9e par le conteneur. Avant cela rendez vous dans la console dans la section Deployment et cliquez sur <code>my-deployment</code>.</p> <p></p> <p>Ex\u00e9cutez la commande suivante pour mettre \u00e0 jour l'image du conteneur :</p> <pre><code>oc set image deployment/my-deployment my-container=registry.access.redhat.com/ubi9/httpd-24:1-325\n</code></pre> <p>Vous deriez alors pouvoir observer le rollout dans la console.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/03_Exercice_guid%C3%A9_Les_deployment_et_les_daemonset/#etape-4-declencher-un-rollback","title":"\u00c9tape 4 : D\u00e9clencher un Rollback","text":"<p>Si quelque chose ne va pas avec la mise \u00e0 jour, vous pouvez revenir \u00e0 la version pr\u00e9c\u00e9dente du d\u00e9ploiement :</p> <pre><code>oc rollout undo deployment/my-deployment\n</code></pre> <p>Cette commande d\u00e9clenchera un rollback, et les pods seront remplac\u00e9s par ceux d\u00e9finis dans la configuration pr\u00e9c\u00e9dente.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/03_Exercice_guid%C3%A9_Les_deployment_et_les_daemonset/#etape-5-verifier-le-rollback","title":"\u00c9tape 5 : V\u00e9rifier le Rollback","text":"<p>Pour v\u00e9rifier que le rollback a bien fonctionn\u00e9, nous allons r\u00e9cup\u00e9rer l'image actuellement utilis\u00e9e par les pods et v\u00e9rifier qu'elle correspond bien \u00e0 l'ancienne version. Utilisez les commandes suivantes :</p> <ol> <li>V\u00e9rifiez le statut du d\u00e9ploiement :</li> </ol> <p><code>bash    oc rollout status deployment/my-deployment</code></p> <ol> <li>Listez les pods pour v\u00e9rifier qu'ils sont tous en cours d'ex\u00e9cution :</li> </ol> <p><code>bash    oc get pods</code></p> <ol> <li>R\u00e9cup\u00e9rez l'image actuellement utilis\u00e9e par le d\u00e9ploiement :</li> </ol> <p><code>bash    oc get deployment my-deployment -o jsonpath='{.spec.template.spec.containers[0].image}'</code></p> <p>Cette commande affichera l'image actuellement utilis\u00e9e par le d\u00e9ploiement. V\u00e9rifiez que cette image correspond \u00e0 l'ancienne version, qui est <code>registry.access.redhat.com/ubi9/httpd-24:1-331</code>.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/03_Exercice_guid%C3%A9_Les_deployment_et_les_daemonset/#conclusion","title":"Conclusion","text":"<p>En suivant ces \u00e9tapes, vous pouvez vous assurer que le rollback a bien fonctionn\u00e9 et que l'image du d\u00e9ploiement est revenue \u00e0 l'ancienne version. Cela compl\u00e8te votre exercice sur la gestion des d\u00e9ploiements et des rollbacks dans OpenShift.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/04_Les_statefulset/","title":"Les statefulSets","text":""},{"location":"03_Executez_des_applications_conteneuris%C3%A9/04_Les_statefulset/#objectifs-de-la-section","title":"Objectifs de la Section","text":"<p>\u00c0 la fin de cette section, vous serez capable de : 1. Comprendre ce qu'est un StatefulSet et comment il diff\u00e8re des autres types de contr\u00f4leurs Kubernetes tels que les Deployments. 2. Identifier les cas d'utilisation appropri\u00e9s pour les StatefulSets. 3. D\u00e9ployer et g\u00e9rer des applications stateful \u00e0 l'aide de StatefulSets. 4. Comprendre les concepts cl\u00e9s associ\u00e9s aux StatefulSets, tels que les noms stables, l'ordonnancement et les Persistent Volume Claims (PVC).</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/04_Les_statefulset/#statefulsets","title":"StatefulSets","text":""},{"location":"03_Executez_des_applications_conteneuris%C3%A9/04_Les_statefulset/#quest-ce-quun-statefulset","title":"Qu'est-ce qu'un StatefulSet ?","text":"<p>Un StatefulSet est un contr\u00f4leur Kubernetes utilis\u00e9 pour d\u00e9ployer et g\u00e9rer des applications stateful. Contrairement \u00e0 un Deployment, qui g\u00e8re des applications stateless en cr\u00e9ant et en supprimant des pods de mani\u00e8re indiff\u00e9rente, un StatefulSet assure que les pods conservent une identit\u00e9 stable et une persistance des donn\u00e9es.</p> <p></p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/04_Les_statefulset/#caracteristiques-cles-des-statefulsets","title":"Caract\u00e9ristiques Cl\u00e9s des StatefulSets","text":"<ol> <li>Noms Stables :</li> <li>Chaque pod dans un StatefulSet a un nom stable bas\u00e9 sur l'index de son ordinal. Par exemple, dans un StatefulSet nomm\u00e9 <code>web</code>, les pods seront nomm\u00e9s <code>web-0</code>, <code>web-1</code>, etc.</li> <li> <p>Cette stabilit\u00e9 permet aux applications de conserver une identit\u00e9 fixe, essentielle pour les applications stateful.</p> </li> <li> <p>Ordonnancement et D\u00e9ploiement S\u00e9quenciel :</p> </li> <li> <p>Les pods d'un StatefulSet sont cr\u00e9\u00e9s et supprim\u00e9s de mani\u00e8re ordonn\u00e9e, c'est-\u00e0-dire un par un, et dans un ordre d\u00e9termin\u00e9. Cela permet de g\u00e9rer les d\u00e9pendances entre les instances de l'application.</p> </li> <li> <p>Persistent Volume Claims (PVCs) :</p> </li> <li>Chaque pod d'un StatefulSet peut avoir son propre PVC, ce qui garantit que chaque instance de l'application conserve son propre stockage persistant.</li> <li>Cela permet de g\u00e9rer les donn\u00e9es de mani\u00e8re isol\u00e9e et ind\u00e9pendante pour chaque instance de l'application.</li> </ol>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/04_Les_statefulset/#cas-dutilisation-des-statefulsets","title":"Cas d'Utilisation des StatefulSets","text":"<ol> <li>Bases de Donn\u00e9es Distribu\u00e9es :</li> <li> <p>Les bases de donn\u00e9es comme Cassandra, MongoDB, et autres bases de donn\u00e9es NoSQL n\u00e9cessitent souvent une persistance des donn\u00e9es et une identit\u00e9 stable pour chaque n\u0153ud.</p> </li> <li> <p>Clusters de Bases de Donn\u00e9es Relationnelles :</p> </li> <li> <p>PostgreSQL, MySQL en mode cluster ou tout autre syst\u00e8me de bases de donn\u00e9es relationnelles n\u00e9cessitant une r\u00e9plication et une persistance des donn\u00e9es peut b\u00e9n\u00e9ficier de l'utilisation de StatefulSets.</p> </li> <li> <p>Applications avec R\u00e9plication de Donn\u00e9es :</p> </li> <li>Toute application n\u00e9cessitant une r\u00e9plication de donn\u00e9es entre ses instances, comme Elasticsearch ou Redis en mode cluster, b\u00e9n\u00e9ficiera des garanties fournies par les StatefulSets.</li> </ol>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/04_Les_statefulset/#exemple-de-deploiement-avec-statefulset","title":"Exemple de D\u00e9ploiement avec StatefulSet","text":""},{"location":"03_Executez_des_applications_conteneuris%C3%A9/04_Les_statefulset/#fichier-de-configuration-pour-un-statefulset-cassandra","title":"Fichier de Configuration pour un StatefulSet Cassandra","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: cassandra\n  labels:\n    app: cassandra\nspec:\n  ports:\n  - port: 9042\n  clusterIP: None\n  selector:\n    app: cassandra\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: cassandra\nspec:\n  serviceName: \"cassandra\"\n  replicas: 3\n  selector:\n    matchLabels:\n      app: cassandra\n  template:\n    metadata:\n      labels:\n        app: cassandra\n    spec:\n      containers:\n      - name: cassandra\n        image: cassandra:3.11\n        ports:\n        - containerPort: 9042\n        env:\n        - name: CASSANDRA_SEEDS\n          value: \"cassandra-0.cassandra.default.svc.cluster.local\"\n        - name: MAX_HEAP_SIZE\n          value: \"512M\"\n        - name: HEAP_NEWSIZE\n          value: \"100M\"\n        volumeMounts:\n        - name: cassandra-data\n          mountPath: /var/lib/cassandra\n  volumeClaimTemplates:\n  - metadata:\n      name: cassandra-data\n    spec:\n      accessModes: [ \"ReadWriteOnce\" ]\n      resources:\n        requests:\n          storage: 10Gi\n</code></pre>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/04_Les_statefulset/#analyse-et-avantages-des-statefulsets","title":"Analyse et Avantages des StatefulSets","text":"<ol> <li>Identit\u00e9 Stable :</li> <li> <p>Les pods conservent des noms stables, ce qui facilite le suivi et la gestion des instances.</p> </li> <li> <p>Persistance des Donn\u00e9es :</p> </li> <li> <p>Chaque pod a son propre PVC, garantissant que les donn\u00e9es sont conserv\u00e9es ind\u00e9pendamment du cycle de vie des pods.</p> </li> <li> <p>Ordonnancement Contr\u00f4l\u00e9 :</p> </li> <li>Les pods sont cr\u00e9\u00e9s et supprim\u00e9s de mani\u00e8re ordonn\u00e9e, ce qui est crucial pour les applications avec des d\u00e9pendances inter-instances.</li> </ol>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/04_Les_statefulset/#conclusion","title":"Conclusion","text":"<p>Les StatefulSets sont essentiels pour le d\u00e9ploiement et la gestion des applications stateful dans Kubernetes. Ils offrent des garanties et des fonctionnalit\u00e9s sp\u00e9ciales pour g\u00e9rer des identit\u00e9s stables, une persistance des donn\u00e9es et un ordonnancement s\u00e9quentiel, rendant possible le d\u00e9ploiement de bases de donn\u00e9es distribu\u00e9es et d'autres applications n\u00e9cessitant une gestion fine de l'\u00e9tat. En comprenant et en utilisant les StatefulSets, vous pouvez d\u00e9ployer des applications stateful de mani\u00e8re fiable et efficace dans votre cluster Kubernetes.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/05_Exercice_guid%C3%A9_Les_statefulset/","title":"Exercice Guid\u00e9: les StatefulSets avec MySQL","text":"<p>Dans cet exercice, nous allons d\u00e9ployer une base de donn\u00e9es MySQL \u00e0 l'aide d'un StatefulSet dans Openshift. Nous cr\u00e9erons deux r\u00e9plicas de la base de donn\u00e9es. Nous v\u00e9rifierons ensuite que chaque r\u00e9plique utilise un Persistent Volume Claim (PVC) distinct.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/05_Exercice_guid%C3%A9_Les_statefulset/#etape-1-creer-le-statefulset-mysql","title":"\u00c9tape 1 : Cr\u00e9er le StatefulSet MySQL","text":""},{"location":"03_Executez_des_applications_conteneuris%C3%A9/05_Exercice_guid%C3%A9_Les_statefulset/#11-creer-un-fichier-de-configuration-statefulset","title":"1.1. Cr\u00e9er un fichier de configuration StatefulSet","text":"<p>Cr\u00e9ez un fichier nomm\u00e9 <code>mysql-statefulset.yaml</code> avec le contenu suivant :</p> <pre><code>apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: mysql\nspec:\n  serviceName: \"mysql\"\n  replicas: 2\n  selector:\n    matchLabels:\n      app: mysql\n  template:\n    metadata:\n      labels:\n        app: mysql\n    spec:\n      containers:\n      - name: mysql\n        image: registry.redhat.io/rhel8/mysql-80\n        env:\n        - name: MYSQL_ROOT_PASSWORD\n          value: \"rootpassword\"\n        - name: MYSQL_DATABASE\n          value: \"mydb\"\n        - name: MYSQL_USER\n          value: \"user\"\n        - name: MYSQL_PASSWORD\n          value: \"password\"\n        ports:\n        - containerPort: 3306\n        volumeMounts:\n        - name: mysql-data\n          mountPath: /var/lib/mysql/data\n  volumeClaimTemplates:\n  - metadata:\n      name: mysql-data\n    spec:\n      accessModes: [ \"ReadWriteOnce\" ]\n      resources:\n        requests:\n          storage: 1Gi\n</code></pre>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/05_Exercice_guid%C3%A9_Les_statefulset/#12-appliquer-le-statefulset","title":"1.2. Appliquer le StatefulSet","text":"<p>Appliquez le fichier de configuration \u00e0 votre cluster Kubernetes en utilisant la commande suivante :</p> <pre><code>oc apply -f mysql-statefulset.yaml\n</code></pre>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/05_Exercice_guid%C3%A9_Les_statefulset/#verifier-les-pvcs","title":"V\u00e9rifier les PVCs","text":""},{"location":"03_Executez_des_applications_conteneuris%C3%A9/05_Exercice_guid%C3%A9_Les_statefulset/#21-listez-les-pods-et-les-pvcs-crees","title":"2.1. Listez les Pods et les PVCs cr\u00e9\u00e9s","text":"<p>Utilisez la commande suivante pour lister les Pods cr\u00e9\u00e9s par le StatefulSet :</p> <pre><code>oc get pod -l app=mysql\n</code></pre> <p>Vous devriez voir deux Pods <code>mysql-0</code> et <code>mysql-1</code>.</p> <pre><code>NAME      READY   STATUS    RESTARTS   AGE\nmysql-0   1/1     Running   0          8m59s\nmysql-1   1/1     Running   0          8m45s\n</code></pre> <p></p> <p>Utilisez la commande suivante pour lister les PVCs cr\u00e9\u00e9s par le StatefulSet :</p> <pre><code>oc get pvc\n</code></pre> <p>Vous devriez voir deux PVCs, un pour chaque r\u00e9plique de la base de donn\u00e9es MySQL (<code>mysql-data-mysql-0</code> et <code>mysql-data-mysql-1</code>).</p> <p></p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/05_Exercice_guid%C3%A9_Les_statefulset/#interagir-avec-les-bases-de-donnees","title":"Interagir avec les bases de donn\u00e9es","text":""},{"location":"03_Executez_des_applications_conteneuris%C3%A9/05_Exercice_guid%C3%A9_Les_statefulset/#31-se-connecter-au-premier-pod-mysql","title":"3.1. Se connecter au premier pod MySQL","text":"<p>Connectez-vous au premier pod (<code>mysql-0</code>) :</p> <pre><code>oc exec -it mysql-0 -- bash\n</code></pre> <p>Une fois connect\u00e9, acc\u00e9dez \u00e0 la base de donn\u00e9es MySQL :</p> <pre><code>mysql -u user -ppassword mydb\n</code></pre>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/05_Exercice_guid%C3%A9_Les_statefulset/#32-ecrire-des-donnees-dans-la-premiere-base-de-donnees","title":"3.2. \u00c9crire des donn\u00e9es dans la premi\u00e8re base de donn\u00e9es","text":"<p>Dans le shell MySQL, cr\u00e9ez une table et ins\u00e9rez des donn\u00e9es :</p> <pre><code>CREATE TABLE test_table (id INT PRIMARY KEY, data VARCHAR(50));\nINSERT INTO test_table (id, data) VALUES (1, 'Data from mysql-0');\nSELECT * FROM test_table;\n</code></pre> <p>Vous devriez voir les donn\u00e9es ins\u00e9r\u00e9es dans la table.</p> <pre><code>mysql&gt; SELECT * FROM test_table;\n+----+-------------------+\n| id | data              |\n+----+-------------------+\n|  1 | Data from mysql-0 |\n+----+-------------------+\n1 row in set (0.00 sec)\n</code></pre>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/05_Exercice_guid%C3%A9_Les_statefulset/#33-se-connecter-au-second-pod-mysql","title":"3.3. Se connecter au second pod MySQL","text":"<p>Ouvrez un autre terminal et connectez-vous au second pod (<code>mysql-1</code>) :</p> <pre><code>oc exec -it mysql-1 -- bash\n</code></pre> <p>Une fois connect\u00e9, acc\u00e9dez \u00e0 la base de donn\u00e9es MySQL :</p> <pre><code>mysql -u user -ppassword mydb\n</code></pre>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/05_Exercice_guid%C3%A9_Les_statefulset/#34-ecrire-des-donnees-dans-la-seconde-base-de-donnees","title":"3.4. \u00c9crire des donn\u00e9es dans la seconde base de donn\u00e9es","text":"<p>Dans le shell MySQL, cr\u00e9ez une table et ins\u00e9rez des donn\u00e9es :</p> <pre><code>CREATE TABLE test_table (id INT PRIMARY KEY, data VARCHAR(50));\nINSERT INTO test_table (id, data) VALUES (2, 'Data from mysql-1');\nSELECT * FROM test_table;\n</code></pre> <p>Vous devriez voir les donn\u00e9es ins\u00e9r\u00e9es dans la table.</p> <pre><code>mysql&gt; SELECT * FROM test_table;\n+----+-------------------+\n| id | data              |\n+----+-------------------+\n|  2 | Data from mysql-1 |\n+----+-------------------+\n1 row in set (0.00 sec)\n</code></pre>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/05_Exercice_guid%C3%A9_Les_statefulset/#etape-4-verifier-lindependance-des-donnees","title":"\u00c9tape 4 : V\u00e9rifier l'ind\u00e9pendance des donn\u00e9es","text":""},{"location":"03_Executez_des_applications_conteneuris%C3%A9/05_Exercice_guid%C3%A9_Les_statefulset/#41-verifier-les-donnees-dans-le-premier-pod","title":"4.1. V\u00e9rifier les donn\u00e9es dans le premier pod","text":"<p>Revenez au terminal connect\u00e9 \u00e0 <code>mysql-0</code> et v\u00e9rifiez les donn\u00e9es :</p> <pre><code>SELECT * FROM test_table;\n</code></pre> <p>Vous devriez voir uniquement les donn\u00e9es <code>Data from mysql-0</code>.</p> <pre><code>mysql&gt; SELECT * FROM test_table;\n+----+-------------------+\n| id | data              |\n+----+-------------------+\n|  1 | Data from mysql-0 |\n+----+-------------------+\n1 row in set (0.00 sec)\n</code></pre> <p>Pour sortir:</p> <pre><code>exit\nexit\n</code></pre>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/05_Exercice_guid%C3%A9_Les_statefulset/#conclusion","title":"Conclusion","text":"<p>Vous avez maintenant d\u00e9ploy\u00e9 une base de donn\u00e9es MySQL en utilisant un StatefulSet dans Kubernetes. Vous avez v\u00e9rifi\u00e9 que chaque r\u00e9plique utilise un PVC distinct et que les donn\u00e9es sont ind\u00e9pendantes entre les r\u00e9plicas. Cela d\u00e9montre l'utilit\u00e9 des StatefulSets pour g\u00e9rer des applications stateful n\u00e9cessitant une persistance des donn\u00e9es et une identit\u00e9 stable.</p>"},{"location":"03_Executez_des_applications_conteneuris%C3%A9/06_R%C3%A9sum%C3%A9/","title":"R\u00e9sum\u00e9","text":"<p>Dans cette partie, le formateur fera une synth\u00e8se de tout ce qui a \u00e9t\u00e9 vu dans les parties pr\u00e9c\u00e9dentes. Ce sera l'occasion de revoir les points cl\u00e9s, de clarifier les concepts abord\u00e9s et de s'assurer que tous les participants ont bien assimil\u00e9 le contenu.</p> <p>C'est \u00e9galement le moment id\u00e9al pour poser toutes les questions que vous pourriez avoir. Rappelez-vous que m\u00eame les questions qui peuvent sembler simples ou \u00e9videntes sont importantes. Alors, ne soyez pas timide : comme on dit, il n'y a pas de questions b\u00eates, seulement des r\u00e9ponses... parfois un peu longues !</p> <p></p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/","title":"Les r\u00e9seaux dans Openshift","text":"<p>Dans un environnement OpenShift, la gestion du r\u00e9seau est essentielle pour garantir une communication efficace et s\u00e9curis\u00e9e entre les diff\u00e9rents composants des applications d\u00e9ploy\u00e9es. Kubernetes impl\u00e9mente un R\u00e9seau D\u00e9fini par Logiciel (SDN) pour orchestrer cette infrastructure r\u00e9seau. Le SDN permet de cr\u00e9er un r\u00e9seau virtuel englobant tous les n\u0153uds du cluster, facilitant ainsi la communication inter-pods tout en maintenant un niveau \u00e9lev\u00e9 de s\u00e9curit\u00e9 et de gestion centralis\u00e9e. Ce cours approfondira les concepts, les fonctionnalit\u00e9s, et les avantages du SDN dans OpenShift, ainsi que les outils et commandes n\u00e9cessaires pour sa gestion.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#objectifs-de-la-section","title":"Objectifs de la section","text":"<ol> <li>Comprendre le concept de R\u00e9seau D\u00e9fini par Logiciel (SDN) dans OpenShift.</li> <li>Explorer les fonctionnalit\u00e9s et les avantages du SDN pour la gestion r\u00e9seau des clusters Kubernetes.</li> <li>Apprendre comment les diff\u00e9rents composants du SDN interagissent pour assurer la communication entre les pods.</li> <li>D\u00e9couvrir les outils et les commandes pour configurer et g\u00e9rer le SDN dans OpenShift.</li> <li>Examiner des cas d'utilisation pratiques et des sc\u00e9narios d'impl\u00e9mentation du SDN.</li> </ol>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#le-reseau-defini-par-logiciel-sdn-dans-openshift","title":"Le R\u00e9seau D\u00e9fini par Logiciel (SDN) dans OpenShift","text":""},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#1-quest-ce-que-le-sdn","title":"1. Qu'est-ce que le SDN ?","text":"<p>Le R\u00e9seau D\u00e9fini par Logiciel (SDN) est une approche permettant de g\u00e9rer les r\u00e9seaux de mani\u00e8re programm\u00e9e et centralis\u00e9e. Dans Kubernetes, le SDN cr\u00e9e un r\u00e9seau virtuel englobant tous les n\u0153uds du cluster, ce qui permet une communication efficace entre tous les pods. Ce r\u00e9seau virtuel est isol\u00e9, garantissant que seul le trafic interne au cluster est autoris\u00e9, ce qui am\u00e9liore la s\u00e9curit\u00e9.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#2-fonctionnement-du-sdn","title":"2. Fonctionnement du SDN","text":"<p>Le SDN dans OpenShift repose sur plusieurs concepts et composants cl\u00e9s :</p> <ul> <li>Abstraction des Couches R\u00e9seau : Le SDN permet d'abstraire les diff\u00e9rentes couches r\u00e9seau, simplifiant ainsi la gestion des services r\u00e9seau.</li> <li>R\u00e9seau Virtuel : Cr\u00e9e un r\u00e9seau virtuel qui englobe tous les n\u0153uds du cluster, facilitant la communication inter-pods.</li> <li>Isolation et S\u00e9curit\u00e9 : Assure une isolation r\u00e9seau entre les pods et les n\u0153uds, garantissant que le r\u00e9seau SDN n'est pas accessible depuis l'ext\u00e9rieur du cluster.</li> </ul>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#3-avantages-du-sdn","title":"3. Avantages du SDN","text":"<p>Le SDN offre de nombreux avantages pour la gestion r\u00e9seau des clusters Kubernetes :</p> <ul> <li>Gestion Centralis\u00e9e : Permet une gestion centralis\u00e9e du trafic r\u00e9seau et des ressources, simplifiant ainsi les op\u00e9rations r\u00e9seau.</li> <li>Scalabilit\u00e9 : Facilite la mise \u00e0 l'\u00e9chelle des applications en permettant l'ajout ou la suppression dynamique de pods.</li> <li>Isolation des Tenants : Assure une isolation efficace des diff\u00e9rents environnements de travail, permettant une meilleure s\u00e9curit\u00e9 et gestion des ressources.</li> </ul>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#fonctionnalites-du-reseau-kubernetes","title":"Fonctionnalit\u00e9s du R\u00e9seau Kubernetes","text":""},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#1-communications-de-conteneur-a-conteneur","title":"1. Communications de Conteneur \u00e0 Conteneur","text":"<p>Les conteneurs au sein d'un m\u00eame pod peuvent communiquer entre eux via l'adresse de bouclage <code>localhost</code>. Cela permet une int\u00e9gration transparente entre les services au sein d'un pod.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#2-communications-de-pod-a-pod","title":"2. Communications de Pod \u00e0 Pod","text":"<p>Kubernetes assigne une adresse IP unique \u00e0 chaque pod, ce qui permet une communication directe entre les pods sans n\u00e9cessiter de traduction d'adresse r\u00e9seau (NAT). Tous les pods peuvent communiquer entre eux, ind\u00e9pendamment de leur emplacement sur diff\u00e9rents n\u0153uds ou espaces de noms Kubernetes.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#3-communications-du-pod-vers-le-service","title":"3. Communications du Pod vers le Service","text":"<p>Les services Kubernetes fournissent des adresses IP stables et permanentes aux groupes de pods, permettant une communication fiable et \u00e9quilibr\u00e9e entre les pods. Les services agissent comme des \u00e9quilibreurs de charge virtuels, distribuant le trafic de mani\u00e8re transparente entre les pods associ\u00e9s.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#4-communication-externe-vers-le-service","title":"4. Communication Externe vers le Service","text":"<p>Les services Kubernetes permettent \u00e9galement l'acc\u00e8s externe aux pods via des adresses IP stables, ce qui est particuli\u00e8rement utile pour exposer des applications \u00e0 l'ext\u00e9rieur du cluster.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#utilisation-des-services-dans-kubernetes","title":"Utilisation des Services dans Kubernetes","text":""},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#1-stabilite-des-adresses-ip","title":"1. Stabilit\u00e9 des Adresses IP","text":"<p>Contrairement aux adresses IP des pods, qui sont \u00e9ph\u00e9m\u00e8res, les adresses IP des services sont stables. Cela permet aux applications de maintenir des connexions fiables, m\u00eame lorsque les pods sont red\u00e9marr\u00e9s ou replanifi\u00e9s.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#2-equilibrage-de-charge","title":"2. \u00c9quilibrage de Charge","text":"<p>Les services Kubernetes agissent comme des \u00e9quilibreurs de charge, r\u00e9partissant le trafic de mani\u00e8re \u00e9quilibr\u00e9e entre les pods associ\u00e9s. Cela am\u00e9liore la tol\u00e9rance aux pannes et la scalabilit\u00e9 des applications.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#3-decouverte-de-services","title":"3. D\u00e9couverte de Services","text":"<p>Kubernetes utilise un serveur DNS interne pour la d\u00e9couverte de services. Chaque service re\u00e7oit un nom de domaine complet (FQDN) qui permet aux pods de le d\u00e9couvrir et de communiquer avec lui de mani\u00e8re fiable.</p> <p></p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#composants-du-sdn","title":"Composants du SDN","text":""},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#1-plug-ins-cni-container-network-interface","title":"1. Plug-ins CNI (Container Network Interface)","text":"<p>Les plug-ins CNI fournissent une interface commune pour la configuration des r\u00e9seaux de conteneurs. OpenShift utilise diff\u00e9rents plug-ins comme OVN-Kubernetes, OpenShift SDN, et Kuryr pour g\u00e9rer le r\u00e9seau. Ces plug-ins permettent aux fournisseurs r\u00e9seau de proposer leurs solutions pour une gestion centralis\u00e9e, un routage dynamique, et l'isolation des tenants.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#2-ovn-kubernetes","title":"2. OVN-Kubernetes","text":"<p>OVN-Kubernetes est le fournisseur r\u00e9seau par d\u00e9faut dans OpenShift 4.12. Il utilise Open Virtual Network (OVN) pour g\u00e9rer le r\u00e9seau de clusters et ex\u00e9cute Open vSwitch (OVS) sur chaque n\u0153ud. OVN configure OVS pour impl\u00e9menter la configuration r\u00e9seau d\u00e9clar\u00e9e.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#3-operateur-de-reseau-de-clusters-cno","title":"3. Op\u00e9rateur de R\u00e9seau de Clusters (CNO)","text":"<p>L'Op\u00e9rateur de R\u00e9seau de Clusters (CNO) est un op\u00e9rateur de cluster OpenShift qui charge et configure les plug-ins CNI. Il permet de g\u00e9rer la configuration r\u00e9seau du cluster de mani\u00e8re centralis\u00e9e et d'assurer que les politiques r\u00e9seau sont correctement appliqu\u00e9es.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#autres-sdn-supportes-sur-openshift","title":"Autres SDN Support\u00e9s sur OpenShift","text":"<p>OpenShift supporte plusieurs impl\u00e9mentations SDN, chacune ayant ses propres caract\u00e9ristiques et avantages sp\u00e9cifiques. Voici un aper\u00e7u des principaux SDN support\u00e9s :</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#1-calico","title":"1. Calico","text":"<p>Calico est une solution de mise en r\u00e9seau et de s\u00e9curit\u00e9 pour les conteneurs, les machines virtuelles et les h\u00f4tes natifs. Il est particuli\u00e8rement appr\u00e9ci\u00e9 pour sa simplicit\u00e9 et son efficacit\u00e9 en termes de performance.</p> <ul> <li>Routage Pur IP : Utilise le routage IP pur sans overlay, ce qui r\u00e9duit la complexit\u00e9 et am\u00e9liore les performances r\u00e9seau.</li> <li>Politiques de S\u00e9curit\u00e9 : Offre des contr\u00f4les granulaires de s\u00e9curit\u00e9 r\u00e9seau avec des politiques de r\u00e9seau bas\u00e9es sur les labels.</li> <li>\u00c9volutivit\u00e9 : Calico peut s'\u00e9tendre pour supporter de grands clusters gr\u00e2ce \u00e0 son architecture l\u00e9g\u00e8re et efficace.</li> </ul>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#2-cilium","title":"2. Cilium","text":"<p>Cilium est une solution de mise en r\u00e9seau bas\u00e9e sur eBPF (Extended Berkeley Packet Filter), qui permet une observabilit\u00e9 et une s\u00e9curit\u00e9 r\u00e9seau avanc\u00e9es.</p> <ul> <li>Observabilit\u00e9 : Utilise eBPF pour fournir une visibilit\u00e9 en profondeur des communications r\u00e9seau au sein des clusters Kubernetes.</li> <li>S\u00e9curit\u00e9 Avanc\u00e9e : Offre des politiques de s\u00e9curit\u00e9 de haut niveau qui s'int\u00e8grent directement dans le noyau Linux.</li> <li>Performances : B\u00e9n\u00e9ficie de l'efficacit\u00e9 de eBPF pour traiter les paquets r\u00e9seau au niveau du noyau, r\u00e9duisant ainsi la latence et am\u00e9liorant les performances.</li> </ul> <p></p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#cas-dutilisation-et-scenarios-dimplementation","title":"Cas d'Utilisation et Sc\u00e9narios d'Impl\u00e9mentation","text":""},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#1-mise-en-conteneur-des-applications-existantes","title":"1. Mise en Conteneur des Applications Existantes","text":"<p>Le SDN dans Kubernetes permet de containeriser facilement les applications existantes sans avoir \u00e0 modifier la mani\u00e8re dont les composants communiquent entre eux. Les conteneurs d'un pod utilisent la m\u00eame pile r\u00e9seau, ce qui simplifie la migration des applications traditionnelles vers un environnement conteneuris\u00e9.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#2-gestion-dynamique-du-trafic","title":"2. Gestion Dynamique du Trafic","text":"<p>Avec le SDN, les \u00e9quipes peuvent g\u00e9rer le trafic et les ressources r\u00e9seau par programme, d\u00e9cidant comment exposer leurs applications en fonction des besoins. Par exemple, en r\u00e9ponse \u00e0 une augmentation du trafic, de nouveaux pods peuvent \u00eatre ajout\u00e9s dynamiquement pour g\u00e9rer la charge.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#3-isolation-et-securite-des-applications","title":"3. Isolation et S\u00e9curit\u00e9 des Applications","text":"<p>Le SDN permet une isolation efficace des diff\u00e9rents tenants au sein du m\u00eame cluster, garantissant que les applications sont s\u00e9curis\u00e9es et que les ressources r\u00e9seau sont correctement partitionn\u00e9es.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/00_Les_sdn_dans_openshift/#conclusion","title":"Conclusion","text":"<p>Le R\u00e9seau D\u00e9fini par Logiciel (SDN) dans OpenShift est un \u00e9l\u00e9ment cl\u00e9 pour la gestion et l'orchestration des r\u00e9seaux au sein des clusters Kubernetes. En offrant une gestion centralis\u00e9e, une scalabilit\u00e9 dynamique, et une isolation efficace, le SDN facilite le d\u00e9ploiement et la maintenance des applications conteneuris\u00e9es. Les services et la d\u00e9couverte DNS assurent une communication fiable et stable entre les diff\u00e9rents composants de l'application, garantissant ainsi une infrastructure r\u00e9seau</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/01_Quiz_Les_sdn_dans_openshift/","title":"Quiz : les Workloads dans Openshift","text":"<p>Nous allons maintenant faire un quiz pour \u00e9valuer votre compr\u00e9hension de la partie \"Les SDN dans Openshift\". Ce quiz couvrira les concepts fondamentaux abord\u00e9s, tels que les conteneurs, Kubernetes et les sp\u00e9cificit\u00e9s d'OpenShift.</p> <p>Pour joindre le quiz, veuillez suivre les \u00e9tapes suivantes :</p> <ol> <li> <p>Ouvrez l'application Quizizz sur votre appareil ou rendez-vous sur : https://quizizz.com/join.</p> </li> <li> <p>Entrez le num\u00e9ro fourni par l'instructeur pour acc\u00e9der au quiz.</p> </li> </ol> <p></p> <p>Bonne chance \u00e0 tous !</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/","title":"Services et Routes dans OpenShift","text":""},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#introduction","title":"Introduction","text":"<p>Dans OpenShift, la gestion du trafic r\u00e9seau pour les applications conteneuris\u00e9es est cruciale pour garantir leur accessibilit\u00e9 et leur s\u00e9curit\u00e9. Les services et les routes sont des composants cl\u00e9s de cette gestion. Les services permettent de regrouper et d'exposer des pods \u00e0 l'int\u00e9rieur du cluster, tandis que les routes facilitent l'acc\u00e8s externe aux applications. Ce cours explore en profondeur ces deux concepts, en expliquant leurs types, cas d'usage, et configurations.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#objectifs-de-la-section","title":"Objectifs de la Section","text":"<p>\u00c0 la fin de cette section, vous serez capable de : 1. Comprendre \u00e0 quoi servent les services dans OpenShift. 2. Expliquer les diff\u00e9rents types de services : ClusterIP, NodePort, LoadBalancer, et leurs cas d'usage. 3. Comprendre le r\u00f4le des routes dans OpenShift pour exposer les applications externes. 4. Expliquer comment fonctionne l'Ingress Controller et les diff\u00e9rentes options d'exposition TLS : passthrough, reencrypt, et edge.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#les-services-dans-openshift","title":"Les Services dans OpenShift","text":""},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#concepts-fondamentaux","title":"Concepts Fondamentaux","text":"<p>Les services dans OpenShift, comme dans Kubernetes, sont utilis\u00e9s pour exposer les pods \u00e0 l'int\u00e9rieur du cluster, permettant une communication stable entre eux. Les services abstraient les pods individuels et offrent une adresse IP stable, assurant que m\u00eame si des pods sont recr\u00e9\u00e9s ou d\u00e9plac\u00e9s, le trafic peut toujours les atteindre via le service.</p> <p>Un service associe un groupe de pods par le biais de labels, et dirige le trafic vers ces pods via un m\u00e9canisme de load balancing interne.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#types-de-services","title":"Types de Services","text":"<p>Il existe plusieurs types de services dans OpenShift, chacun ayant ses propres cas d'utilisation :</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#1-clusterip-service-par-defaut","title":"1. ClusterIP (Service par d\u00e9faut)","text":""},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#description","title":"Description","text":"<p>Le type de service ClusterIP est le plus basique et le plus utilis\u00e9. Il expose le service \u00e0 l'int\u00e9rieur du cluster, ce qui signifie que le service est accessible uniquement depuis d'autres pods dans le m\u00eame cluster. Une adresse IP interne est attribu\u00e9e au service, et le trafic est rout\u00e9 vers les pods s\u00e9lectionn\u00e9s par le service.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#cas-dusage","title":"Cas d'usage","text":"<ul> <li>Communication interne : Utilis\u00e9 pour permettre aux pods d'une application de communiquer entre eux.</li> <li>Services backend : Id\u00e9al pour des bases de donn\u00e9es, caches, ou autres composants internes non destin\u00e9s \u00e0 \u00eatre accessibles depuis l'ext\u00e9rieur du cluster.</li> </ul>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#exemple-de-configuration","title":"Exemple de configuration","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-clusterip-service\nspec:\n  selector:\n    app: my-app\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 8080\n  type: ClusterIP\n</code></pre> <p>Dans cet exemple, un service <code>ClusterIP</code> expose les pods avec le label <code>app: my-app</code> sur le port 80.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#2-nodeport","title":"2. NodePort","text":""},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#description_1","title":"Description","text":"<p>Le service de type NodePort expose le service sur un port sp\u00e9cifique de chaque n\u0153ud du cluster. Cela permet d'acc\u00e9der au service depuis l'ext\u00e9rieur du cluster en utilisant l'adresse IP d'un n\u0153ud et le port allou\u00e9.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#cas-dusage_1","title":"Cas d'usage","text":"<ul> <li>Acc\u00e8s externe simple : Utilis\u00e9 lorsque vous avez besoin d'acc\u00e9der au service depuis l'ext\u00e9rieur du cluster, mais sans infrastructure de load balancing externe.</li> <li>Test et d\u00e9veloppement : Pratique pour des environnements de test ou des d\u00e9ploiements simples sans utiliser des configurations plus complexes comme des LoadBalancers ou des routes.</li> </ul>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#exemple-de-configuration_1","title":"Exemple de configuration","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-nodeport-service\nspec:\n  selector:\n    app: my-app\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 8080\n    nodePort: 30007\n  type: NodePort\n</code></pre> <p>Dans cet exemple, le service <code>NodePort</code> est expos\u00e9 sur le port 30007 de chaque n\u0153ud du cluster.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#3-loadbalancer","title":"3. LoadBalancer","text":""},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#description_2","title":"Description","text":"<p>Le service de type LoadBalancer expose le service \u00e0 l'ext\u00e9rieur du cluster en configurant automatiquement un load balancer externe qui distribue le trafic vers les n\u0153uds du cluster. Ce type de service est g\u00e9n\u00e9ralement utilis\u00e9 dans les environnements cloud o\u00f9 les load balancers sont fournis par le fournisseur de cloud.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#cas-dusage_2","title":"Cas d'usage","text":"<ul> <li>Environnements Cloud : Id\u00e9al pour des d\u00e9ploiements en production sur des infrastructures cloud (AWS, GCP, Azure) o\u00f9 le load balancer est automatiquement provisionn\u00e9.</li> <li>Exposition de services critiques : Convient pour des applications n\u00e9cessitant une haute disponibilit\u00e9 et une r\u00e9partition automatique du trafic.</li> </ul>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#exemple-de-configuration-dans-un-environnement-cloud","title":"Exemple de configuration dans un environnement cloud","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-loadbalancer-service\nspec:\n  selector:\n    app: my-app\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 8080\n  type: LoadBalancer\n</code></pre> <p>Dans cet exemple, le service <code>LoadBalancer</code> demande la cr\u00e9ation d'un load balancer externe qui r\u00e9partira le trafic sur les pods s\u00e9lectionn\u00e9s.</p> <p></p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#utilisation-de-metallb-pour-les-environnements-on-premise","title":"Utilisation de MetalLB pour les Environnements On-Premise","text":"<p>Dans les environnements on-premise (sans cloud provider), vous pouvez utiliser un composant comme MetalLB pour simuler un service de type LoadBalancer. MetalLB fournit un load balancing en mode bare-metal pour Kubernetes, permettant d'allouer des IPs externes sur votre r\u00e9seau pour exposer vos services.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#les-routes-dans-openshift","title":"Les Routes dans OpenShift","text":""},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#concepts-fondamentaux_1","title":"Concepts Fondamentaux","text":"<p>Les routes dans OpenShift permettent d'exposer des services internes \u00e0 l'ext\u00e9rieur du cluster. Une route associe un nom de domaine (DNS) \u00e0 un service, et dirige le trafic HTTP/HTTPS vers les pods g\u00e9r\u00e9s par ce service. Les routes sont sp\u00e9cifiques \u00e0 OpenShift et offrent une couche suppl\u00e9mentaire de gestion du trafic par rapport aux services standard de Kubernetes.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#fonctionnement-de-lingress-controller","title":"Fonctionnement de l'Ingress Controller","text":"<p>L'Ingress Controller dans OpenShift agit comme un proxy qui g\u00e8re les routes et le trafic entrant dans le cluster. Il est responsable de recevoir les requ\u00eates HTTP/HTTPS externes et de les router vers les services appropri\u00e9s bas\u00e9s sur les configurations de route.</p> <p>L'Ingress Controller peut \u00e9galement g\u00e9rer la terminaison SSL/TLS, en s'assurant que le trafic est s\u00e9curis\u00e9 entre les clients externes et les services dans le cluster.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#modes-dexposition-tls","title":"Modes d'Exposition TLS","text":"<p>Lorsqu'on configure une route avec TLS dans OpenShift, il existe trois modes principaux pour g\u00e9rer le chiffrement du trafic :</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#1-edge-termination-mode-edge","title":"1. Edge Termination (Mode Edge)","text":""},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#description_3","title":"Description","text":"<p>Dans le mode Edge Termination, la terminaison TLS (chiffrement/d\u00e9chiffrement) est effectu\u00e9e par l'Ingress Controller lui-m\u00eame. Le trafic entre le client et l'Ingress Controller est s\u00e9curis\u00e9 via TLS, mais une fois le trafic d\u00e9chiffr\u00e9, il est envoy\u00e9 en clair aux pods cibles \u00e0 l'int\u00e9rieur du cluster.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#cas-dusage_3","title":"Cas d'usage","text":"<ul> <li>Simplicit\u00e9 : Utilis\u00e9 lorsqu'il est suffisant de s\u00e9curiser le trafic entre le client et le cluster, sans n\u00e9cessiter un chiffrement interne.</li> <li>Performances : Offre une bonne performance en \u00e9vitant le chiffrement suppl\u00e9mentaire \u00e0 l'int\u00e9rieur du cluster.</li> </ul>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#exemple-de-configuration_2","title":"Exemple de configuration","text":"<pre><code>apiVersion: route.openshift.io/v1\nkind: Route\nmetadata:\n  name: my-edge-route\nspec:\n  host: example.com\n  to:\n    kind: Service\n    name: my-service\n  tls:\n    termination: edge\n</code></pre>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#2-re-encrypt-termination-mode-reencrypt","title":"2. Re-encrypt Termination (Mode Reencrypt)","text":""},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#description_4","title":"Description","text":"<p>Dans le mode Re-encrypt Termination, la terminaison TLS est effectu\u00e9e par l'Ingress Controller, mais le trafic est ensuite r\u00e9-encrypt\u00e9 et achemin\u00e9 vers les pods cibles en TLS. Cela assure que le trafic reste chiffr\u00e9 tout au long de son parcours, du client jusqu'aux pods.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#cas-dusage_4","title":"Cas d'usage","text":"<ul> <li>S\u00e9curit\u00e9 accrue : Utilis\u00e9 lorsqu'il est n\u00e9cessaire de s\u00e9curiser le trafic non seulement entre le client et le cluster, mais aussi \u00e0 l'int\u00e9rieur du cluster.</li> <li>Conformit\u00e9 : Id\u00e9al pour les environnements n\u00e9cessitant une conformit\u00e9 stricte en mati\u00e8re de s\u00e9curit\u00e9 des donn\u00e9es.</li> </ul>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#exemple-de-configuration_3","title":"Exemple de configuration","text":"<pre><code>apiVersion: route.openshift.io/v1\nkind: Route\nmetadata:\n  name: my-reencrypt-route\nspec:\n  host: example.com\n  to:\n    kind: Service\n    name: my-service\n  tls:\n    termination: reencrypt\n    destinationCACertificate: |\n      -----BEGIN CERTIFICATE-----\n      MIIBIjANBgkqh...\n      -----END CERTIFICATE-----\n</code></pre>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#3-passthrough-termination-mode-passthrough","title":"3. Passthrough Termination (Mode Passthrough)","text":""},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#description_5","title":"Description","text":"<p>Dans le mode Passthrough Termination, l'Ingress Controller ne termine pas la connexion TLS. Au lieu de cela, il passe directement le trafic TLS au service backend sans modification. Le service backend doit \u00eatre configur\u00e9 pour g\u00e9rer le chiffrement TLS.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#cas-dusage_5","title":"Cas d'usage","text":"<ul> <li>Applications sensibles : Utilis\u00e9 pour des applications qui n\u00e9cessitent un contr\u00f4le total sur le chiffrement TLS, ou lorsqu'une application g\u00e8re d\u00e9j\u00e0 son propre chiffrement.</li> <li>Performances : \u00c9vite la surcharge du chiffrement/d\u00e9chiffrement dans l'Ingress Controller, mais n\u00e9cessite que le backend soit capable de g\u00e9rer les connexions TLS.</li> </ul>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#exemple-de-configuration_4","title":"Exemple de configuration","text":"<pre><code>apiVersion: route.openshift.io/v1\nkind: Route\nmetadata:\n  name: my-passthrough-route\nspec:\n  host: example.com\n  to:\n    kind:\n\n Service\n    name: my-service\n  tls:\n    termination: passthrough\n</code></pre>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/02_Les_r%C3%A9seaux_de_pods_et_de_services/#conclusion","title":"Conclusion","text":"<p>Les services et les routes sont des composantes essentielles pour g\u00e9rer le trafic r\u00e9seau dans OpenShift. Les services permettent de regrouper et d'exposer des pods \u00e0 l'int\u00e9rieur du cluster, tandis que les routes facilitent l'acc\u00e8s externe. En comprenant les diff\u00e9rents types de services et les modes d'exposition TLS, vous pouvez configurer des applications s\u00e9curis\u00e9es et hautement disponibles, adapt\u00e9es \u00e0 divers environnements et besoins.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/03_Exercice_guid%C3%A9_Les_r%C3%A9seaux_de_pods_et_de_services/","title":"Exercice Guid\u00e9 : Les Services et les Routes dans OpenShift","text":"<p>Dans cet exercice, vous allez cr\u00e9er diff\u00e9rents types de services pour exposer vos applications et configurer des routes pour permettre un acc\u00e8s externe. Suivez les \u00e9tapes ci-dessous pour mettre en pratique les concepts th\u00e9oriques abord\u00e9s dans le cours.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/03_Exercice_guid%C3%A9_Les_r%C3%A9seaux_de_pods_et_de_services/#objectifs-de-lexercice","title":"Objectifs de l'Exercice","text":"<ul> <li>Cr\u00e9er des services <code>ClusterIP</code>, <code>NodePort</code>, et <code>LoadBalancer</code>.</li> <li>Configurer une route pour exposer une application via HTTP.</li> <li>Mettre en place une route TLS en mode <code>edge</code>.</li> <li>Tester les diff\u00e9rentes configurations de service et de route.</li> </ul>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/03_Exercice_guid%C3%A9_Les_r%C3%A9seaux_de_pods_et_de_services/#prerequis","title":"Pr\u00e9requis","text":"<p>Vous allez, au cours de cet exercice, exposer une application qui nous affichera les resultats des jeux olympiques de paris 2024.</p> <p>Pour cela cr\u00e9ez un fichier nomm\u00e9 <code>olympic-medals-app.yaml</code> avec le contenu suivant :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: olympic-medals-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: olympic-medals-app\n  template:\n    metadata:\n      labels:\n        app: olympic-medals-app\n    spec:\n      containers:\n        - name: olympic-medals-app\n          image: quay.io/neutron-it/olympic-medals-app:latest\n          ports:\n            - containerPort: 5000\n</code></pre> <p>Appliquez ce service avec la commande suivante :</p> <pre><code>oc apply -f olympic-medals-app.yaml\n</code></pre> <p></p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/03_Exercice_guid%C3%A9_Les_r%C3%A9seaux_de_pods_et_de_services/#etape-1-creer-un-service-clusterip","title":"\u00c9tape 1 : Cr\u00e9er un Service ClusterIP","text":"<p>Cr\u00e9ez un fichier nomm\u00e9 <code>my-clusterip-service.yaml</code> avec le contenu suivant :</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: olympic-medals-app\nspec:\n  selector:\n    app: my-app\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 5000\n  type: ClusterIP\n</code></pre> <p>Ce fichier YAML d\u00e9finit un service <code>ClusterIP</code> qui expose les pods ayant le label <code>app: my-app</code> sur le port 80.</p> <p>Appliquez ce service avec la commande suivante :</p> <pre><code>oc apply -f my-clusterip-service.yaml\n</code></pre> <p>V\u00e9rifiez que le service a \u00e9t\u00e9 cr\u00e9\u00e9 et qu'il est accessible depuis d'autres pods dans le cluster :</p> <pre><code>oc get svc\noc describe svc my-clusterip-service\n</code></pre>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/03_Exercice_guid%C3%A9_Les_r%C3%A9seaux_de_pods_et_de_services/#etape-2-creer-un-service-nodeport","title":"\u00c9tape 2 : Cr\u00e9er un Service NodePort","text":"<p>Cr\u00e9ez un fichier nomm\u00e9 <code>my-nodeport-service.yaml</code> avec le contenu suivant :</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: olympic-medals-app\nspec:\n  selector:\n    app: my-app\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 5000\n    nodePort: 30007\n  type: NodePort\n</code></pre> <p>Ce fichier YAML d\u00e9finit un service <code>NodePort</code> qui expose le service sur le port 30007 de chaque n\u0153ud du cluster.</p> <p>Appliquez ce service :</p> <pre><code>oc apply -f my-nodeport-service.yaml\n</code></pre> <p>V\u00e9rifiez que le service est accessible en utilisant l'adresse IP de l'un des n\u0153uds du cluster :</p> <pre><code>oc get svc\nNAME                   TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE\nmy-clusterip-service   ClusterIP   172.30.72.127    &lt;none&gt;        80/TCP         13m\nmy-nodeport-service    NodePort    172.30.141.210   &lt;none&gt;        80:30007/TCP   27s\n</code></pre> <pre><code>oc get nodes -o jsonpath='{range .items[*]}{.status.addresses[?(@.type==\"InternalIP\")].address}{\"\\n\"}{end}'\n&lt;NODE_IP&gt;\n</code></pre> <p>Acc\u00e9dez dans votre moteur de recherche a http://:30007 pour acc\u00e9der a votre application. <p>Remplacez <code>&lt;NODE_IP&gt;</code> par l'adresse IP d'un n\u0153ud de votre cluster.</p> <p></p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/03_Exercice_guid%C3%A9_Les_r%C3%A9seaux_de_pods_et_de_services/#etape-3-creer-un-service-loadbalancer-avec-metallb-si-en-environnement-on-premise","title":"\u00c9tape 3 : Cr\u00e9er un Service LoadBalancer (avec MetalLB si en environnement On-Premise)","text":"<p>NOTE: TODO not configured yet on the cluster</p> <p>Cr\u00e9ez un fichier nomm\u00e9 <code>my-loadbalancer-service.yaml</code> :</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: my-loadbalancer-service\nspec:\n  selector:\n    app: olympic-medals-app\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 5000\n</code></pre> <p>Appliquez le service :</p> <pre><code>oc apply -f my-loadbalancer-service.yaml\n</code></pre> <p>V\u00e9rifiez que le service est expos\u00e9 avec une adresse IP externe :</p> <pre><code>oc get svc\n</code></pre>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/03_Exercice_guid%C3%A9_Les_r%C3%A9seaux_de_pods_et_de_services/#etape-4-creer-une-route-pour-exposer-le-service","title":"\u00c9tape 4 : Cr\u00e9er une Route pour Exposer le Service","text":"<p>Cr\u00e9ez un fichier nomm\u00e9 <code>my-route.yaml</code> pour exposer votre application via HTTP :</p> <pre><code>apiVersion: route.openshift.io/v1\nkind: Route\nmetadata:\n  name: my-http-route\nspec:\n  to:\n    kind: Service\n    name: my-clusterip-service\n</code></pre> <p>Appliquez cette route :</p> <pre><code>oc apply -f my-route.yaml\n</code></pre> <p>V\u00e9rifiez que la route est cr\u00e9\u00e9e et accessible :</p> <pre><code>oc get route my-http-route -o jsonpath='http://{.spec.host}'\nhttp://my-http-route-prague-user-ns.apps.neutron-sno-office.intraneutron.fr\n</code></pre> <p>Acc\u00e9dez dans votre moteur de recherche a <code>http://&lt;YOUR_ROUTE&gt;</code> pour acc\u00e9der a votre application.</p> <p>Remplacez <code>&lt;NODE_IP&gt;</code> par l'adresse IP d'un n\u0153ud de votre cluster.</p> <p></p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/03_Exercice_guid%C3%A9_Les_r%C3%A9seaux_de_pods_et_de_services/#etape-5-configurer-une-route-tls-mode-edge","title":"\u00c9tape 5 : Configurer une Route TLS (Mode Edge)","text":"<p>Cr\u00e9ez un fichier nomm\u00e9 <code>my-edge-route.yaml</code> :</p> <pre><code>apiVersion: route.openshift.io/v1\nkind: Route\nmetadata:\n  name: my-edge-route\nspec:\n  to:\n    kind: Service\n    name: my-clusterip-service\n  tls:\n    termination: edge\n</code></pre> <p>Appliquez la route TLS :</p> <pre><code>oc apply -f my-edge-route.yaml\n</code></pre> <p>Testez l'acc\u00e8s HTTPS \u00e0 l'application :</p> <pre><code>oc get route my-edge-route -o jsonpath='https://{.spec.host}'\nhttps://my-edge-route-prague-user-ns.apps.neutron-sno-office.intraneutron.fr\n</code></pre> <p></p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/03_Exercice_guid%C3%A9_Les_r%C3%A9seaux_de_pods_et_de_services/#etape-6-nettoyage","title":"\u00c9tape 6 : Nettoyage","text":"<p>Apr\u00e8s avoir termin\u00e9 les tests, nettoyez les ressources cr\u00e9\u00e9es pour \u00e9viter les co\u00fbts inutiles :</p> <pre><code>oc delete deployment olympic-medals-app\noc delete svc my-clusterip-service my-nodeport-service my-loadbalancer-service\noc delete route my-http-route my-edge-route\n</code></pre>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/03_Exercice_guid%C3%A9_Les_r%C3%A9seaux_de_pods_et_de_services/#conclusion","title":"Conclusion","text":"<p>En suivant cet exercice guid\u00e9, vous avez mis en pratique la cr\u00e9ation de diff\u00e9rents types de services et de routes dans OpenShift. Vous avez appris \u00e0 exposer des applications \u00e0 l'int\u00e9rieur et \u00e0 l'ext\u00e9rieur du cluster et \u00e0 s\u00e9curiser les connexions \u00e0 l'aide des routes TLS.</p>"},{"location":"04_Les_r%C3%A9seaux_dans_openshift/04_R%C3%A9sum%C3%A9/","title":"R\u00e9sum\u00e9","text":"<p>Dans cette partie, le formateur fera une synth\u00e8se de tout ce qui a \u00e9t\u00e9 vu dans les parties pr\u00e9c\u00e9dentes. Ce sera l'occasion de revoir les points cl\u00e9s, de clarifier les concepts abord\u00e9s et de s'assurer que tous les participants ont bien assimil\u00e9 le contenu.</p> <p>C'est \u00e9galement le moment id\u00e9al pour poser toutes les questions que vous pourriez avoir. Rappelez-vous que m\u00eame les questions qui peuvent sembler simples ou \u00e9videntes sont importantes. Alors, ne soyez pas timide : comme on dit, il n'y a pas de questions b\u00eates, seulement des r\u00e9ponses... parfois un peu longues !</p> <p></p>"},{"location":"05_Gestion_du_stockage/00_Les_configmap_et_les_secrets_dans_openshift/","title":"ConfigMaps et Secrets dans OpenShift","text":""},{"location":"05_Gestion_du_stockage/00_Les_configmap_et_les_secrets_dans_openshift/#introduction","title":"Introduction","text":"<p>Dans OpenShift, la gestion des configurations et des donn\u00e9es sensibles est cruciale pour assurer la s\u00e9curit\u00e9 et la flexibilit\u00e9 des applications. Les ConfigMaps et les Secrets sont deux m\u00e9canismes essentiels pour stocker et g\u00e9rer ces informations de mani\u00e8re s\u00e9curis\u00e9e. Les ConfigMaps sont utilis\u00e9s pour stocker des donn\u00e9es non sensibles, comme des configurations applicatives, tandis que les Secrets sont con\u00e7us pour des donn\u00e9es sensibles telles que les mots de passe et les cl\u00e9s API. Cette section explore ces deux concepts, leur utilisation, et leur configuration dans OpenShift.</p>"},{"location":"05_Gestion_du_stockage/00_Les_configmap_et_les_secrets_dans_openshift/#objectifs-de-la-section","title":"Objectifs de la Section","text":"<p>\u00c0 la fin de cette section, vous serez capable de :</p> <ul> <li>Comprendre l'utilit\u00e9 des ConfigMaps et des Secrets dans OpenShift.</li> <li>Expliquer les diff\u00e9rences entre les ConfigMaps et les Secrets, et leurs cas d'usage respectifs.</li> <li>Cr\u00e9er et consommer des ConfigMaps et des Secrets dans des applications d\u00e9ploy\u00e9es sur OpenShift.</li> <li>Savoir s\u00e9curiser l'acc\u00e8s aux Secrets et assurer une bonne gestion des donn\u00e9es sensibles.</li> </ul>"},{"location":"05_Gestion_du_stockage/00_Les_configmap_et_les_secrets_dans_openshift/#les-configmaps-dans-openshift","title":"Les ConfigMaps dans OpenShift","text":""},{"location":"05_Gestion_du_stockage/00_Les_configmap_et_les_secrets_dans_openshift/#concepts-fondamentaux","title":"Concepts Fondamentaux","text":"<p>Les ConfigMaps dans OpenShift permettent de stocker des donn\u00e9es de configuration sous forme de paires cl\u00e9-valeur. Ils sont principalement utilis\u00e9s pour s\u00e9parer les configurations des applications de leur code, facilitant ainsi la gestion des environnements et le d\u00e9ploiement de configurations diff\u00e9rentes selon le contexte (d\u00e9veloppement, test, production).</p>"},{"location":"05_Gestion_du_stockage/00_Les_configmap_et_les_secrets_dans_openshift/#cas-dusage-des-configmaps","title":"Cas d'Usage des ConfigMaps","text":"<ul> <li>Stockage des configurations applicatives : Les ConfigMaps sont id\u00e9aux pour stocker les configurations non sensibles telles que les param\u00e8tres de connexion \u00e0 une base de donn\u00e9es ou les URL de services externes.</li> <li>Centralisation des configurations : Ils permettent de centraliser la gestion des configurations, rendant les applications plus faciles \u00e0 mettre \u00e0 jour et \u00e0 reconfigurer sans modifier le code source.</li> </ul>"},{"location":"05_Gestion_du_stockage/00_Les_configmap_et_les_secrets_dans_openshift/#exemple-de-creation-de-configmap","title":"Exemple de Cr\u00e9ation de ConfigMap","text":"<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\ndata:\n  database_url: \"jdbc:mysql://db:3306/mydatabase\"\n  log_level: \"DEBUG\"\n</code></pre> <p>Dans cet exemple, le ConfigMap <code>app-config</code> contient des informations de configuration pour une application, comme l'URL de la base de donn\u00e9es et le niveau de journalisation.</p>"},{"location":"05_Gestion_du_stockage/00_Les_configmap_et_les_secrets_dans_openshift/#utilisation-des-configmaps-dans-une-application","title":"Utilisation des ConfigMaps dans une Application","text":"<p>Les ConfigMaps peuvent \u00eatre mont\u00e9s sous forme de volumes ou inject\u00e9s sous forme de variables d'environnement dans les pods. Par exemple :</p> <pre><code>env:\n- name: DATABASE_URL\n  valueFrom:\n    configMapKeyRef:\n      name: app-config\n      key: database_url\n</code></pre>"},{"location":"05_Gestion_du_stockage/00_Les_configmap_et_les_secrets_dans_openshift/#les-secrets-dans-openshift","title":"Les Secrets dans OpenShift","text":""},{"location":"05_Gestion_du_stockage/00_Les_configmap_et_les_secrets_dans_openshift/#concepts-fondamentaux_1","title":"Concepts Fondamentaux","text":"<p>Les Secrets permettent de stocker des donn\u00e9es sensibles telles que des mots de passe, des certificats ou des cl\u00e9s SSH de mani\u00e8re s\u00e9curis\u00e9e. Contrairement aux ConfigMaps, les Secrets sont encod\u00e9s en base64 et leur acc\u00e8s est restreint pour garantir la s\u00e9curit\u00e9 des informations qu'ils contiennent.</p>"},{"location":"05_Gestion_du_stockage/00_Les_configmap_et_les_secrets_dans_openshift/#cas-dusage-des-secrets","title":"Cas d'Usage des Secrets","text":"<ul> <li>Stockage des informations sensibles : Utilis\u00e9s pour stocker des donn\u00e9es critiques comme les identifiants de connexion \u00e0 des bases de donn\u00e9es, les tokens d'API, ou les certificats TLS.</li> <li>Gestion de la s\u00e9curit\u00e9 : Permettent de contr\u00f4ler l'acc\u00e8s aux donn\u00e9es sensibles via des politiques de s\u00e9curit\u00e9 (RBAC), et de s'assurer que seules les applications autoris\u00e9es peuvent y acc\u00e9der.</li> </ul>"},{"location":"05_Gestion_du_stockage/00_Les_configmap_et_les_secrets_dans_openshift/#exemple-de-creation-de-secret","title":"Exemple de Cr\u00e9ation de Secret","text":"<pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: app-secret\ntype: Opaque\ndata:\n  password: cGFzc3dvcmQxMjM=\n</code></pre> <p>Dans cet exemple, le Secret <code>app-secret</code> contient un mot de passe encod\u00e9 en base64 (<code>password</code>). Le type <code>Opaque</code> indique qu'il s'agit de donn\u00e9es g\u00e9n\u00e9riques.</p>"},{"location":"05_Gestion_du_stockage/00_Les_configmap_et_les_secrets_dans_openshift/#utilisation-des-secrets-dans-une-application","title":"Utilisation des Secrets dans une Application","text":"<p>Les Secrets peuvent aussi \u00eatre mont\u00e9s sous forme de volumes ou inject\u00e9s sous forme de variables d'environnement :</p> <pre><code>env:\n- name: APP_PASSWORD\n  valueFrom:\n    secretKeyRef:\n      name: app-secret\n      key: password\n</code></pre> <p>Cet exemple montre comment injecter le mot de passe contenu dans le Secret <code>app-secret</code> sous forme de variable d'environnement dans un pod.</p>"},{"location":"05_Gestion_du_stockage/00_Les_configmap_et_les_secrets_dans_openshift/#comparaison-entre-configmaps-et-secrets","title":"Comparaison entre ConfigMaps et Secrets","text":"Caract\u00e9ristique ConfigMap Secret Type de donn\u00e9es Non sensibles Sensibles Encodage des donn\u00e9es Texte brut Base64 encod\u00e9 Cas d'usage Configurations g\u00e9n\u00e9rales Mots de passe, certificats S\u00e9curit\u00e9 Moins restreint Acc\u00e8s plus s\u00e9curis\u00e9 via RBAC"},{"location":"05_Gestion_du_stockage/00_Les_configmap_et_les_secrets_dans_openshift/#conclusion","title":"Conclusion","text":"<p>Les ConfigMaps et les Secrets sont des outils essentiels pour g\u00e9rer les configurations et les donn\u00e9es sensibles des applications dans OpenShift. En utilisant correctement ces deux m\u00e9canismes, vous pouvez cr\u00e9er des applications flexibles, s\u00e9curis\u00e9es et adapt\u00e9es \u00e0 diff\u00e9rents environnements. La compr\u00e9hension de leurs diff\u00e9rences et la ma\u00eetrise de leur configuration vous permettent d\u2019optimiser la gestion des d\u00e9ploiements et d\u2019assurer la s\u00e9curit\u00e9 de vos applications.</p>"},{"location":"05_Gestion_du_stockage/01_Exercice_guid%C3%A9_Les_configmap_et_les_secrets_dans_openshifts/","title":"Exercice Guid\u00e9 : Utilisation des ConfigMaps et Secrets dans OpenShift","text":"<p>Cet exercice vous guidera \u00e0 travers la cr\u00e9ation, la gestion et la consommation de ConfigMaps et de Secrets pour vos applications dans OpenShift. Vous apprendrez \u00e0 les utiliser pour stocker des configurations et des donn\u00e9es sensibles, et \u00e0 les int\u00e9grer dans un d\u00e9ploiement pour une gestion s\u00e9curis\u00e9e des informations.</p>"},{"location":"05_Gestion_du_stockage/01_Exercice_guid%C3%A9_Les_configmap_et_les_secrets_dans_openshifts/#objectifs-de-lexercice","title":"Objectifs de l'Exercice","text":"<ul> <li>Cr\u00e9er des ConfigMaps pour stocker des donn\u00e9es de configuration applicatives.</li> <li>Cr\u00e9er des Secrets pour g\u00e9rer des donn\u00e9es sensibles comme des mots de passe.</li> <li>Int\u00e9grer les ConfigMaps et les Secrets dans des applications d\u00e9ploy\u00e9es.</li> <li>Mettre \u00e0 jour les ConfigMaps et red\u00e9ployer les applications pour appliquer les nouvelles configurations.</li> <li>Tester la s\u00e9curisation des donn\u00e9es \u00e0 travers les Secrets.</li> </ul>"},{"location":"05_Gestion_du_stockage/01_Exercice_guid%C3%A9_Les_configmap_et_les_secrets_dans_openshifts/#prerequis","title":"Pr\u00e9requis","text":"<p>Pour cet exercice, vous allez d\u00e9ployer une application simple qui nous affichera les messages de bienvenue d'un site web de d\u00e9monstration. Pour cela, cr\u00e9ez un fichier nomm\u00e9 <code>welcome-app.yaml</code> avec le contenu suivant :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: welcome-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: welcome-app\n  template:\n    metadata:\n      labels:\n        app: welcome-app\n    spec:\n      containers:\n        - name: welcome-app-container\n          image: quay.io/neutron-it/welcome-app:latest\n          ports:\n            - containerPort: 8080\n</code></pre> <p>Appliquez ce d\u00e9ploiement avec la commande suivante :</p> <pre><code>oc apply -f welcome-app.yaml\n</code></pre>"},{"location":"05_Gestion_du_stockage/01_Exercice_guid%C3%A9_Les_configmap_et_les_secrets_dans_openshifts/#etape-1-creer-un-configmap-pour-lapplication","title":"\u00c9tape 1 : Cr\u00e9er un ConfigMap pour l'application","text":"<ol> <li> <p>Objectif : Cr\u00e9er un ConfigMap pour stocker le message de bienvenue affich\u00e9 par l'application.</p> </li> <li> <p>Action : Cr\u00e9ez un fichier nomm\u00e9 <code>welcome-config.yaml</code> avec le contenu suivant :</p> </li> </ol> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: welcome-config\ndata:\n  welcome_message: \"Bienvenue sur notre site de d\u00e9monstration !\"\n  app_mode: \"production\"\n</code></pre> <ol> <li>Commande : Appliquez le fichier pour cr\u00e9er le ConfigMap :</li> </ol> <pre><code>oc apply -f welcome-config.yaml\n</code></pre> <ol> <li>V\u00e9rification : Affichez le ConfigMap pour v\u00e9rifier sa cr\u00e9ation :</li> </ol> <pre><code>oc get configmap welcome-config -o yaml\n</code></pre>"},{"location":"05_Gestion_du_stockage/01_Exercice_guid%C3%A9_Les_configmap_et_les_secrets_dans_openshifts/#etape-2-creer-un-secret-pour-lapplication","title":"\u00c9tape 2 : Cr\u00e9er un Secret pour l'application","text":"<ol> <li> <p>Objectif : Cr\u00e9er un Secret pour stocker les informations sensibles de l'application, comme un token API.</p> </li> <li> <p>Action : Cr\u00e9ez un fichier nomm\u00e9 <code>welcome-secret.yaml</code> avec le contenu suivant :</p> </li> </ol> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: welcome-secret\ntype: Opaque\ndata:\n  api_token: d2VsY29tZVRva2VuMTIz # Le token \"welcomeToken123\" encod\u00e9 en base64\n</code></pre> <ol> <li>Commande : Appliquez le fichier pour cr\u00e9er le Secret :</li> </ol> <pre><code>oc apply -f welcome-secret.yaml\n</code></pre> <ol> <li>V\u00e9rification : Affichez le Secret (sans afficher les donn\u00e9es sensibles) pour v\u00e9rifier sa cr\u00e9ation :</li> </ol> <pre><code>oc get secret welcome-secret -o yaml\n</code></pre>"},{"location":"05_Gestion_du_stockage/01_Exercice_guid%C3%A9_Les_configmap_et_les_secrets_dans_openshifts/#etape-3-consommer-le-configmap-et-le-secret-dans-lapplication","title":"\u00c9tape 3 : Consommer le ConfigMap et le Secret dans l'application","text":"<ol> <li> <p>Objectif : Utiliser le ConfigMap et le Secret dans le d\u00e9ploiement de l'application pour les injecter en tant que variables d'environnement.</p> </li> <li> <p>Action : Modifiez le fichier <code>welcome-app.yaml</code> pour inclure les variables d'environnement :</p> </li> </ol> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: welcome-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: welcome-app\n  template:\n    metadata:\n      labels:\n        app: welcome-app\n    spec:\n      containers:\n        - name: welcome-app-container\n          image: quay.io/neutron-it/welcome-app:latest\n          ports:\n            - containerPort: 8080\n          env:\n            - name: WELCOME_MESSAGE\n              valueFrom:\n                configMapKeyRef:\n                  name: welcome-config\n                  key: welcome_message\n            - name: APP_MODE\n              valueFrom:\n                configMapKeyRef:\n                  name: welcome-config\n                  key: app_mode\n            - name: API_TOKEN\n              valueFrom:\n                secretKeyRef:\n                  name: welcome-secret\n                  key: api_token\n</code></pre> <ol> <li>Commande : Appliquez les modifications pour mettre \u00e0 jour le d\u00e9ploiement :</li> </ol> <pre><code>oc apply -f welcome-app.yaml\n</code></pre> <ol> <li>V\u00e9rification : V\u00e9rifiez que le d\u00e9ploiement est bien en cours d'ex\u00e9cution :</li> </ol> <pre><code>oc get pods -l app=welcome-app\n</code></pre>"},{"location":"05_Gestion_du_stockage/01_Exercice_guid%C3%A9_Les_configmap_et_les_secrets_dans_openshifts/#etape-4-mise-a-jour-du-configmap","title":"\u00c9tape 4 : Mise \u00e0 Jour du ConfigMap","text":"<ol> <li> <p>Objectif : Modifier le ConfigMap pour changer le message de bienvenue et observer l'impact sur l'application.</p> </li> <li> <p>Action : Modifiez le fichier <code>welcome-config.yaml</code> pour mettre \u00e0 jour le message :</p> </li> </ol> <pre><code>data:\n  welcome_message: \"Bienvenue \u00e0 notre nouvelle application d\u00e9ploy\u00e9e avec OpenShift !\"\n  app_mode: \"development\"\n</code></pre> <ol> <li>Commande : R\u00e9appliquez le fichier pour mettre \u00e0 jour le ConfigMap :</li> </ol> <pre><code>oc apply -f welcome-config.yaml\n</code></pre> <ol> <li>V\u00e9rification : Red\u00e9marrez les pods pour qu'ils r\u00e9cup\u00e8rent la nouvelle configuration :</li> </ol> <pre><code>oc rollout restart deployment welcome-app\n</code></pre>"},{"location":"05_Gestion_du_stockage/01_Exercice_guid%C3%A9_Les_configmap_et_les_secrets_dans_openshifts/#etape-6-nettoyage","title":"\u00c9tape 6 : Nettoyage","text":"<p>Apr\u00e8s avoir termin\u00e9 les tests, nettoyez les ressources cr\u00e9\u00e9es :</p> <pre><code>oc delete deployment welcome-app\noc delete configmap welcome-config\noc delete secret welcome-secret\noc delete role secret-reader\noc delete rolebinding read-secrets\n</code></pre>"},{"location":"05_Gestion_du_stockage/01_Exercice_guid%C3%A9_Les_configmap_et_les_secrets_dans_openshifts/#conclusion","title":"Conclusion","text":"<p>En suivant cet exercice, vous avez appris \u00e0 cr\u00e9er et g\u00e9rer des ConfigMaps et des Secrets dans OpenShift. Vous avez explor\u00e9 la fa\u00e7on de les int\u00e9grer dans une application d\u00e9ploy\u00e9e, de les mettre \u00e0 jour. Cela vous permet de g\u00e9rer les configurations et les informations sensibles de mani\u00e8re centralis\u00e9e et s\u00e9curis\u00e9e dans un environnement OpenShift.</p>"},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/","title":"Persistent Volumes (PV) et Persistent Volume Claims (PVC) dans OpenShift","text":""},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/#introduction","title":"Introduction","text":"<p>Dans l'architecture des applications modernes, la gestion du stockage persistant est cruciale pour assurer la durabilit\u00e9 et l'int\u00e9grit\u00e9 des donn\u00e9es. OpenShift, en tant que plateforme Kubernetes, propose des m\u00e9canismes robustes pour g\u00e9rer le stockage, \u00e0 savoir les Persistent Volumes (PV) et les Persistent Volume Claims (PVC). Les PV repr\u00e9sentent des ressources de stockage physique disponibles dans le cluster, tandis que les PVC sont des requ\u00eates des utilisateurs pour consommer ce stockage. Cette section explore ces deux concepts, leurs cas d\u2019usage, et leur configuration dans OpenShift.</p>"},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/#objectifs-de-la-section","title":"Objectifs de la Section","text":"<p>\u00c0 la fin de cette section, vous serez capable de :</p> <ul> <li>Comprendre le r\u00f4le des Persistent Volumes et des Persistent Volume Claims dans OpenShift.</li> <li>Expliquer les diff\u00e9rences fondamentales entre PV et PVC, ainsi que leurs cas d\u2019utilisation respectifs.</li> <li>Cr\u00e9er et consommer des PV et des PVC dans des applications d\u00e9ploy\u00e9es sur OpenShift.</li> </ul>"},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/#les-persistent-volumes-dans-openshift","title":"Les Persistent Volumes dans OpenShift","text":""},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/#concepts-fondamentaux","title":"Concepts Fondamentaux","text":"<p>Les Persistent Volumes (PV) sont des ressources de stockage dans un cluster OpenShift qui ont \u00e9t\u00e9 provisionn\u00e9es par un administrateur ou par un m\u00e9canisme d'approvisionnement dynamique. Contrairement aux volumes \u00e9ph\u00e9m\u00e8res, les PV sont ind\u00e9pendants du cycle de vie des pods. Ils sont con\u00e7us pour conserver les donn\u00e9es m\u00eame apr\u00e8s la suppression ou le red\u00e9marrage des applications. Cela en fait un choix id\u00e9al pour les applications qui n\u00e9cessitent un stockage durable, comme les bases de donn\u00e9es ou les syst\u00e8mes de fichiers partag\u00e9s.</p>"},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/#cas-dusage-des-persistent-volumes","title":"Cas d'Usage des Persistent Volumes","text":"<ul> <li>Stockage de donn\u00e9es critiques : Les PV sont utilis\u00e9s pour stocker des donn\u00e9es essentielles pour les applications, telles que les fichiers de configuration, les donn\u00e9es d\u2019utilisateur et les sauvegardes.</li> <li>Partage de donn\u00e9es entre plusieurs pods : Les PV peuvent \u00eatre configur\u00e9s pour permettre l\u2019acc\u00e8s simultan\u00e9 \u00e0 plusieurs pods, ce qui est essentiel pour les applications n\u00e9cessitant un acc\u00e8s partag\u00e9 aux donn\u00e9es.</li> <li>Ind\u00e9pendance du cycle de vie des applications : Les PV permettent de dissocier le stockage des applications, facilitant ainsi les mises \u00e0 jour, les migrations et la gestion des ressources.</li> </ul>"},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/#types-de-persistent-volumes","title":"Types de Persistent Volumes","text":"<p>Il existe plusieurs types de Persistent Volumes que vous pouvez utiliser dans OpenShift, notamment :</p> <ol> <li>NFS (Network File System) : Permet le partage de fichiers \u00e0 travers un r\u00e9seau, id\u00e9al pour les applications qui n\u00e9cessitent un acc\u00e8s simultan\u00e9 \u00e0 des fichiers.</li> <li>iSCSI (Internet Small Computer System Interface) : Utilis\u00e9 pour le stockage en bloc, offrant des performances \u00e9lev\u00e9es pour les bases de donn\u00e9es et les syst\u00e8mes de fichiers.</li> <li>Ceph : Un syst\u00e8me de stockage distribu\u00e9 qui fournit \u00e0 la fois le stockage objet et le stockage en bloc, adapt\u00e9 aux environnements de cloud.</li> <li>Cloud Storage (AWS EBS, GCP Persistent Disk) : Int\u00e9gration avec des solutions de stockage dans le cloud pour une scalabilit\u00e9 et une durabilit\u00e9 accrues.</li> </ol>"},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/#exemple-de-creation-de-persistent-volume","title":"Exemple de Cr\u00e9ation de Persistent Volume","text":"<p>Voici un exemple YAML pour cr\u00e9er un Persistent Volume utilisant NFS :</p> <pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: nfs-pv\nspec:\n  capacity:\n    storage: 20Gi\n  accessModes:\n    - ReadWriteMany\n  persistentVolumeReclaimPolicy: Recycle\n  nfs:\n    path: /mnt/nfs\n    server: nfs-server.example.com\n</code></pre> <p>Dans cet exemple, le Persistent Volume <code>nfs-pv</code> a une capacit\u00e9 de 20 GiB, est accessible en mode <code>ReadWriteMany</code> (plusieurs pods peuvent \u00e9crire) et utilise un serveur NFS pour le stockage.</p>"},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/#utilisation-des-persistent-volumes-dans-une-application","title":"Utilisation des Persistent Volumes dans une Application","text":"<p>Pour utiliser un PV, vous devez le lier \u00e0 un Persistent Volume Claim (PVC). Voici comment d\u00e9clarer un PVC qui demande ce volume :</p> <pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: nfs-pvc\nspec:\n  accessModes:\n    - ReadWriteMany\n  resources:\n    requests:\n      storage: 20Gi\n</code></pre> <p>Ce PVC demande 20 GiB de stockage en mode <code>ReadWriteMany</code>, et sera automatiquement li\u00e9 \u00e0 un PV disponible qui satisfait cette demande.</p>"},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/#les-persistent-volume-claims-dans-openshift","title":"Les Persistent Volume Claims dans OpenShift","text":""},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/#concepts-fondamentaux_1","title":"Concepts Fondamentaux","text":"<p>Les Persistent Volume Claims (PVC) sont des requ\u00eates de stockage que les utilisateurs cr\u00e9ent pour consommer des volumes persistants. Ils permettent aux d\u00e9veloppeurs de sp\u00e9cifier leurs besoins en mati\u00e8re de stockage (taille, mode d\u2019acc\u00e8s) sans se pr\u00e9occuper des d\u00e9tails sous-jacents de la fa\u00e7on dont le stockage est provisionn\u00e9.</p>"},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/#cas-dusage-des-persistent-volume-claims","title":"Cas d'Usage des Persistent Volume Claims","text":"<ul> <li>Simplification de l\u2019acc\u00e8s au stockage : Les PVC rendent le stockage plus accessible pour les d\u00e9veloppeurs, qui peuvent se concentrer sur le d\u00e9veloppement d\u2019applications sans se soucier des aspects techniques du stockage.</li> <li>Approvisionnement dynamique : OpenShift peut automatiquement cr\u00e9er des PV pour r\u00e9pondre \u00e0 la demande des PVC, ce qui simplifie la gestion du stockage dans des environnements dynamiques.</li> <li>Gestion des acc\u00e8s : Les PVC permettent de g\u00e9rer facilement qui a acc\u00e8s \u00e0 quel stockage, en int\u00e9grant des contr\u00f4les d\u2019acc\u00e8s bas\u00e9s sur les r\u00f4les (RBAC).</li> </ul>"},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/#exemple-de-creation-de-persistent-volume-claim","title":"Exemple de Cr\u00e9ation de Persistent Volume Claim","text":"<p>Voici un exemple de cr\u00e9ation d\u2019un PVC :</p> <pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: app-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n</code></pre> <p>Dans cet exemple, le PVC <code>app-pvc</code> demande un volume de 10 GiB en mode <code>ReadWriteOnce</code>, ce qui signifie qu\u2019un seul pod pourra \u00e9crire sur le volume \u00e0 la fois.</p>"},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/#utilisation-des-persistent-volume-claims-dans-une-application","title":"Utilisation des Persistent Volume Claims dans une Application","text":"<p>Les PVC sont g\u00e9n\u00e9ralement mont\u00e9s dans des pods comme suit :</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-app\nspec:\n  containers:\n    - name: app-container\n      image: my-app-image\n      volumeMounts:\n        - mountPath: /data\n          name: app-storage\n  volumes:\n    - name: app-storage\n      persistentVolumeClaim:\n        claimName: app-pvc\n</code></pre> <p>Dans cet exemple, le PVC <code>app-pvc</code> est mont\u00e9 dans le conteneur \u00e0 l'emplacement <code>/data</code>, permettant \u00e0 l'application d\u2019acc\u00e9der au stockage persistant.</p>"},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/#gestion-du-cycle-de-vie-des-persistent-volumes","title":"Gestion du Cycle de Vie des Persistent Volumes","text":""},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/#recyclage-des-persistent-volumes","title":"Recyclage des Persistent Volumes","text":"<p>Une fois qu\u2019un PVC n\u2019est plus utilis\u00e9, le PV peut \u00eatre r\u00e9cup\u00e9r\u00e9 et r\u00e9utilis\u00e9. La politique de recyclage d\u00e9termine comment le PV est trait\u00e9 apr\u00e8s sa lib\u00e9ration :</p> <ul> <li>Retain : Le PV est conserv\u00e9 et doit \u00eatre supprim\u00e9 manuellement.</li> <li>Recycle : Le PV est nettoy\u00e9 et peut \u00eatre r\u00e9utilis\u00e9.</li> <li>Delete : Le PV est supprim\u00e9 automatiquement.</li> </ul>"},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/#exemples-de-strategies-de-recyclage","title":"Exemples de Strat\u00e9gies de Recyclage","text":"<p>Voici un exemple d'un PV avec une strat\u00e9gie de recyclage d\u00e9finie :</p> <pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: example-pv\nspec:\n  capacity:\n    storage: 10Gi\n  accessModes:\n    - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Recycle\n  hostPath:\n    path: /mnt/data\n</code></pre> <p>Dans cet exemple, le PV <code>example-pv</code> est configur\u00e9 avec la politique de recyclage <code>Recycle</code>, ce qui signifie qu'il sera nettoy\u00e9 et pr\u00eat \u00e0 \u00eatre utilis\u00e9 \u00e0 nouveau apr\u00e8s que le PVC associ\u00e9 soit lib\u00e9r\u00e9.</p>"},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/#comparaison-entre-persistent-volumes-et-persistent-volume-claims","title":"Comparaison entre Persistent Volumes et Persistent Volume Claims","text":"Caract\u00e9ristique Persistent Volume (PV) Persistent Volume Claim (PVC) Ressource Repr\u00e9sentation de stockage Demande de stockage par l'utilisateur Gestion Provisionn\u00e9e par l'administrateur Cr\u00e9\u00e9e par le d\u00e9veloppeur Type d'acc\u00e8s D\u00e9finie par l'administrateur Sp\u00e9cifi\u00e9e par l'utilisateur Cycle de vie Ind\u00e9pendant des pods D\u00e9pend du cycle de vie des pods Politique de recyclage Sp\u00e9cifi\u00e9e dans le PV N/A"},{"location":"05_Gestion_du_stockage/02_Approvisionnement_des_volumes_de_donn%C3%A9s_persistantes/#conclusion","title":"Conclusion","text":"<p>Les Persistent Volumes et les Persistent Volume Claims sont des composants essentiels pour la gestion du stockage persistant dans OpenShift. Gr\u00e2ce \u00e0 leur conception abstraite, ils permettent aux d\u00e9veloppeurs de se concentrer sur la cr\u00e9ation d'applications tout en garantissant que leurs donn\u00e9es sont stock\u00e9es de mani\u00e8re durable et s\u00e9curis\u00e9e. En comprenant bien ces concepts et en ma\u00eetrisant leur configuration, vous pourrez optimiser la gestion des ressources de stockage dans vos d\u00e9ploiements OpenShift, tout en respectant les meilleures pratiques de s\u00e9curit\u00e9 et de performance.</p>"},{"location":"05_Gestion_du_stockage/03_Selection_d_une_classe_de_stockage/","title":"Section de Cours : Gestion des Classes de Stockage dans Kubernetes","text":""},{"location":"05_Gestion_du_stockage/03_Selection_d_une_classe_de_stockage/#introduction","title":"Introduction","text":"<p>Dans Kubernetes, la gestion efficace du stockage est cruciale pour r\u00e9pondre aux besoins vari\u00e9s des applications. Les classes de stockage permettent d\u2019associer des applications \u00e0 des types de stockage sp\u00e9cifiques, en fournissant des services adapt\u00e9s qui r\u00e9pondent aux exigences de performance, de fiabilit\u00e9 et de co\u00fbt.</p>"},{"location":"05_Gestion_du_stockage/03_Selection_d_une_classe_de_stockage/#selection-des-classes-de-stockage","title":"S\u00e9lection des Classes de Stockage","text":"<p>Les classes de stockage, d\u00e9finies par les administrateurs de cluster, d\u00e9crivent les types de stockage disponibles. Elles peuvent \u00eatre adapt\u00e9es \u00e0 diff\u00e9rents environnements, comme le d\u00e9veloppement ou la production. Kubernetes supporte divers backends de stockage, permettant aux d\u00e9veloppeurs de choisir la solution qui correspond le mieux \u00e0 leurs besoins, sans n\u00e9cessiter de connaissances approfondies sur l'infrastructure sous-jacente.</p> <ul> <li>Classe de stockage par d\u00e9faut : Kubernetes permet d\u2019attribuer une classe de stockage par d\u00e9faut pour l\u2019approvisionnement dynamique. Cela signifie que si une PVC (Persistent Volume Claim) ne sp\u00e9cifie pas de classe, Kubernetes utilise automatiquement cette classe par d\u00e9faut. Les d\u00e9veloppeurs doivent donc d\u00e9finir explicitement la classe de stockage requise pour leurs applications afin d'\u00e9viter des comportements inattendus.</li> </ul>"},{"location":"05_Gestion_du_stockage/03_Selection_d_une_classe_de_stockage/#politique-de-recuperation","title":"Politique de R\u00e9cup\u00e9ration","text":"<p>Une politique de r\u00e9cup\u00e9ration d\u00e9termine le sort des donn\u00e9es d'une PVC apr\u00e8s sa suppression. Les deux principales politiques sont :</p> <ul> <li> <p>Retain : Cette politique conserve les donn\u00e9es sur le volume persistant (PV) apr\u00e8s la suppression de la PVC. L'administrateur doit alors effectuer des \u00e9tapes manuelles pour r\u00e9cup\u00e9rer et r\u00e9utiliser le volume.</p> </li> <li> <p>Delete : Cette politique supprime automatiquement le PV et ses donn\u00e9es lorsque la PVC est supprim\u00e9e. C'est la politique par d\u00e9faut pour la plupart des approvisionneurs de stockage.</p> </li> </ul> <p>Les d\u00e9veloppeurs doivent comprendre l'impact de ces politiques sur les exigences de stockage et choisir la classe en cons\u00e9quence.</p>"},{"location":"05_Gestion_du_stockage/03_Selection_d_une_classe_de_stockage/#responsabilites-des-applications","title":"Responsabilit\u00e9s des Applications","text":"<p>Il est essentiel de noter que Kubernetes ne modifie pas la relation entre une application et son stockage. Les applications sont responsables de l'utilisation appropri\u00e9e de leurs p\u00e9riph\u00e9riques de stockage, ce qui inclut la gestion de l'int\u00e9grit\u00e9 et de la coh\u00e9rence des donn\u00e9es. Des configurations incorrectes, comme le partage d'une PVC entre plusieurs pods n\u00e9cessitant un acc\u00e8s exclusif, peuvent entra\u00eener des comportements ind\u00e9sirables.</p>"},{"location":"05_Gestion_du_stockage/03_Selection_d_une_classe_de_stockage/#modes-de-volumes-de-stockage","title":"Modes de Volumes de Stockage","text":"<p>Les classes de stockage peuvent \u00e9galement \u00eatre configur\u00e9es pour prendre en charge diff\u00e9rents modes de volumes :</p> <ul> <li>Block : Id\u00e9al pour des performances optimales, utilis\u00e9 par des applications n\u00e9cessitant un acc\u00e8s en mode bloc brut.</li> <li>Filesystem : Appropri\u00e9 pour les applications qui partagent des fichiers ou n\u00e9cessitent un acc\u00e8s aux fichiers.</li> </ul>"},{"location":"05_Gestion_du_stockage/03_Selection_d_une_classe_de_stockage/#niveaux-de-qualite-de-service-qos","title":"Niveaux de Qualit\u00e9 de Service (QoS)","text":"<p>Les classes de stockage peuvent \u00e9galement diff\u00e9rer en termes de qualit\u00e9 de service. Par exemple, l'utilisation de disques SSD rapides peut convenir aux applications \u00e0 acc\u00e8s fr\u00e9quent, tandis que des disques durs plus lents peuvent \u00eatre utilis\u00e9s pour des fichiers rarement consult\u00e9s.</p>"},{"location":"05_Gestion_du_stockage/03_Selection_d_une_classe_de_stockage/#creation-dune-classe-de-stockage","title":"Cr\u00e9ation d'une Classe de Stockage","text":"<p>La cr\u00e9ation d'une classe de stockage se fait \u00e0 l'aide d'un objet <code>StorageClass</code> en YAML. Ce dernier contient des param\u00e8tres cruciaux, tels que :</p> <ul> <li>Provisionneur : D\u00e9finit la source du plug-in de stockage.</li> <li>Politique de r\u00e9cup\u00e9ration : Indique si le stockage doit \u00eatre supprim\u00e9 ou conserv\u00e9 apr\u00e8s la suppression de la PVC.</li> <li>Mode de liaison de volume : Sp\u00e9cifie comment les associations de volumes sont g\u00e9r\u00e9es lors de la demande d'une PVC.</li> </ul> <p>Exemple d'un objet <code>StorageClass</code> :</p> <pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: io1-gold-storage\n  annotations:\n    storageclass.kubernetes.io/is-default-class: 'false'\ndescription: 'Provides RWO and RWOP Filesystem &amp; Block volumes'\nparameters:\n  type: io1\n  iopsPerGB: \"10\"\nprovisioner: kubernetes.io/aws-ebs\nreclaimPolicy: Delete\nvolumeBindingMode: Immediate\nallowVolumeExpansion: true\n</code></pre>"},{"location":"05_Gestion_du_stockage/03_Selection_d_une_classe_de_stockage/#conclusion","title":"Conclusion","text":"<p>La gestion des classes de stockage dans Kubernetes est essentielle pour garantir que les applications disposent du stockage dont elles ont besoin. En comprenant les diff\u00e9rents types de classes de stockage, les politiques de r\u00e9cup\u00e9ration, et les responsabilit\u00e9s des applications, les administrateurs et d\u00e9veloppeurs peuvent optimiser les performances et la fiabilit\u00e9 des solutions de stockage dans un environnement Kubernetes.</p>"},{"location":"05_Gestion_du_stockage/04_Exercice_guid%C3%A9_pv_pvc_storage_class/","title":"Exercice Guid\u00e9 sur les PVC, PV et Storage Class","text":""},{"location":"05_Gestion_du_stockage/04_Exercice_guid%C3%A9_pv_pvc_storage_class/#objectif","title":"Objectif","text":"<p>L'objectif de cet exercice est de d\u00e9montrer comment utiliser des Persistent Volume Claims (PVC) et Persistent Volumes (PV) avec une Storage Class pour assurer la persistance des donn\u00e9es d'une application, m\u00eame apr\u00e8s la suppression de pods.</p>"},{"location":"05_Gestion_du_stockage/04_Exercice_guid%C3%A9_pv_pvc_storage_class/#etapes-de-lexercice","title":"\u00c9tapes de l'Exercice","text":""},{"location":"05_Gestion_du_stockage/04_Exercice_guid%C3%A9_pv_pvc_storage_class/#etape-1-deployer-postgresql-avec-un-stockage-ephemere","title":"\u00c9tape 1 : D\u00e9ployer PostgreSQL avec un stockage \u00e9ph\u00e9m\u00e8re","text":"<ol> <li>Cr\u00e9ez le d\u00e9ploiement PostgreSQL en utilisant <code>emptyDir</code>.</li> </ol> <p>Cr\u00e9ez un fichier YAML nomm\u00e9 <code>postgres-emptydir-deployment.yaml</code> contenant le manifeste suivant :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: postgres\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      volumes:\n        - name: postgres-storage\n          emptyDir: {} # Utilisation de emptyDir pour le stockage temporaire\n      containers:\n        - name: postgres\n          image: registry.redhat.io/rhel8/postgresql-12:latest\n          ports:\n            - containerPort: 5432\n          env:\n            - name: POSTGRESQL_USER\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-credentials\n                  key: POSTGRES_USER\n            - name: POSTGRESQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-credentials\n                  key: POSTGRES_PASSWORD\n            - name: POSTGRESQL_DATABASE\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-credentials\n                  key: POSTGRES_DB\n            - name: POSTGRESQL_PORT\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-credentials\n                  key: POSTGRES_PORT\n          volumeMounts:\n            - name: postgres-storage\n              mountPath: /var/lib/pgsql/data\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: postgres-service\nspec:\n  selector:\n    app: postgres\n  ports:\n    - name: postgres\n      port: 5432\n      targetPort: 5432\n  type: ClusterIP\n---\napiVersion: v1\ndata:\n  POSTGRES_DB: dGFzaw==\n  POSTGRES_PASSWORD: bXlzZWNyZXRwYXNzd29yZA==\n  POSTGRES_PORT: NTQzMg==\n  POSTGRES_USER: dGFzay11c2Vy\nkind: Secret\nmetadata:\n  name: postgres-credentials\ntype: Opaque\n</code></pre> <ol> <li>Appliquez le d\u00e9ploiement :</li> </ol> <pre><code>oc apply -f postgres-emptydir-deployment.yaml\n</code></pre>"},{"location":"05_Gestion_du_stockage/04_Exercice_guid%C3%A9_pv_pvc_storage_class/#etape-2-deployer-lapplication-todo","title":"\u00c9tape 2 : D\u00e9ployer l'Application Todo","text":"<ol> <li>Cr\u00e9ez le d\u00e9ploiement pour l'application Todo.</li> </ol> <p>Cr\u00e9ez un fichier YAML nomm\u00e9 <code>todo-app.yaml</code> :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: todo-app\n  labels:\n    app: todo-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: todo-app\n  template:\n    metadata:\n      labels:\n        app: todo-app\n    spec:\n      containers:\n        - name: todo-app\n          image: quay.io/neutron-it/todoapp:v4\n          ports:\n            - containerPort: 8080\n          env:\n            - name: NAMESPACE\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.namespace\n            - name: POSTGRESQL_USER\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-credentials\n                  key: POSTGRES_USER\n            - name: POSTGRESQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-credentials\n                  key: POSTGRES_PASSWORD\n            - name: POSTGRESQL_DATABASE\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-credentials\n                  key: POSTGRES_DB\n            - name: POSTGRESQL_PORT\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-credentials\n                  key: POSTGRES_PORT\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: todo-app-service\nspec:\n  selector:\n    app: todo-app\n  ports:\n    - name: todo-app\n      port: 8080\n      targetPort: 8080\n  type: ClusterIP\n---\napiVersion: route.openshift.io/v1\nkind: Route\nmetadata:\n  name: todo-route\nspec:\n  to:\n    kind: Service\n    name: todo-app-service\n    weight: 100\n  port:\n    targetPort: 8080\n  tls:\n    termination: edge\n</code></pre> <ol> <li>Appliquez le d\u00e9ploiement :</li> </ol> <pre><code>oc apply -f todo-app.yaml\n</code></pre> <ol> <li>R\u00e9cup\u00e9rez la route pour acc\u00e9der \u00e0 l'application Todo :</li> </ol> <p>Utilisez la commande suivante :</p> <pre><code>oc get route\n</code></pre> <p>Notez l'URL fournie et acc\u00e9dez-y depuis votre navigateur. Ajoutez quelques t\u00e2ches \u00e0 votre liste de t\u00e2ches.</p> <p></p>"},{"location":"05_Gestion_du_stockage/04_Exercice_guid%C3%A9_pv_pvc_storage_class/#etape-3-tester-la-persistance-des-donnees","title":"\u00c9tape 3 : Tester la Persistance des Donn\u00e9es","text":"<ol> <li>Red\u00e9marrez le d\u00e9ploiement PostgreSQL.</li> </ol> <p>Supprimez le pod PostgreSQL pour observer le comportement du stockage \u00e9ph\u00e9m\u00e8re :</p> <pre><code>oc delete pod -l app=postgres\n</code></pre> <p>Kubernetes recr\u00e9era le pod automatiquement gr\u00e2ce au d\u00e9ploiement.</p> <ol> <li>V\u00e9rifiez l'Application Todo.</li> </ol> <p>Rendez-vous \u00e0 nouveau sur l'interface de votre application Todo et faite un refresh de la page. Vous devriez voir que les t\u00e2ches que vous avez ajout\u00e9es pr\u00e9c\u00e9demment ont disparu, car les donn\u00e9es \u00e9taient stock\u00e9es dans un volume \u00e9ph\u00e9m\u00e8re (<code>emptyDir</code>), qui est supprim\u00e9 avec le pod.</p> <p></p>"},{"location":"05_Gestion_du_stockage/04_Exercice_guid%C3%A9_pv_pvc_storage_class/#transition-vers-un-stockage-persistant","title":"Transition vers un Stockage Persistant","text":"<p>Pour \u00e9viter que le contenu persistant disparaisse lorsque vous modifiez l'image de votre pod, nous allons ajouter du stockage persistant avec des PV et des PVC.</p> <ol> <li>Modifiez le manifeste du d\u00e9ploiement PostgreSQL pour utiliser un PVC.</li> </ol> <p>Voici le manifeste mis \u00e0 jour pour le d\u00e9ploiement PostgreSQL :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: postgres\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app: postgres\n    spec:\n      volumes:\n        - name: postgres-storage\n          persistentVolumeClaim:\n            claimName: postgres-pvc\n      containers:\n        - name: postgres\n          image: registry.redhat.io/rhel8/postgresql-12:latest\n          ports:\n            - containerPort: 5432\n          env:\n            - name: POSTGRESQL_USER\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-credentials\n                  key: POSTGRES_USER\n            - name: POSTGRESQL_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-credentials\n                  key: POSTGRES_PASSWORD\n            - name: POSTGRESQL_DATABASE\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-credentials\n                  key: POSTGRES_DB\n            - name: POSTGRESQL_PORT\n              valueFrom:\n                secretKeyRef:\n                  name: postgres-credentials\n                  key: POSTGRES_PORT\n          volumeMounts:\n            - name: postgres-storage\n              mountPath: /var/lib/pgsql/data\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: postgres-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n</code></pre> <ol> <li>Appliquez les modifications.</li> </ol> <p>Appliquez le nouveau d\u00e9ploiement :</p> <pre><code>oc apply -f postgres-pvc-deployment.yaml\noc delete pod -l app=todo-app\n</code></pre>"},{"location":"05_Gestion_du_stockage/04_Exercice_guid%C3%A9_pv_pvc_storage_class/#test-de-creation-de-taches-avec-stockage-persistant","title":"Test de Cr\u00e9ation de T\u00e2ches avec Stockage Persistant","text":"<ol> <li>V\u00e9rifiez l'Application Todo.</li> </ol> <p>Acc\u00e9dez \u00e0 l'interface de l'application Todo via l'URL que vous avez r\u00e9cup\u00e9r\u00e9e pr\u00e9c\u00e9demment. Ajoutez de nouvelles t\u00e2ches \u00e0 votre liste.</p> <p></p> <ol> <li>Testez le comportement apr\u00e8s le red\u00e9marrage du pod.</li> </ol> <p>Apr\u00e8s avoir ajout\u00e9 quelques t\u00e2ches, r\u00e9p\u00e9tez le processus de red\u00e9marrage du pod PostgreSQL :</p> <pre><code>oc delete pod -l app=postgres\n</code></pre> <p>Kubernetes va recr\u00e9er le pod automatiquement.</p> <ol> <li>V\u00e9rifiez \u00e0 nouveau l'interface de l'application Todo.</li> </ol> <p>Vous devriez maintenant constater que les t\u00e2ches que vous avez ajout\u00e9es pr\u00e9c\u00e9demment sont toujours pr\u00e9sentes avec votre refresh de la page. Cela s'explique par le fait que les donn\u00e9es sont maintenant stock\u00e9es dans un volume persistant via un Persistent Volume Claim (PVC), ce qui permet de pr\u00e9server les donn\u00e9es m\u00eame apr\u00e8s la suppression des pods.</p>"},{"location":"05_Gestion_du_stockage/04_Exercice_guid%C3%A9_pv_pvc_storage_class/#conclusion","title":"Conclusion","text":"<p>Dans cette section, nous avons r\u00e9alis\u00e9 un exercice pratique sur l'utilisation des Persistent Volume Claims (PVC), des Persistent Volumes (PV) et des Storage Classes dans Kubernetes.</p>"},{"location":"05_Gestion_du_stockage/05_R%C3%A9sum%C3%A9/","title":"R\u00e9sum\u00e9","text":"<p>Dans cette partie, le formateur fera une synth\u00e8se de tout ce qui a \u00e9t\u00e9 vu dans les parties pr\u00e9c\u00e9dentes. Ce sera l'occasion de revoir les points cl\u00e9s, de clarifier les concepts abord\u00e9s et de s'assurer que tous les participants ont bien assimil\u00e9 le contenu.</p> <p>C'est \u00e9galement le moment id\u00e9al pour poser toutes les questions que vous pourriez avoir. Rappelez-vous que m\u00eame les questions qui peuvent sembler simples ou \u00e9videntes sont importantes. Alors, ne soyez pas timide : comme on dit, il n'y a pas de questions b\u00eates, seulement des r\u00e9ponses... parfois un peu longues !</p> <p></p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/00_Gestion_de_la_haute_disponibilit%C3%A9_dans_Kubernetes/","title":"Gestion de la Haute Disponibilit\u00e9 dans Kubernetes","text":"<p>La haute disponibilit\u00e9 (HA) est une caract\u00e9ristique essentielle des environnements Kubernetes, garantissant que les applications restent accessibles et fonctionnelles m\u00eame en cas de d\u00e9faillance mat\u00e9rielle ou logicielle. Dans cette section, nous allons explorer les strat\u00e9gies et les outils pour assurer la haute disponibilit\u00e9 des charges de travail dans Kubernetes.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/00_Gestion_de_la_haute_disponibilit%C3%A9_dans_Kubernetes/#strategies-pour-assurer-la-haute-disponibilite","title":"Strat\u00e9gies pour Assurer la Haute Disponibilit\u00e9","text":"<p>Voici quelques strat\u00e9gies courantes pour garantir la haute disponibilit\u00e9 dans Kubernetes :</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/00_Gestion_de_la_haute_disponibilit%C3%A9_dans_Kubernetes/#1-replication-des-pods","title":"1. R\u00e9plication des Pods","text":"<p>La r\u00e9plication des pods est l'une des m\u00e9thodes les plus fondamentales pour assurer la haute disponibilit\u00e9 dans Kubernetes. En d\u00e9ployant plusieurs r\u00e9pliques d'une application (pods), Kubernetes peut r\u00e9partir le trafic entre ces r\u00e9pliques et tol\u00e9rer les d\u00e9faillances individuelles sans affecter la disponibilit\u00e9 globale de l'application.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/00_Gestion_de_la_haute_disponibilit%C3%A9_dans_Kubernetes/#2-gestion-des-echecs-et-des-redemarrages-automatiques","title":"2. Gestion des \u00c9checs et des Red\u00e9marrages Automatiques","text":"<p>Kubernetes offre des m\u00e9canismes int\u00e9gr\u00e9s pour d\u00e9tecter les \u00e9checs des pods et les red\u00e9marrer automatiquement. Les contr\u00f4leurs de r\u00e9plication et les ensembles de r\u00e9plicas supervisent en permanence l'\u00e9tat des pods et prennent des mesures pour garantir que le nombre souhait\u00e9 de r\u00e9pliques est toujours en cours d'ex\u00e9cution.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/00_Gestion_de_la_haute_disponibilit%C3%A9_dans_Kubernetes/#3-gestion-des-mises-a-jour-sans-temps-darret","title":"3. Gestion des Mises \u00e0 Jour sans Temps d'Arr\u00eat","text":"<p>Kubernetes permet la mise \u00e0 jour des applications sans temps d'arr\u00eat en utilisant des strat\u00e9gies telles que le d\u00e9ploiement progressif (rolling updates) et le d\u00e9ploiement canari (canary deployment). Ces strat\u00e9gies permettent de mettre \u00e0 jour les applications de mani\u00e8re incr\u00e9mentielle tout en garantissant que les utilisateurs continuent \u00e0 b\u00e9n\u00e9ficier d'un acc\u00e8s ininterrompu aux services.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/00_Gestion_de_la_haute_disponibilit%C3%A9_dans_Kubernetes/#4-surveillance-et-alertes","title":"4. Surveillance et Alertes","text":"<p>La surveillance \u00e9troite de l'\u00e9tat des applications et de l'infrastructure est essentielle pour d\u00e9tecter les probl\u00e8mes potentiels avant qu'ils n'affectent la disponibilit\u00e9 des services. Kubernetes offre des int\u00e9grations avec des outils de surveillance tiers tels que Prometheus et Grafana, ainsi que des m\u00e9canismes d'alerte int\u00e9gr\u00e9s pour informer les administrateurs des \u00e9v\u00e9nements importants.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/00_Gestion_de_la_haute_disponibilit%C3%A9_dans_Kubernetes/#utilisation-dans-openshift","title":"Utilisation dans OpenShift","text":"<p>Dans OpenShift, la gestion de la haute disponibilit\u00e9 est simplifi\u00e9e gr\u00e2ce \u00e0 des fonctionnalit\u00e9s int\u00e9gr\u00e9es telles que les contr\u00f4leurs de r\u00e9plication, les ensembles de r\u00e9plicas, et les strat\u00e9gies de d\u00e9ploiement avanc\u00e9es. Les administrateurs de cluster peuvent configurer ces fonctionnalit\u00e9s pour garantir que les applications critiques restent disponibles et fonctionnelles en tout temps.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/00_Gestion_de_la_haute_disponibilit%C3%A9_dans_Kubernetes/#conclusion","title":"Conclusion","text":"<p>La gestion de la haute disponibilit\u00e9 dans Kubernetes est essentielle pour garantir la fiabilit\u00e9 et la performance des applications d\u00e9ploy\u00e9es dans des environnements Kubernetes. En utilisant des strat\u00e9gies telles que la r\u00e9plication des pods, la gestion des \u00e9checs et des red\u00e9marrages automatiques, et la surveillance \u00e9troite, les organisations peuvent minimiser les temps d'arr\u00eat et assurer une exp\u00e9rience utilisateur optimale pour leurs applications.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/01_Exercice_guid%C3%A9_Gestion_de_la_haute_disponibilit%C3%A9_dans_Kubernetes/","title":"01 Exercice guid\u00e9 Gestion de la haute disponibilit\u00e9 dans Kubernetes","text":"<p>Bien s\u00fbr, voici la version mise \u00e0 jour avec les commandes Linux pour chaque \u00e9tape de l'exercice :</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/01_Exercice_guid%C3%A9_Gestion_de_la_haute_disponibilit%C3%A9_dans_Kubernetes/#exercice-guidee-gestion-de-la-haute-disponibilite-dans-kubernetes","title":"Exercice Guid\u00e9e : Gestion de la Haute Disponibilit\u00e9 dans Kubernetes","text":"<p>Dans cet exercice, nous allons pratiquer la mise en \u0153uvre de la haute disponibilit\u00e9 (HA) pour les charges de travail dans Kubernetes. Nous allons explorer diff\u00e9rentes strat\u00e9gies et outils pour garantir que nos applications restent disponibles et fonctionnelles m\u00eame en cas de d\u00e9faillance.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/01_Exercice_guid%C3%A9_Gestion_de_la_haute_disponibilit%C3%A9_dans_Kubernetes/#objectifs-de-lexercice","title":"Objectifs de l'Exercice","text":"<ul> <li>Apprendre \u00e0 utiliser les contr\u00f4leurs de r\u00e9plication et les ensembles de r\u00e9plicas pour assurer la haute disponibilit\u00e9.</li> <li>Comprendre comment configurer des strat\u00e9gies de mise \u00e0 jour sans temps d'arr\u00eat.</li> <li>Pratiquer la surveillance et les alertes pour d\u00e9tecter et r\u00e9agir aux incidents de d\u00e9faillance.</li> </ul>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/01_Exercice_guid%C3%A9_Gestion_de_la_haute_disponibilit%C3%A9_dans_Kubernetes/#instructions","title":"Instructions","text":""},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/01_Exercice_guid%C3%A9_Gestion_de_la_haute_disponibilit%C3%A9_dans_Kubernetes/#1-deploiement-dune-application-avec-replication","title":"1. D\u00e9ploiement d'une Application avec R\u00e9plication","text":"<ol> <li>D\u00e9ployez une application avec un contr\u00f4leur de r\u00e9plication en utilisant un fichier de d\u00e9ploiement YAML :</li> </ol> <p><code>bash    kubectl apply -f deployment.yaml</code></p> <p>Assurez-vous que le fichier <code>deployment.yaml</code> sp\u00e9cifie le nombre de r\u00e9pliques souhait\u00e9 pour l'application.</p> <ol> <li>V\u00e9rifiez que les r\u00e9pliques de l'application sont en cours d'ex\u00e9cution :</li> </ol> <p><code>bash    kubectl get pods</code></p> <p>Assurez-vous que le nombre de pods en cours d'ex\u00e9cution correspond au nombre de r\u00e9pliques sp\u00e9cifi\u00e9 dans le d\u00e9ploiement.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/01_Exercice_guid%C3%A9_Gestion_de_la_haute_disponibilit%C3%A9_dans_Kubernetes/#2-configuration-des-strategies-de-mise-a-jour","title":"2. Configuration des Strat\u00e9gies de Mise \u00e0 Jour","text":"<ol> <li>Modifiez la strat\u00e9gie de mise \u00e0 jour du d\u00e9ploiement pour utiliser un d\u00e9ploiement progressif (rolling update) :</li> </ol> <p><code>bash    kubectl edit deployment &lt;nom-du-deploiement&gt;</code></p> <p>Assurez-vous que la strat\u00e9gie de mise \u00e0 jour sp\u00e9cifie les param\u00e8tres appropri\u00e9s pour le d\u00e9ploiement progressif.</p> <ol> <li>Appliquez la nouvelle configuration de d\u00e9ploiement :</li> </ol> <p><code>bash    kubectl apply -f deployment.yaml</code></p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/01_Exercice_guid%C3%A9_Gestion_de_la_haute_disponibilit%C3%A9_dans_Kubernetes/#3-configuration-de-la-surveillance-et-des-alertes","title":"3. Configuration de la Surveillance et des Alertes","text":"<ol> <li>Installez et configurez Prometheus et Grafana pour surveiller l'\u00e9tat de votre cluster Kubernetes.</li> </ol> <p><code>bash    helm install prometheus stable/prometheus    helm install grafana stable/grafana</code></p> <ol> <li> <p>Configurez des alertes dans Prometheus pour d\u00e9tecter les incidents de d\u00e9faillance potentiels, tels que le nombre \u00e9lev\u00e9 de red\u00e9marrages de pods ou les erreurs de sant\u00e9 des pods.</p> </li> <li> <p>Testez les alertes en simulant une d\u00e9faillance d'un pod ou d'un n\u0153ud dans le cluster, puis observez comment les alertes sont d\u00e9clench\u00e9es dans Prometheus.</p> </li> </ol>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/01_Exercice_guid%C3%A9_Gestion_de_la_haute_disponibilit%C3%A9_dans_Kubernetes/#conclusion","title":"Conclusion","text":"<p>Cet exercice vous a permis de pratiquer la gestion de la haute disponibilit\u00e9 dans Kubernetes en utilisant des contr\u00f4leurs de r\u00e9plication, des strat\u00e9gies de mise \u00e0 jour sans temps d'arr\u00eat, et des outils de surveillance et d'alerte. En mettant en \u0153uvre ces pratiques, vous pouvez garantir que vos applications restent disponibles et fonctionnelles m\u00eame en cas de d\u00e9faillance des composants sous-jacents.</p> <p>Cet exercice devrait vous donner une bonne exp\u00e9rience pratique dans la gestion de la haute disponibilit\u00e9 dans Kubernetes. Si vous avez des questions suppl\u00e9mentaires ou si vous rencontrez des difficult\u00e9s lors de cet exercice, n'h\u00e9sitez pas \u00e0 demander de l'aide !</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/02_Utilisation_des_probes_dans_Kubernetes/","title":"Utilisation des Probes dans Kubernetes","text":"<p>Dans Kubernetes, les probes (sondes) sont des m\u00e9canismes cruciaux pour surveiller et maintenir la sant\u00e9 des conteneurs. Ils permettent au syst\u00e8me de d\u00e9terminer si un conteneur est en \u00e9tat de fonctionnement, pr\u00eat \u00e0 recevoir du trafic, ou s'il n\u00e9cessite un red\u00e9marrage. Les probes sont essentielles pour garantir la fiabilit\u00e9 des applications d\u00e9ploy\u00e9es dans un environnement Kubernetes. Dans cette section, nous explorerons en d\u00e9tail les trois types de probes disponibles dans Kubernetes : les probes de d\u00e9marrage, les probes de v\u00e9rification, et les probes de liveness.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/02_Utilisation_des_probes_dans_Kubernetes/#les-probes-de-demarrage-startup-probes","title":"Les Probes de D\u00e9marrage (Startup Probes)","text":"<p>Les probes de d\u00e9marrage sont utilis\u00e9es pour \u00e9valuer si un conteneur a d\u00e9marr\u00e9 correctement. Elles sont ex\u00e9cut\u00e9es une seule fois apr\u00e8s le d\u00e9marrage du conteneur. Si la probe de d\u00e9marrage \u00e9choue, Kubernetes peut d\u00e9cider de red\u00e9marrer le conteneur pour tenter de r\u00e9soudre le probl\u00e8me. Les probes de d\u00e9marrage sont particuli\u00e8rement utiles pour les applications qui n\u00e9cessitent un temps de d\u00e9marrage prolong\u00e9 ou qui doivent effectuer des initialisations complexes avant d'\u00eatre consid\u00e9r\u00e9es comme op\u00e9rationnelles.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/02_Utilisation_des_probes_dans_Kubernetes/#les-probes-de-verification-readiness-probes","title":"Les Probes de V\u00e9rification (Readiness Probes)","text":"<p>Les probes de v\u00e9rification, \u00e9galement connues sous le nom de readiness probes, sont utilis\u00e9es pour d\u00e9terminer si un conteneur est pr\u00eat \u00e0 recevoir du trafic. Elles sont ex\u00e9cut\u00e9es p\u00e9riodiquement apr\u00e8s le d\u00e9marrage du conteneur. Si la probe de v\u00e9rification \u00e9choue, Kubernetes retire le conteneur de l'\u00e9quilibreur de charge pour \u00e9viter que du trafic ne lui soit dirig\u00e9. Les probes de v\u00e9rification sont essentielles pour \u00e9viter de diriger du trafic vers des conteneurs qui ne sont pas encore pr\u00eats \u00e0 r\u00e9pondre aux requ\u00eates.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/02_Utilisation_des_probes_dans_Kubernetes/#les-probes-de-liveness-liveness-probes","title":"Les Probes de Liveness (Liveness Probes)","text":"<p>Les probes de liveness sont utilis\u00e9es pour d\u00e9terminer si un conteneur est toujours en cours d'ex\u00e9cution. Elles sont ex\u00e9cut\u00e9es p\u00e9riodiquement pendant la dur\u00e9e de vie du conteneur. Si la probe de liveness \u00e9choue, Kubernetes peut d\u00e9cider de red\u00e9marrer le conteneur pour tenter de restaurer son \u00e9tat de sant\u00e9. Les probes de liveness sont particuli\u00e8rement utiles pour d\u00e9tecter les situations o\u00f9 un conteneur est tomb\u00e9 dans un \u00e9tat bloqu\u00e9 ou non r\u00e9actif, mais n'a pas encore \u00e9t\u00e9 d\u00e9tect\u00e9 par d'autres m\u00e9canismes de surveillance.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/02_Utilisation_des_probes_dans_Kubernetes/#utilisation-dans-les-deploiements-kubernetes","title":"Utilisation dans les D\u00e9ploiements Kubernetes","text":"<p>Les probes sont configur\u00e9es dans les fichiers de sp\u00e9cification des d\u00e9ploiements Kubernetes \u00e0 l'aide des champs <code>livenessProbe</code>, <code>readinessProbe</code>, et <code>startupProbe</code>. Les administrateurs peuvent sp\u00e9cifier divers param\u00e8tres pour chaque type de probe, tels que le chemin de l'endpoint \u00e0 v\u00e9rifier, les d\u00e9lais d'attente, et les seuils d'\u00e9chec avant qu'une action corrective ne soit d\u00e9clench\u00e9e. En utilisant ces probes de mani\u00e8re appropri\u00e9e, les administrateurs peuvent garantir que les conteneurs fonctionnent de mani\u00e8re fiable et r\u00e9pondent aux exigences de disponibilit\u00e9 des applications.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/02_Utilisation_des_probes_dans_Kubernetes/#conclusion","title":"Conclusion","text":"<p>Les probes dans Kubernetes sont des outils cruciaux pour garantir la fiabilit\u00e9 et la disponibilit\u00e9 des applications d\u00e9ploy\u00e9es dans des environnements conteneuris\u00e9s. En surveillant activement l'\u00e9tat de sant\u00e9 des conteneurs et en r\u00e9agissant de mani\u00e8re proactive aux probl\u00e8mes potentiels, les administrateurs peuvent minimiser les temps d'arr\u00eat et assurer une exp\u00e9rience utilisateur optimale. Il est essentiel de comprendre les diff\u00e9rents types de probes disponibles dans Kubernetes et de les configurer correctement pour r\u00e9pondre aux besoins sp\u00e9cifiques de vos applications.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/03_Exercice_guid%C3%A9_Utilisation_des_probes_dans_Kubernetes/","title":"Exercice Guid\u00e9 : Gestion des Probes dans Kubernetes","text":"<p>Dans cet exercice, nous allons pratiquer la configuration et la gestion des probes dans Kubernetes. Nous explorerons comment d\u00e9finir et ajuster les probes de d\u00e9marrage, de v\u00e9rification et de liveness pour surveiller la sant\u00e9 des conteneurs et assurer la disponibilit\u00e9 des applications.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/03_Exercice_guid%C3%A9_Utilisation_des_probes_dans_Kubernetes/#objectifs-de-lexercice","title":"Objectifs de l'Exercice","text":"<ul> <li>Configurer les probes de d\u00e9marrage, de v\u00e9rification et de liveness dans un d\u00e9ploiement Kubernetes.</li> <li>Tester les probes en simulant des sc\u00e9narios de d\u00e9faillance et en observant les r\u00e9actions du syst\u00e8me.</li> <li>Ajuster les param\u00e8tres des probes pour optimiser la surveillance et la r\u00e9activit\u00e9.</li> </ul>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/03_Exercice_guid%C3%A9_Utilisation_des_probes_dans_Kubernetes/#instructions","title":"Instructions","text":""},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/03_Exercice_guid%C3%A9_Utilisation_des_probes_dans_Kubernetes/#1-deploiement-dune-application-avec-des-probes","title":"1. D\u00e9ploiement d'une Application avec des Probes","text":"<ol> <li> <p>Cr\u00e9ez un fichier de sp\u00e9cification de d\u00e9ploiement YAML pour votre application, en incluant les sections <code>livenessProbe</code>, <code>readinessProbe</code> et <code>startupProbe</code> avec des param\u00e8tres appropri\u00e9s.</p> </li> <li> <p>D\u00e9ployez l'application en utilisant le fichier de sp\u00e9cification YAML :</p> </li> </ol> <p><code>bash    kubectl apply -f deployment.yaml</code></p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/03_Exercice_guid%C3%A9_Utilisation_des_probes_dans_Kubernetes/#2-test-des-probes","title":"2. Test des Probes","text":"<ol> <li>V\u00e9rifiez l'\u00e9tat des probes pour votre d\u00e9ploiement :</li> </ol> <p><code>bash    kubectl describe deployment &lt;nom-du-deploiement&gt;</code></p> <p>Assurez-vous que les probes sont configur\u00e9es correctement et qu'il n'y a pas d'\u00e9checs signal\u00e9s.</p> <ol> <li> <p>Simulez une d\u00e9faillance en introduisant un probl\u00e8me dans votre application (par exemple, en provoquant une erreur 500 dans une URL) ou en arr\u00eatant un processus vital.</p> </li> <li> <p>Observez le comportement du syst\u00e8me pour voir comment Kubernetes r\u00e9agit \u00e0 la d\u00e9faillance. V\u00e9rifiez les logs des pods et observez si des red\u00e9marrages sont d\u00e9clench\u00e9s en raison d'\u00e9checs de probes.</p> </li> </ol>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/03_Exercice_guid%C3%A9_Utilisation_des_probes_dans_Kubernetes/#3-ajustement-des-parametres-des-probes","title":"3. Ajustement des Param\u00e8tres des Probes","text":"<ol> <li> <p>Modifiez les param\u00e8tres des probes dans votre fichier de sp\u00e9cification de d\u00e9ploiement YAML pour ajuster les d\u00e9lais d'attente, les seuils d'\u00e9chec ou d'autres param\u00e8tres pertinents.</p> </li> <li> <p>Appliquez les modifications au d\u00e9ploiement en utilisant la commande <code>kubectl apply</code>.</p> </li> <li> <p>Re-testez les probes pour vous assurer que les ajustements ont l'effet souhait\u00e9.</p> </li> </ol>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/03_Exercice_guid%C3%A9_Utilisation_des_probes_dans_Kubernetes/#conclusion","title":"Conclusion","text":"<p>Cet exercice vous a permis de pratiquer la configuration et la gestion des probes dans Kubernetes. En utilisant les commandes <code>kubectl</code> et en modifiant les fichiers de sp\u00e9cification YAML, vous avez pu d\u00e9finir et ajuster les probes de d\u00e9marrage, de v\u00e9rification et de liveness pour surveiller la sant\u00e9 des conteneurs de votre application. En comprenant comment les probes fonctionnent et en les configurant correctement, vous pouvez garantir que vos applications sont fiables et disponibles, m\u00eame en cas de probl\u00e8mes potentiels.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/04_R%C3%A9servation_de_capacit%C3%A9_de_calcul_pour_les_applications/","title":"R\u00e9servation de Capacit\u00e9 de Calcul dans Kubernetes","text":"<p>Dans Kubernetes, la r\u00e9servation de capacit\u00e9 de calcul est un m\u00e9canisme permettant de garantir que des ressources de calcul suffisantes sont disponibles pour les conteneurs d'une application. En d\u00e9finissant des limites minimales sur la quantit\u00e9 de CPU et de m\u00e9moire allou\u00e9e \u00e0 chaque conteneur, les administrateurs peuvent s'assurer que les performances de l'application ne sont pas affect\u00e9es par d'autres charges de travail sur le cluster.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/04_R%C3%A9servation_de_capacit%C3%A9_de_calcul_pour_les_applications/#configuration-de-la-reservation-de-capacite","title":"Configuration de la R\u00e9servation de Capacit\u00e9","text":"<p>La r\u00e9servation de capacit\u00e9 de calcul est configur\u00e9e dans les fichiers de sp\u00e9cification des d\u00e9ploiements Kubernetes en utilisant les champs <code>resources.requests.cpu</code> et <code>resources.requests.memory</code>. Ces champs sp\u00e9cifient les quantit\u00e9s minimales de CPU et de m\u00e9moire requises par chaque conteneur dans le d\u00e9ploiement. Par exemple :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-container\n        image: my-image:latest\n        resources:\n          requests:\n            cpu: \"0.5\"  # R\u00e9serve 0.5 unit\u00e9 de CPU\n            memory: \"512Mi\"  # R\u00e9serve 512 MiB de m\u00e9moire\n</code></pre>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/04_R%C3%A9servation_de_capacit%C3%A9_de_calcul_pour_les_applications/#avantages-de-la-reservation-de-capacite","title":"Avantages de la R\u00e9servation de Capacit\u00e9","text":"<ul> <li>Garantie de Performance: En r\u00e9servant une quantit\u00e9 minimale de ressources de calcul pour chaque conteneur, les administrateurs peuvent garantir que l'application b\u00e9n\u00e9ficie de performances coh\u00e9rentes m\u00eame en cas de pic d'activit\u00e9 sur le cluster.</li> <li>Isolation des Charges de Travail: La r\u00e9servation de capacit\u00e9 de calcul permet d'isoler les charges de travail les unes des autres, \u00e9vitant ainsi les conflits de ressources et les ralentissements inattendus.</li> <li>Planification des Noeuds: Kubernetes utilise les r\u00e9servations de capacit\u00e9 pour planifier les conteneurs sur les n\u0153uds du cluster, en s'assurant qu'il y a suffisamment de ressources disponibles pour r\u00e9pondre aux exigences de chaque conteneur.</li> </ul>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/04_R%C3%A9servation_de_capacit%C3%A9_de_calcul_pour_les_applications/#bonnes-pratiques","title":"Bonnes Pratiques","text":"<ul> <li>Analyse des Besoins: Il est important de comprendre les besoins en ressources de votre application avant de d\u00e9finir les r\u00e9servations de capacit\u00e9. Des tests et des analyses de charge peuvent \u00eatre n\u00e9cessaires pour d\u00e9terminer les quantit\u00e9s appropri\u00e9es de CPU et de m\u00e9moire \u00e0 r\u00e9server.</li> <li>Surveillance Continue: La surveillance continue des ressources utilis\u00e9es par les conteneurs permet aux administrateurs d'ajuster les r\u00e9servations de capacit\u00e9 en fonction de l'\u00e9volution des besoins de l'application.</li> </ul>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/04_R%C3%A9servation_de_capacit%C3%A9_de_calcul_pour_les_applications/#conclusion","title":"Conclusion","text":"<p>La r\u00e9servation de capacit\u00e9 de calcul dans Kubernetes est un outil essentiel pour garantir des performances fiables et coh\u00e9rentes pour les applications d\u00e9ploy\u00e9es dans des environnements conteneuris\u00e9s. En d\u00e9finissant des limites minimales sur la quantit\u00e9 de CPU et de m\u00e9moire allou\u00e9e \u00e0 chaque conteneur, les administrateurs peuvent garantir que l'application dispose toujours des ressources n\u00e9cessaires pour fonctionner efficacement, m\u00eame dans des conditions de charge \u00e9lev\u00e9e.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/05_Exercice_guid%C3%A9_R%C3%A9servation_de_capacit%C3%A9_de_calcul_pour_les_applications/","title":"Exercice Guid\u00e9 : R\u00e9servation de Capacit\u00e9 de Calcul dans Kubernetes","text":"<p>Dans cet exercice, nous allons pratiquer la configuration et la gestion de la r\u00e9servation de capacit\u00e9 de calcul dans Kubernetes. Nous allons d\u00e9finir des limites minimales sur la quantit\u00e9 de CPU et de m\u00e9moire allou\u00e9e \u00e0 chaque conteneur d'une application, et observer comment Kubernetes utilise ces r\u00e9servations pour planifier et g\u00e9rer les ressources sur le cluster.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/05_Exercice_guid%C3%A9_R%C3%A9servation_de_capacit%C3%A9_de_calcul_pour_les_applications/#objectifs-de-lexercice","title":"Objectifs de l'Exercice","text":"<ul> <li>D\u00e9finir des r\u00e9servations de capacit\u00e9 de calcul pour les conteneurs d'un d\u00e9ploiement Kubernetes.</li> <li>Observer comment Kubernetes utilise ces r\u00e9servations pour planifier les conteneurs sur les n\u0153uds du cluster.</li> <li>V\u00e9rifier que les r\u00e9servations de capacit\u00e9 garantissent des performances stables pour l'application, m\u00eame en cas de charge \u00e9lev\u00e9e sur le cluster.</li> </ul>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/05_Exercice_guid%C3%A9_R%C3%A9servation_de_capacit%C3%A9_de_calcul_pour_les_applications/#instructions","title":"Instructions","text":""},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/05_Exercice_guid%C3%A9_R%C3%A9servation_de_capacit%C3%A9_de_calcul_pour_les_applications/#1-definition-des-reservations-de-capacite","title":"1. D\u00e9finition des R\u00e9servations de Capacit\u00e9","text":"<ol> <li>Modifiez le fichier de sp\u00e9cification de d\u00e9ploiement YAML de votre application pour inclure des r\u00e9servations de capacit\u00e9 de calcul pour chaque conteneur. Utilisez les champs <code>resources.requests.cpu</code> et <code>resources.requests.memory</code> pour d\u00e9finir les quantit\u00e9s minimales de CPU et de m\u00e9moire requises par chaque conteneur.</li> </ol> <p><code>yaml    apiVersion: apps/v1    kind: Deployment    metadata:      name: my-deployment    spec:      replicas: 3      selector:        matchLabels:          app: my-app      template:        metadata:          labels:            app: my-app        spec:          containers:          - name: my-container            image: my-image:latest            resources:              requests:                cpu: \"0.5\"  # R\u00e9serve 0.5 unit\u00e9 de CPU                memory: \"512Mi\"  # R\u00e9serve 512 MiB de m\u00e9moire</code></p> <ol> <li>Appliquez les modifications au d\u00e9ploiement en utilisant la commande <code>kubectl apply</code>.</li> </ol>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/05_Exercice_guid%C3%A9_R%C3%A9servation_de_capacit%C3%A9_de_calcul_pour_les_applications/#2-observation-de-lutilisation-des-reservations","title":"2. Observation de l'Utilisation des R\u00e9servations","text":"<ol> <li>Surveillez l'\u00e9tat des pods pour votre d\u00e9ploiement en utilisant la commande :</li> </ol> <p><code>bash    kubectl get pods</code></p> <p>V\u00e9rifiez que les pods sont en cours d'ex\u00e9cution et qu'ils ont \u00e9t\u00e9 planifi\u00e9s sur les n\u0153uds du cluster en fonction des r\u00e9servations de capacit\u00e9 d\u00e9finies.</p> <ol> <li>V\u00e9rifiez l'utilisation des ressources sur les n\u0153uds du cluster en utilisant la commande :</li> </ol> <p><code>bash    kubectl top nodes</code></p> <p>Observez comment les r\u00e9servations de capacit\u00e9 influencent la r\u00e9partition des ressources sur les n\u0153uds du cluster.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/05_Exercice_guid%C3%A9_R%C3%A9servation_de_capacit%C3%A9_de_calcul_pour_les_applications/#3-test-des-performances-de-lapplication","title":"3. Test des Performances de l'Application","text":"<ol> <li> <p>D\u00e9marrez une charge de travail sur l'application pour simuler une charge \u00e9lev\u00e9e sur le cluster. Cela peut \u00eatre fait en ex\u00e9cutant des requ\u00eates HTTP ou en ex\u00e9cutant des op\u00e9rations intensives sur l'application.</p> </li> <li> <p>Surveillez les performances de l'application en termes de temps de r\u00e9ponse, de latence et de stabilit\u00e9. Assurez-vous que l'application continue de fonctionner de mani\u00e8re stable, m\u00eame sous une charge \u00e9lev\u00e9e, gr\u00e2ce aux r\u00e9servations de capacit\u00e9 de calcul.</p> </li> </ol>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/05_Exercice_guid%C3%A9_R%C3%A9servation_de_capacit%C3%A9_de_calcul_pour_les_applications/#conclusion","title":"Conclusion","text":"<p>Cet exercice vous a permis de pratiquer la configuration et la gestion de la r\u00e9servation de capacit\u00e9 de calcul dans Kubernetes. En d\u00e9finissant des r\u00e9servations minimales de CPU et de m\u00e9moire pour les conteneurs d'une application, vous avez pu observer comment Kubernetes utilise ces informations pour planifier et g\u00e9rer efficacement les ressources sur le cluster. En comprenant comment les r\u00e9servations de capacit\u00e9 fonctionnent et en les ajustant en fonction des besoins de votre application, vous pouvez garantir des performances stables et fiables, m\u00eame dans des conditions de charge \u00e9lev\u00e9e sur le cluster.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/06_Limitation_de_la_capacit%C3%A9_de_calcul_pour_les_applications/","title":"Limitation de la Capacit\u00e9 de Calcul dans OpenShift","text":"<p>Dans OpenShift, la limitation de la capacit\u00e9 de calcul est un m\u00e9canisme permettant de d\u00e9finir des limites maximales sur la quantit\u00e9 de CPU et de m\u00e9moire qu'un conteneur peut consommer. Cela permet de garantir une utilisation \u00e9quitable des ressources du cluster et d'\u00e9viter qu'un conteneur ne monopolise excessivement les ressources disponibles.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/06_Limitation_de_la_capacit%C3%A9_de_calcul_pour_les_applications/#configuration-de-la-limitation-de-capacite","title":"Configuration de la Limitation de Capacit\u00e9","text":"<p>La limitation de capacit\u00e9 de calcul est configur\u00e9e dans les fichiers de sp\u00e9cification des d\u00e9ploiements OpenShift en utilisant les champs <code>resources.limits.cpu</code> et <code>resources.limits.memory</code>. Ces champs sp\u00e9cifient les quantit\u00e9s maximales de CPU et de m\u00e9moire que chaque conteneur peut utiliser. Par exemple :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-container\n        image: my-image:latest\n        resources:\n          limits:\n            cpu: \"1\"  # Limite de 1 unit\u00e9 de CPU\n            memory: \"1Gi\"  # Limite de 1 GiB de m\u00e9moire\n</code></pre>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/06_Limitation_de_la_capacit%C3%A9_de_calcul_pour_les_applications/#avantages-de-la-limitation-de-capacite","title":"Avantages de la Limitation de Capacit\u00e9","text":"<ul> <li>Pr\u00e9vention de la Surutilisation: En d\u00e9finissant des limites maximales sur la quantit\u00e9 de ressources qu'un conteneur peut utiliser, la limitation de capacit\u00e9 de calcul pr\u00e9vient la surutilisation des ressources du cluster et garantit une utilisation \u00e9quitable des ressources entre les diff\u00e9rentes charges de travail.</li> <li>Protection contre les D\u00e9passements: En fixant des limites strictes sur la quantit\u00e9 de CPU et de m\u00e9moire qu'un conteneur peut consommer, la limitation de capacit\u00e9 prot\u00e8ge contre les d\u00e9passements de ressources qui pourraient entra\u00eener des perturbations ou des pannes dans d'autres parties du cluster.</li> <li>Optimisation des Performances: En emp\u00eachant les conteneurs de monopoliser excessivement les ressources, la limitation de capacit\u00e9 de calcul contribue \u00e0 maintenir des performances stables et pr\u00e9visibles pour toutes les charges de travail du cluster.</li> </ul>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/06_Limitation_de_la_capacit%C3%A9_de_calcul_pour_les_applications/#bonnes-pratiques","title":"Bonnes Pratiques","text":"<ul> <li>Analyse des Besoins: Il est important de comprendre les besoins en ressources de votre application avant de d\u00e9finir les limites de capacit\u00e9. Des tests et des analyses de charge peuvent \u00eatre n\u00e9cessaires pour d\u00e9terminer les quantit\u00e9s appropri\u00e9es de CPU et de m\u00e9moire \u00e0 allouer \u00e0 chaque conteneur.</li> <li>Surveillance Continue: La surveillance continue de l'utilisation des ressources par les conteneurs permet aux administrateurs de d\u00e9tecter et de r\u00e9soudre rapidement les probl\u00e8mes de d\u00e9passement de capacit\u00e9.</li> </ul>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/06_Limitation_de_la_capacit%C3%A9_de_calcul_pour_les_applications/#conclusion","title":"Conclusion","text":"<p>La limitation de la capacit\u00e9 de calcul dans OpenShift est un outil essentiel pour garantir une utilisation \u00e9quitable et efficace des ressources du cluster. En d\u00e9finissant des limites maximales sur la quantit\u00e9 de CPU et de m\u00e9moire qu'un conteneur peut utiliser, les administrateurs peuvent pr\u00e9venir la surutilisation des ressources, prot\u00e9ger contre les d\u00e9passements de capacit\u00e9 et maintenir des performances stables et pr\u00e9visibles pour toutes les charges de travail du cluster.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/07_Exercice_guid%C3%A9_Limitation_de_la_capacit%C3%A9_de_calcul_pour_les_applications/","title":"07 Exercice guid\u00e9 Limitation de la capacit\u00e9 de calcul pour les applications","text":"<p>Voici l'exercice guid\u00e9 sur la limitation de la capacit\u00e9 de calcul dans OpenShift :</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/07_Exercice_guid%C3%A9_Limitation_de_la_capacit%C3%A9_de_calcul_pour_les_applications/#exercice-guide-limitation-de-la-capacite-de-calcul-dans-openshift","title":"Exercice Guid\u00e9 : Limitation de la Capacit\u00e9 de Calcul dans OpenShift","text":"<p>Dans cet exercice, nous allons pratiquer la configuration et la gestion de la limitation de la capacit\u00e9 de calcul dans OpenShift. Nous allons d\u00e9finir des limites maximales sur la quantit\u00e9 de CPU et de m\u00e9moire qu'un conteneur peut consommer, et observer comment OpenShift utilise ces limites pour contr\u00f4ler l'utilisation des ressources sur le cluster.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/07_Exercice_guid%C3%A9_Limitation_de_la_capacit%C3%A9_de_calcul_pour_les_applications/#objectifs-de-lexercice","title":"Objectifs de l'Exercice","text":"<ul> <li>D\u00e9finir des limites de capacit\u00e9 de calcul pour les conteneurs d'un d\u00e9ploiement OpenShift.</li> <li>Observer comment OpenShift applique ces limites pour contr\u00f4ler l'utilisation des ressources par les conteneurs.</li> <li>V\u00e9rifier que les limites de capacit\u00e9 emp\u00eachent les conteneurs de consommer excessivement les ressources du cluster.</li> </ul>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/07_Exercice_guid%C3%A9_Limitation_de_la_capacit%C3%A9_de_calcul_pour_les_applications/#instructions","title":"Instructions","text":""},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/07_Exercice_guid%C3%A9_Limitation_de_la_capacit%C3%A9_de_calcul_pour_les_applications/#1-definition-des-limites-de-capacite","title":"1. D\u00e9finition des Limites de Capacit\u00e9","text":"<ol> <li>Modifiez le fichier de sp\u00e9cification de d\u00e9ploiement YAML de votre application pour inclure des limites de capacit\u00e9 de calcul pour chaque conteneur. Utilisez les champs <code>resources.limits.cpu</code> et <code>resources.limits.memory</code> pour d\u00e9finir les quantit\u00e9s maximales de CPU et de m\u00e9moire que chaque conteneur peut utiliser. Par exemple :</li> </ol> <p><code>yaml    apiVersion: apps/v1    kind: Deployment    metadata:      name: my-deployment    spec:      replicas: 3      selector:        matchLabels:          app: my-app      template:        metadata:          labels:            app: my-app        spec:          containers:          - name: my-container            image: my-image:latest            resources:              limits:                cpu: \"1\"  # Limite de 1 unit\u00e9 de CPU                memory: \"1Gi\"  # Limite de 1 GiB de m\u00e9moire</code></p> <ol> <li>Appliquez les modifications au d\u00e9ploiement en utilisant la commande <code>oc apply</code>.</li> </ol>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/07_Exercice_guid%C3%A9_Limitation_de_la_capacit%C3%A9_de_calcul_pour_les_applications/#2-observation-de-lutilisation-des-limites","title":"2. Observation de l'Utilisation des Limites","text":"<ol> <li>Surveillez l'\u00e9tat des pods pour votre d\u00e9ploiement en utilisant la commande :</li> </ol> <p><code>bash    oc get pods</code></p> <p>V\u00e9rifiez que les pods sont en cours d'ex\u00e9cution et que les limites de capacit\u00e9 de calcul sont appliqu\u00e9es aux conteneurs.</p> <ol> <li>Surveillez l'utilisation des ressources sur le cluster en utilisant la console OpenShift ou en utilisant des outils de surveillance tiers. Observez comment OpenShift contr\u00f4le l'utilisation des ressources en fonction des limites de capacit\u00e9 d\u00e9finies.</li> </ol>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/07_Exercice_guid%C3%A9_Limitation_de_la_capacit%C3%A9_de_calcul_pour_les_applications/#3-test-des-performances-de-lapplication","title":"3. Test des Performances de l'Application","text":"<ol> <li> <p>D\u00e9marrez une charge de travail sur l'application pour simuler une utilisation intensive des ressources. Cela peut \u00eatre fait en ex\u00e9cutant des requ\u00eates HTTP ou en ex\u00e9cutant des op\u00e9rations intensives sur l'application.</p> </li> <li> <p>Surveillez les performances de l'application en termes de temps de r\u00e9ponse, de latence et de stabilit\u00e9. Assurez-vous que l'application continue de fonctionner de mani\u00e8re stable, m\u00eame lorsque les limites de capacit\u00e9 sont atteintes.</p> </li> </ol>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/07_Exercice_guid%C3%A9_Limitation_de_la_capacit%C3%A9_de_calcul_pour_les_applications/#conclusion","title":"Conclusion","text":"<p>Cet exercice vous a permis de pratiquer la configuration et la gestion de la limitation de la capacit\u00e9 de calcul dans OpenShift. En d\u00e9finissant des limites maximales sur la quantit\u00e9 de CPU et de m\u00e9moire qu'un conteneur peut consommer, vous avez pu observer comment OpenShift contr\u00f4le l'utilisation des ressources sur le cluster pour garantir des performances stables et pr\u00e9visibles pour toutes les charges de travail d\u00e9ploy\u00e9es.</p> <p>Cet exercice devrait vous donner une exp\u00e9rience pratique de la gestion des limites de capacit\u00e9 de calcul dans OpenShift. Si vous avez des questions suppl\u00e9mentaires ou si vous rencontrez des difficult\u00e9s lors de cet exercice, n'h\u00e9sitez pas \u00e0 demander de l'aide !</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/08_Mise_a_l%27echelle_automatique_des_applications/","title":"Mise \u00e0 l'\u00c9chelle Automatique des Applications dans OpenShift","text":"<p>La mise \u00e0 l'\u00e9chelle automatique des applications dans OpenShift est un m\u00e9canisme permettant d'ajuster dynamiquement le nombre de r\u00e9pliques d'une application en fonction de la charge de travail. Cela garantit que l'application dispose toujours des ressources n\u00e9cessaires pour r\u00e9pondre \u00e0 la demande, tout en optimisant l'utilisation des ressources disponibles sur le cluster.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/08_Mise_a_l%27echelle_automatique_des_applications/#configuration-de-la-mise-a-lechelle-automatique","title":"Configuration de la Mise \u00e0 l'\u00c9chelle Automatique","text":"<p>OpenShift offre plusieurs options pour configurer la mise \u00e0 l'\u00e9chelle automatique des applications, notamment :</p> <ul> <li>Horicontal Pod Autoscaler (HPA) : Cela permet de d\u00e9finir des r\u00e8gles bas\u00e9es sur l'utilisation des ressources (CPU ou m\u00e9moire) pour ajuster automatiquement le nombre de r\u00e9pliques d'une application.</li> <li>Vertical Pod Autoscaler (VPA) : Il ajuste automatiquement les demandes de ressources des conteneurs en fonction de leur utilisation r\u00e9elle.</li> <li>Cluster Autoscaler : Il ajuste automatiquement la taille du cluster en ajoutant ou en supprimant des n\u0153uds en fonction de la demande de ressources.</li> </ul> <p>La configuration de la mise \u00e0 l'\u00e9chelle automatique se fait g\u00e9n\u00e9ralement \u00e0 l'aide de fichiers de sp\u00e9cification YAML ou via l'interface utilisateur d'OpenShift.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/08_Mise_a_l%27echelle_automatique_des_applications/#avantages-de-la-mise-a-lechelle-automatique","title":"Avantages de la Mise \u00e0 l'\u00c9chelle Automatique","text":"<ul> <li>Optimisation des Ressources : La mise \u00e0 l'\u00e9chelle automatique permet d'optimiser l'utilisation des ressources en ajustant dynamiquement le nombre de r\u00e9pliques d'une application en fonction de la demande.</li> <li>Am\u00e9lioration de la Disponibilit\u00e9 : En garantissant que l'application dispose toujours des ressources n\u00e9cessaires, la mise \u00e0 l'\u00e9chelle automatique contribue \u00e0 maintenir la disponibilit\u00e9 de l'application, m\u00eame en cas de variation de charge.</li> <li>R\u00e9duction des Co\u00fbts : En ajustant automatiquement la taille du cluster en fonction de la demande, la mise \u00e0 l'\u00e9chelle automatique permet d'\u00e9conomiser des co\u00fbts en \u00e9vitant la surprovisionnement des ressources.</li> </ul>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/08_Mise_a_l%27echelle_automatique_des_applications/#bonnes-pratiques","title":"Bonnes Pratiques","text":"<ul> <li>Surveillance Continue : Il est essentiel de surveiller en permanence les performances de l'application et d'ajuster les param\u00e8tres de mise \u00e0 l'\u00e9chelle automatique en cons\u00e9quence.</li> <li>D\u00e9finition de R\u00e8gles Pr\u00e9cises : D\u00e9finissez des r\u00e8gles de mise \u00e0 l'\u00e9chelle automatique pr\u00e9cises bas\u00e9es sur les besoins et les mod\u00e8les de charge de votre application.</li> </ul>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/08_Mise_a_l%27echelle_automatique_des_applications/#conclusion","title":"Conclusion","text":"<p>La mise \u00e0 l'\u00e9chelle automatique des applications dans OpenShift est un outil puissant pour optimiser les performances, la disponibilit\u00e9 et les co\u00fbts des applications d\u00e9ploy\u00e9es sur le cluster. En ajustant automatiquement le nombre de r\u00e9pliques d'une application en fonction de la demande, la mise \u00e0 l'\u00e9chelle automatique garantit que l'application peut \u00e9voluer pour r\u00e9pondre aux besoins changeants de l'utilisateur, tout en maximisant l'efficacit\u00e9 des ressources du cluster.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/09_Exercice_guid%C3%A9_Mise_a_l%27echelle_automatique_des_applications/","title":"Exercice Guid\u00e9 : Mise \u00e0 l'\u00c9chelle Automatique des Applications dans OpenShift","text":"<p>Dans cet exercice, nous allons pratiquer la configuration et la gestion de la mise \u00e0 l'\u00e9chelle automatique des applications dans OpenShift. Nous allons d\u00e9finir des r\u00e8gles de mise \u00e0 l'\u00e9chelle automatique bas\u00e9es sur l'utilisation des ressources et observer comment OpenShift ajuste automatiquement le nombre de r\u00e9pliques d'une application en fonction de la demande.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/09_Exercice_guid%C3%A9_Mise_a_l%27echelle_automatique_des_applications/#objectifs-de-lexercice","title":"Objectifs de l'Exercice","text":"<ul> <li>Configurer la mise \u00e0 l'\u00e9chelle automatique des applications dans OpenShift en utilisant Horizontal Pod Autoscaler (HPA).</li> <li>D\u00e9finir des r\u00e8gles de mise \u00e0 l'\u00e9chelle automatique bas\u00e9es sur l'utilisation des ressources.</li> <li>Observer comment OpenShift ajuste automatiquement le nombre de r\u00e9pliques d'une application en fonction de la charge de travail.</li> </ul>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/09_Exercice_guid%C3%A9_Mise_a_l%27echelle_automatique_des_applications/#instructions","title":"Instructions","text":""},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/09_Exercice_guid%C3%A9_Mise_a_l%27echelle_automatique_des_applications/#1-configuration-de-la-mise-a-lechelle-automatique","title":"1. Configuration de la Mise \u00e0 l'\u00c9chelle Automatique","text":"<ol> <li>D\u00e9finir les r\u00e8gles de mise \u00e0 l'\u00e9chelle automatique : Modifiez le fichier de sp\u00e9cification YAML de votre application pour inclure les r\u00e8gles de mise \u00e0 l'\u00e9chelle automatique. Utilisez les champs <code>spec.autoscaler.minReplicas</code>, <code>spec.autoscaler.maxReplicas</code> et <code>spec.autoscaler.targetCPUUtilizationPercentage</code> pour d\u00e9finir le nombre minimum et maximum de r\u00e9pliques et le niveau d'utilisation cible des ressources CPU pour lequel vous souhaitez ajuster automatiquement le nombre de r\u00e9pliques. Par exemple :</li> </ol> <p><code>yaml    apiVersion: autoscaling/v1    kind: HorizontalPodAutoscaler    metadata:      name: my-hpa    spec:      scaleTargetRef:        apiVersion: apps/v1        kind: Deployment        name: my-deployment      minReplicas: 2      maxReplicas: 10      targetCPUUtilizationPercentage: 50</code></p> <ol> <li>Appliquer les modifications au HPA en utilisant la commande <code>oc apply</code>.</li> </ol>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/09_Exercice_guid%C3%A9_Mise_a_l%27echelle_automatique_des_applications/#2-observation-de-la-mise-a-lechelle-automatique","title":"2. Observation de la Mise \u00e0 l'\u00c9chelle Automatique","text":"<ol> <li>Surveiller l'\u00e9tat du HPA en utilisant la commande :</li> </ol> <p><code>bash    oc get hpa</code></p> <p>V\u00e9rifiez que le HPA est actif et qu'il surveille l'utilisation des ressources de votre application.</p> <ol> <li> <p>Simuler une augmentation de la charge de travail sur votre application en ex\u00e9cutant des op\u00e9rations intensives ou en g\u00e9n\u00e9rant du trafic.</p> </li> <li> <p>Observer l'ajustement automatique du nombre de r\u00e9pliques de votre application en fonction de la demande. Vous pouvez utiliser la commande <code>oc get pods</code> pour surveiller le nombre de r\u00e9pliques en cours d'ex\u00e9cution.</p> </li> </ol>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/09_Exercice_guid%C3%A9_Mise_a_l%27echelle_automatique_des_applications/#conclusion","title":"Conclusion","text":"<p>Cet exercice vous a permis de pratiquer la configuration et la gestion de la mise \u00e0 l'\u00e9chelle automatique des applications dans OpenShift en utilisant Horizontal Pod Autoscaler (HPA). En d\u00e9finissant des r\u00e8gles bas\u00e9es sur l'utilisation des ressources, vous avez pu observer comment OpenShift ajuste automatiquement le nombre de r\u00e9pliques d'une application en fonction de la charge de travail, garantissant ainsi des performances optimales et une disponibilit\u00e9 continue de l'application.</p> <p>Dans la prochaine section, nous explorerons d'autres aspects de la gestion des ressources dans OpenShift.</p>"},{"location":"06_Configuration_de_la_fiabilit%C3%A9_des_applications/10_R%C3%A9sum%C3%A9/","title":"R\u00e9sum\u00e9","text":"<p>Dans cette partie, le formateur fera une synth\u00e8se de tout ce qui a \u00e9t\u00e9 vu dans les parties pr\u00e9c\u00e9dentes. Ce sera l'occasion de revoir les points cl\u00e9s, de clarifier les concepts abord\u00e9s et de s'assurer que tous les participants ont bien assimil\u00e9 le contenu.</p> <p>C'est \u00e9galement le moment id\u00e9al pour poser toutes les questions que vous pourriez avoir. Rappelez-vous que m\u00eame les questions qui peuvent sembler simples ou \u00e9videntes sont importantes. Alors, ne soyez pas timide : comme on dit, il n'y a pas de questions b\u00eates, seulement des r\u00e9ponses... parfois un peu longues !</p> <p></p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/00_Identit%C3%A9_et_balise_d_image_de_conteneur/","title":"Identit\u00e9 et Balisage d'Image de Conteneur","text":"<p>Dans OpenShift, l'identit\u00e9 et le balisage d'image de conteneur sont des concepts fondamentaux pour la gestion des images utilis\u00e9es dans les d\u00e9ploiements d'applications. L'identit\u00e9 d'une image fait r\u00e9f\u00e9rence \u00e0 son emplacement dans un registre d'images, tandis que le balisage permet de sp\u00e9cifier une version sp\u00e9cifique de l'image.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/00_Identit%C3%A9_et_balise_d_image_de_conteneur/#identite-de-limage","title":"Identit\u00e9 de l'Image","text":"<p>L'identit\u00e9 d'une image de conteneur est d\u00e9termin\u00e9e par son emplacement dans un registre d'images. Un registre d'images est un r\u00e9f\u00e9rentiel centralis\u00e9 qui stocke et distribue des images de conteneur. Dans OpenShift, les images peuvent \u00eatre stock\u00e9es dans un registre int\u00e9gr\u00e9, tel que Red Hat Quay, ou dans un registre externe, tel que Docker Hub.</p> <p>L'identit\u00e9 d'une image est g\u00e9n\u00e9ralement sp\u00e9cifi\u00e9e par son URL compl\u00e8te, qui comprend le nom du registre, le nom de l'utilisateur ou de l'organisation, le nom de l'image et \u00e9ventuellement le tag de version. Par exemple :</p> <pre><code>registry.example.com/user/my-image:latest\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/00_Identit%C3%A9_et_balise_d_image_de_conteneur/#balisage-de-limage","title":"Balisage de l'Image","text":"<p>Le balisage d'une image de conteneur permet de sp\u00e9cifier une version sp\u00e9cifique de l'image. Les balises sont g\u00e9n\u00e9ralement utilis\u00e9es pour distinguer diff\u00e9rentes versions d'une m\u00eame image, telles que les versions de d\u00e9veloppement, de test et de production. Il est courant d'utiliser des balises telles que <code>latest</code>, <code>stable</code>, <code>v1.0</code>, etc.</p> <p>Il est important de noter que l'utilisation de la balise <code>latest</code> peut entra\u00eener des probl\u00e8mes de gestion des versions, car elle pointe toujours vers la derni\u00e8re version de l'image dans le registre. Il est recommand\u00e9 d'utiliser des balises sp\u00e9cifiques pour chaque version d'image utilis\u00e9e dans les d\u00e9ploiements d'application.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/00_Identit%C3%A9_et_balise_d_image_de_conteneur/#bonnes-pratiques","title":"Bonnes Pratiques","text":"<ul> <li>Utilisation de Balises Sp\u00e9cifiques : Utilisez des balises sp\u00e9cifiques pour chaque version d'image afin de garantir la reproductibilit\u00e9 des d\u00e9ploiements et de faciliter la gestion des versions.</li> <li>Gestion des Autorisations : Assurez-vous que seuls les utilisateurs autoris\u00e9s ont acc\u00e8s aux images dans les registres, en d\u00e9finissant des politiques d'acc\u00e8s appropri\u00e9es.</li> </ul>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/00_Identit%C3%A9_et_balise_d_image_de_conteneur/#conclusion","title":"Conclusion","text":"<p>L'identit\u00e9 et le balisage d'image de conteneur sont des concepts importants dans OpenShift pour la gestion efficace des images utilis\u00e9es dans les d\u00e9ploiements d'applications. En sp\u00e9cifiant l'identit\u00e9 d'une image par son emplacement dans un registre d'images et en utilisant des balises sp\u00e9cifiques pour chaque version, les administrateurs peuvent garantir la reproductibilit\u00e9 des d\u00e9ploiements et la gestion efficace des versions d'image.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/01_Exercice_guid%C3%A9_Identit%C3%A9_et_balise_d_image_de_conteneur/","title":"Exercice Guid\u00e9 : Identit\u00e9 et Balisage d'Image de Conteneur","text":"<p>Dans cet exercice guid\u00e9, nous allons explorer comment g\u00e9rer l'identit\u00e9 et le balisage des images de conteneurs dans OpenShift. Vous apprendrez \u00e0 taguer des images, \u00e0 les pousser vers un registre et \u00e0 d\u00e9ployer des applications en utilisant des images avec des balises sp\u00e9cifiques.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/01_Exercice_guid%C3%A9_Identit%C3%A9_et_balise_d_image_de_conteneur/#objectifs-de-lexercice","title":"Objectifs de l'Exercice","text":"<ul> <li>Taguer une image de conteneur avec une balise sp\u00e9cifique.</li> <li>Pousser l'image tagu\u00e9e vers un registre d'images.</li> <li>D\u00e9ployer une application en utilisant une image avec une balise sp\u00e9cifique.</li> </ul>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/01_Exercice_guid%C3%A9_Identit%C3%A9_et_balise_d_image_de_conteneur/#prerequis","title":"Pr\u00e9requis","text":"<ul> <li>Un cluster OpenShift fonctionnel.</li> <li>Une image de conteneur existante que vous souhaitez taguer et d\u00e9ployer.</li> </ul>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/01_Exercice_guid%C3%A9_Identit%C3%A9_et_balise_d_image_de_conteneur/#etape-1-taguer-une-image-de-conteneur","title":"\u00c9tape 1 : Taguer une Image de Conteneur","text":"<p>Tout d'abord, nous allons taguer une image de conteneur existante avec une nouvelle balise.</p> <ol> <li>Lister les images disponibles sur votre machine locale pour identifier l'image \u00e0 taguer :</li> </ol> <p><code>bash    docker images</code></p> <ol> <li>Taguer l'image avec une nouvelle balise. Par exemple, si l'image source est <code>my-app:latest</code> et que vous voulez la taguer en <code>my-app:v1.0</code> :</li> </ol> <p><code>bash    docker tag my-app:latest my-registry.example.com/my-namespace/my-app:v1.0</code></p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/01_Exercice_guid%C3%A9_Identit%C3%A9_et_balise_d_image_de_conteneur/#etape-2-pousser-limage-taguee-vers-un-registre","title":"\u00c9tape 2 : Pousser l'Image Tagu\u00e9e vers un Registre","text":"<p>Ensuite, nous allons pousser l'image tagu\u00e9e vers un registre d'images. Assurez-vous que vous \u00eates connect\u00e9 au registre d'images.</p> <ol> <li>Se connecter au registre d'images (si ce n'est pas d\u00e9j\u00e0 fait) :</li> </ol> <p><code>bash    docker login my-registry.example.com</code></p> <ol> <li>Pousser l'image tagu\u00e9e vers le registre :</li> </ol> <p><code>bash    docker push my-registry.example.com/my-namespace/my-app:v1.0</code></p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/01_Exercice_guid%C3%A9_Identit%C3%A9_et_balise_d_image_de_conteneur/#etape-3-deployer-une-application-en-utilisant-limage-taguee","title":"\u00c9tape 3 : D\u00e9ployer une Application en Utilisant l'Image Tagu\u00e9e","text":"<p>Maintenant, nous allons d\u00e9ployer une application dans OpenShift en utilisant l'image que nous avons tagu\u00e9e et pouss\u00e9e vers le registre.</p> <ol> <li>Cr\u00e9er un fichier de d\u00e9ploiement YAML pour votre application. Par exemple, <code>deployment.yaml</code> :</li> </ol> <p><code>yaml    apiVersion: apps/v1    kind: Deployment    metadata:      name: my-app    spec:      replicas: 3      selector:        matchLabels:          app: my-app      template:        metadata:          labels:            app: my-app        spec:          containers:          - name: my-app-container            image: my-registry.example.com/my-namespace/my-app:v1.0            ports:            - containerPort: 8080</code></p> <ol> <li>Appliquer le fichier de d\u00e9ploiement pour cr\u00e9er le d\u00e9ploiement dans OpenShift :</li> </ol> <p><code>bash    oc apply -f deployment.yaml</code></p> <ol> <li>V\u00e9rifier le statut du d\u00e9ploiement pour s'assurer que les pods sont correctement cr\u00e9\u00e9s et en cours d'ex\u00e9cution :</li> </ol> <p><code>bash    oc get pods</code></p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/01_Exercice_guid%C3%A9_Identit%C3%A9_et_balise_d_image_de_conteneur/#conclusion","title":"Conclusion","text":"<p>Dans cet exercice guid\u00e9, vous avez appris \u00e0 taguer une image de conteneur, \u00e0 la pousser vers un registre d'images et \u00e0 d\u00e9ployer une application dans OpenShift en utilisant cette image. La gestion des balises et l'identit\u00e9 des images sont des comp\u00e9tences essentielles pour assurer la coh\u00e9rence et la reproductibilit\u00e9 des d\u00e9ploiements d'applications.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/02_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/","title":"Mise \u00e0 Jour des Param\u00e8tres et de l'Image de l'Application","text":"<p>La mise \u00e0 jour des param\u00e8tres et de l'image de l'application est une t\u00e2che courante dans la gestion des applications conteneuris\u00e9es. Dans OpenShift, cela implique souvent de mettre \u00e0 jour la configuration de d\u00e9ploiement pour pointer vers une nouvelle version de l'image ou pour modifier les variables d'environnement et autres param\u00e8tres de l'application. Cette section d\u00e9taille les \u00e9tapes n\u00e9cessaires pour effectuer ces mises \u00e0 jour de mani\u00e8re efficace et s\u00e9curis\u00e9e.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/02_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/#objectifs-de-cette-section","title":"Objectifs de cette Section","text":"<ul> <li>Comprendre comment mettre \u00e0 jour l'image d'une application d\u00e9ploy\u00e9e.</li> <li>Savoir comment modifier les variables d'environnement et autres param\u00e8tres de l'application.</li> <li>Apprendre \u00e0 v\u00e9rifier que les mises \u00e0 jour ont \u00e9t\u00e9 appliqu\u00e9es correctement.</li> </ul>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/02_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/#mise-a-jour-de-limage-de-lapplication","title":"Mise \u00e0 Jour de l'Image de l'Application","text":"<p>Mettre \u00e0 jour l'image de l'application consiste \u00e0 pointer le d\u00e9ploiement vers une nouvelle version de l'image. Cette op\u00e9ration peut \u00eatre d\u00e9clench\u00e9e par une modification du fichier de d\u00e9ploiement YAML et l'application de cette mise \u00e0 jour.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/02_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/#etape-1-identifier-la-nouvelle-version-de-limage","title":"\u00c9tape 1 : Identifier la Nouvelle Version de l'Image","text":"<p>Tout d'abord, d\u00e9terminez la nouvelle version de l'image que vous souhaitez d\u00e9ployer. Assurez-vous que cette image est disponible dans le registre d'images.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/02_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/#etape-2-modifier-le-fichier-de-deploiement","title":"\u00c9tape 2 : Modifier le Fichier de D\u00e9ploiement","text":"<p>Ouvrez le fichier de d\u00e9ploiement YAML correspondant \u00e0 votre application et mettez \u00e0 jour la section <code>image</code> avec la nouvelle version. Par exemple, si vous passez de <code>my-app:v1.0</code> \u00e0 <code>my-app:v2.0</code> :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-app-container\n        image: my-registry.example.com/my-namespace/my-app:v2.0\n        ports:\n        - containerPort: 8080\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/02_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/#etape-3-appliquer-les-modifications","title":"\u00c9tape 3 : Appliquer les Modifications","text":"<p>Appliquez les modifications en utilisant la commande <code>oc apply</code> :</p> <pre><code>oc apply -f deployment.yaml\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/02_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/#etape-4-verifier-le-deploiement","title":"\u00c9tape 4 : V\u00e9rifier le D\u00e9ploiement","text":"<p>V\u00e9rifiez que le d\u00e9ploiement a \u00e9t\u00e9 mis \u00e0 jour correctement et que les nouveaux pods utilisent la nouvelle image :</p> <pre><code>oc get pods\n</code></pre> <p>Vous pouvez \u00e9galement d\u00e9crire le d\u00e9ploiement pour v\u00e9rifier l'image utilis\u00e9e :</p> <pre><code>oc describe deployment my-app\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/02_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/#mise-a-jour-des-parametres-de-lapplication","title":"Mise \u00e0 Jour des Param\u00e8tres de l'Application","text":"<p>Les param\u00e8tres de l'application, tels que les variables d'environnement, peuvent \u00e9galement \u00eatre mis \u00e0 jour via le fichier de d\u00e9ploiement YAML.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/02_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/#etape-1-modifier-les-variables-denvironnement","title":"\u00c9tape 1 : Modifier les Variables d'Environnement","text":"<p>Ajoutez ou modifiez les variables d'environnement dans la section <code>env</code> du conteneur. Par exemple :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-app-container\n        image: my-registry.example.com/my-namespace/my-app:v2.0\n        ports:\n        - containerPort: 8080\n        env:\n        - name: DATABASE_URL\n          value: \"postgres://user:password@hostname:5432/dbname\"\n        - name: DEBUG\n          value: \"true\"\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/02_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/#etape-2-appliquer-les-modifications","title":"\u00c9tape 2 : Appliquer les Modifications","text":"<p>Appliquez les modifications comme pr\u00e9c\u00e9demment :</p> <pre><code>oc apply -f deployment.yaml\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/02_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/#etape-3-verifier-les-modifications","title":"\u00c9tape 3 : V\u00e9rifier les Modifications","text":"<p>V\u00e9rifiez que les nouvelles variables d'environnement ont \u00e9t\u00e9 appliqu\u00e9es correctement en d\u00e9crivant les pods :</p> <pre><code>oc describe pod &lt;pod-name&gt;\n</code></pre> <p>Recherchez la section <code>Environment</code> pour confirmer les valeurs des variables.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/02_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/#conclusion","title":"Conclusion","text":"<p>Mettre \u00e0 jour les param\u00e8tres et l'image de l'application dans OpenShift est une op\u00e9ration essentielle pour la gestion continue des applications. En suivant les \u00e9tapes d\u00e9crites ci-dessus, vous pouvez effectuer ces mises \u00e0 jour de mani\u00e8re structur\u00e9e et s\u00e9curis\u00e9e, garantissant ainsi que vos applications fonctionnent avec les derni\u00e8res versions et configurations n\u00e9cessaires.</p> <p>Dans la prochaine section, nous explorerons le d\u00e9ploiement automatique avec les ImageStreams dans OpenShift pour simplifier davantage le processus de gestion des versions.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/03_Exercice_guid%C3%A9_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/","title":"Exercice Guid\u00e9 : Mise \u00e0 Jour des Param\u00e8tres et de l'Image de l'Application","text":"<p>Dans cet exercice guid\u00e9, nous allons pratiquer la mise \u00e0 jour des param\u00e8tres et de l'image de l'application d\u00e9ploy\u00e9e dans OpenShift. Vous apprendrez \u00e0 modifier le fichier de d\u00e9ploiement pour pointer vers une nouvelle version de l'image et \u00e0 mettre \u00e0 jour les variables d'environnement de l'application.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/03_Exercice_guid%C3%A9_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/#objectifs-de-lexercice","title":"Objectifs de l'Exercice","text":"<ul> <li>Mettre \u00e0 jour l'image d'une application.</li> <li>Modifier les variables d'environnement de l'application.</li> <li>V\u00e9rifier que les mises \u00e0 jour ont \u00e9t\u00e9 appliqu\u00e9es correctement.</li> </ul>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/03_Exercice_guid%C3%A9_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/#prerequis","title":"Pr\u00e9requis","text":"<ul> <li>Un cluster OpenShift fonctionnel.</li> <li>Un d\u00e9ploiement existant de l'application que vous souhaitez mettre \u00e0 jour.</li> </ul>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/03_Exercice_guid%C3%A9_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/#etape-1-mettre-a-jour-limage-de-lapplication","title":"\u00c9tape 1 : Mettre \u00e0 Jour l'Image de l'Application","text":"<p>Tout d'abord, nous allons mettre \u00e0 jour l'image de l'application. Supposons que nous avons une nouvelle version de l'image <code>my-app:v2.0</code> disponible dans notre registre.</p> <ol> <li> <p>Ouvrez le fichier de d\u00e9ploiement YAML de votre application. Par exemple, <code>deployment.yaml</code>.</p> </li> <li> <p>Modifiez la section <code>image</code> pour pointer vers la nouvelle version de l'image :</p> </li> </ol> <p><code>yaml    apiVersion: apps/v1    kind: Deployment    metadata:      name: my-app    spec:      replicas: 3      selector:        matchLabels:          app: my-app      template:        metadata:          labels:            app: my-app        spec:          containers:          - name: my-app-container            image: my-registry.example.com/my-namespace/my-app:v2.0            ports:            - containerPort: 8080</code></p> <ol> <li>Appliquez les modifications en utilisant la commande <code>oc apply</code> :</li> </ol> <p><code>bash    oc apply -f deployment.yaml</code></p> <ol> <li>V\u00e9rifiez le d\u00e9ploiement pour vous assurer que les nouveaux pods utilisent la nouvelle image :</li> </ol> <p><code>bash    oc get pods</code></p> <ol> <li>D\u00e9crivez le d\u00e9ploiement pour v\u00e9rifier l'image utilis\u00e9e :</li> </ol> <p><code>bash    oc describe deployment my-app</code></p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/03_Exercice_guid%C3%A9_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/#etape-2-mettre-a-jour-les-parametres-de-lapplication","title":"\u00c9tape 2 : Mettre \u00e0 Jour les Param\u00e8tres de l'Application","text":"<p>Ensuite, nous allons mettre \u00e0 jour les variables d'environnement de l'application.</p> <ol> <li> <p>Ouvrez le fichier de d\u00e9ploiement YAML de votre application.</p> </li> <li> <p>Ajoutez ou modifiez les variables d'environnement dans la section <code>env</code> du conteneur. Par exemple :</p> </li> </ol> <p><code>yaml    apiVersion: apps/v1    kind: Deployment    metadata:      name: my-app    spec:      replicas: 3      selector:        matchLabels:          app: my-app      template:        metadata:          labels:            app: my-app        spec:          containers:          - name: my-app-container            image: my-registry.example.com/my-namespace/my-app:v2.0            ports:            - containerPort: 8080            env:            - name: DATABASE_URL              value: \"postgres://user:password@hostname:5432/dbname\"            - name: DEBUG              value: \"true\"</code></p> <ol> <li>Appliquez les modifications comme pr\u00e9c\u00e9demment :</li> </ol> <p><code>bash    oc apply -f deployment.yaml</code></p> <ol> <li>V\u00e9rifiez les modifications en d\u00e9crivant les pods pour confirmer les valeurs des variables d'environnement :</li> </ol> <p><code>bash    oc describe pod &lt;pod-name&gt;</code></p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/03_Exercice_guid%C3%A9_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/#etape-3-verification-finale","title":"\u00c9tape 3 : V\u00e9rification Finale","text":"<p>Apr\u00e8s avoir appliqu\u00e9 les modifications, il est crucial de v\u00e9rifier que tout fonctionne comme pr\u00e9vu.</p> <ol> <li>Obtenez la liste des pods pour v\u00e9rifier leur statut :</li> </ol> <p><code>bash    oc get pods</code></p> <ol> <li>Consultez les journaux des pods pour vous assurer qu'il n'y a pas d'erreurs li\u00e9es aux nouvelles variables d'environnement ou \u00e0 la nouvelle image :</li> </ol> <p><code>bash    oc logs &lt;pod-name&gt;</code></p> <ol> <li>Acc\u00e9dez \u00e0 l'application via son URL (si applicable) pour v\u00e9rifier qu'elle fonctionne correctement avec les mises \u00e0 jour appliqu\u00e9es.</li> </ol>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/03_Exercice_guid%C3%A9_Mise_a_jour_des_parametres_et_de_l%27image_de_l_application/#conclusion","title":"Conclusion","text":"<p>Dans cet exercice guid\u00e9, vous avez appris \u00e0 mettre \u00e0 jour l'image et les param\u00e8tres de l'application d\u00e9ploy\u00e9e dans OpenShift. En suivant ces \u00e9tapes, vous pouvez assurer que vos applications fonctionnent toujours avec les derni\u00e8res versions et configurations n\u00e9cessaires.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/04_Deploiement_automatique_avec_les_images_stream_openshift/","title":"D\u00e9ploiement Automatique avec les ImageStreams dans OpenShift","text":"<p>Le d\u00e9ploiement automatique avec les ImageStreams dans OpenShift permet de simplifier la gestion des versions et des mises \u00e0 jour des applications. En utilisant les ImageStreams, OpenShift peut surveiller les modifications des images de conteneur et d\u00e9clencher automatiquement des d\u00e9ploiements lorsque de nouvelles versions d'images sont disponibles.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/04_Deploiement_automatique_avec_les_images_stream_openshift/#objectifs-de-cette-section","title":"Objectifs de cette Section","text":"<ul> <li>Comprendre ce qu'est un ImageStream.</li> <li>Apprendre \u00e0 cr\u00e9er et g\u00e9rer des ImageStreams.</li> <li>Configurer des d\u00e9ploiements automatiques bas\u00e9s sur les mises \u00e0 jour des ImageStreams.</li> </ul>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/04_Deploiement_automatique_avec_les_images_stream_openshift/#quest-ce-quun-imagestream","title":"Qu'est-ce qu'un ImageStream ?","text":"<p>Un ImageStream est une abstraction dans OpenShift qui permet de g\u00e9rer et de suivre les versions des images de conteneur. Au lieu de r\u00e9f\u00e9rencer directement les images de conteneur par leur nom et leur balise, vous pouvez utiliser un ImageStream pour obtenir un niveau d'indirection et de flexibilit\u00e9. Cela permet de :</p> <ul> <li>Surveiller les modifications d'images.</li> <li>D\u00e9clencher automatiquement des d\u00e9ploiements lorsque de nouvelles versions d'images sont disponibles.</li> <li>G\u00e9rer les versions d'images de mani\u00e8re centralis\u00e9e.</li> </ul>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/04_Deploiement_automatique_avec_les_images_stream_openshift/#creation-dun-imagestream","title":"Cr\u00e9ation d'un ImageStream","text":"<p>Pour cr\u00e9er un ImageStream, vous pouvez utiliser un fichier YAML ou la ligne de commande OpenShift. Voici un exemple de fichier YAML pour cr\u00e9er un ImageStream :</p> <pre><code>apiVersion: image.openshift.io/v1\nkind: ImageStream\nmetadata:\n  name: my-app\n  namespace: my-namespace\n</code></pre> <p>Pour cr\u00e9er cet ImageStream, utilisez la commande suivante :</p> <pre><code>oc apply -f imagestream.yaml\n</code></pre> <p>Vous pouvez \u00e9galement cr\u00e9er un ImageStream directement via la ligne de commande :</p> <pre><code>oc create imagestream my-app\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/04_Deploiement_automatique_avec_les_images_stream_openshift/#gestion-des-imagestreams","title":"Gestion des ImageStreams","text":"<p>Une fois l'ImageStream cr\u00e9\u00e9, vous pouvez configurer des d\u00e9clencheurs de d\u00e9ploiement automatique. Un d\u00e9clencheur de d\u00e9ploiement surveille les mises \u00e0 jour de l'ImageStream et d\u00e9clenche un nouveau d\u00e9ploiement lorsque l'image est mise \u00e0 jour.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/04_Deploiement_automatique_avec_les_images_stream_openshift/#exemple-de-deploiement-avec-declencheur-automatique","title":"Exemple de D\u00e9ploiement avec D\u00e9clencheur Automatique","text":"<p>Voici un exemple de fichier de d\u00e9ploiement YAML avec un d\u00e9clencheur de d\u00e9ploiement automatique bas\u00e9 sur un ImageStream :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\n  namespace: my-namespace\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-app-container\n        image: image-registry.openshift-image-registry.svc:5000/my-namespace/my-app:latest\n        ports:\n        - containerPort: 8080\n  triggers:\n  - type: ImageChange\n    imageChangeParams:\n      automatic: true\n      containerNames:\n      - my-app-container\n      from:\n        kind: ImageStreamTag\n        name: my-app:latest\n</code></pre> <p>Dans cet exemple, le d\u00e9clencheur de type <code>ImageChange</code> est configur\u00e9 pour surveiller les modifications de l'ImageStreamTag <code>my-app:latest</code>. Lorsque cette balise est mise \u00e0 jour, un nouveau d\u00e9ploiement est automatiquement d\u00e9clench\u00e9.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/04_Deploiement_automatique_avec_les_images_stream_openshift/#appliquer-le-deploiement","title":"Appliquer le D\u00e9ploiement","text":"<p>Pour appliquer ce d\u00e9ploiement, utilisez la commande suivante :</p> <pre><code>oc apply -f deployment.yaml\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/04_Deploiement_automatique_avec_les_images_stream_openshift/#mettre-a-jour-limagestream","title":"Mettre \u00e0 Jour l'ImageStream","text":"<p>Lorsque vous poussez une nouvelle version de l'image de votre application vers le registre d'images, l'ImageStream est automatiquement mis \u00e0 jour, et le d\u00e9clencheur de d\u00e9ploiement se d\u00e9clenche.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/04_Deploiement_automatique_avec_les_images_stream_openshift/#exemple-de-mise-a-jour-de-limage","title":"Exemple de Mise \u00e0 Jour de l'Image","text":"<p>Supposons que vous avez une nouvelle version de l'image <code>my-app:v2.0</code>. Pour pousser cette image vers le registre et mettre \u00e0 jour l'ImageStream, utilisez les commandes suivantes :</p> <pre><code>docker build -t my-registry.example.com/my-namespace/my-app:v2.0 .\ndocker push my-registry.example.com/my-namespace/my-app:v2.0\noc tag my-namespace/my-app:v2.0 my-namespace/my-app:latest\n</code></pre> <p>La derni\u00e8re commande met \u00e0 jour l'ImageStreamTag <code>my-app:latest</code> pour pointer vers la nouvelle image <code>v2.0</code>, ce qui d\u00e9clenche automatiquement un nouveau d\u00e9ploiement.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/04_Deploiement_automatique_avec_les_images_stream_openshift/#verification-du-deploiement-automatique","title":"V\u00e9rification du D\u00e9ploiement Automatique","text":"<p>Apr\u00e8s avoir mis \u00e0 jour l'ImageStream, v\u00e9rifiez que le d\u00e9ploiement automatique s'est bien d\u00e9roul\u00e9 :</p> <ol> <li>Obtenez la liste des d\u00e9ploiements pour v\u00e9rifier l'\u00e9tat :</li> </ol> <p><code>bash    oc get deployments</code></p> <ol> <li>Consultez les journaux des nouveaux pods pour vous assurer qu'ils fonctionnent correctement :</li> </ol> <p><code>bash    oc logs &lt;pod-name&gt;</code></p> <ol> <li>Acc\u00e9dez \u00e0 l'application via son URL (si applicable) pour v\u00e9rifier qu'elle fonctionne correctement avec la nouvelle version de l'image.</li> </ol>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/04_Deploiement_automatique_avec_les_images_stream_openshift/#conclusion","title":"Conclusion","text":"<p>Le d\u00e9ploiement automatique avec les ImageStreams dans OpenShift permet de simplifier la gestion des versions et des mises \u00e0 jour des applications. En configurant des d\u00e9clencheurs de d\u00e9ploiement bas\u00e9s sur les ImageStreams, vous pouvez assurer que vos applications sont toujours \u00e0 jour avec les derni\u00e8res versions d'images disponibles.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/05_Exercice_guid%C3%A9_Deploiement_automatique_avec_les_images_stream_openshift/","title":"Exercice Guid\u00e9 : D\u00e9ploiement Automatique avec les ImageStreams dans OpenShift","text":"<p>Dans cet exercice guid\u00e9, nous allons apprendre \u00e0 configurer et utiliser les ImageStreams pour d\u00e9ployer automatiquement des applications dans OpenShift lorsque de nouvelles versions d'images sont disponibles.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/05_Exercice_guid%C3%A9_Deploiement_automatique_avec_les_images_stream_openshift/#objectifs-de-lexercice","title":"Objectifs de l'Exercice","text":"<ul> <li>Cr\u00e9er un ImageStream.</li> <li>Configurer un d\u00e9ploiement automatique bas\u00e9 sur un ImageStream.</li> <li>Mettre \u00e0 jour l'ImageStream et observer le d\u00e9ploiement automatique.</li> </ul>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/05_Exercice_guid%C3%A9_Deploiement_automatique_avec_les_images_stream_openshift/#prerequis","title":"Pr\u00e9requis","text":"<ul> <li>Acc\u00e8s \u00e0 un cluster OpenShift.</li> <li>OpenShift CLI (<code>oc</code>) install\u00e9 et configur\u00e9.</li> <li>Un registre d'images Docker pour stocker les images de conteneur.</li> </ul>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/05_Exercice_guid%C3%A9_Deploiement_automatique_avec_les_images_stream_openshift/#etapes-de-lexercice","title":"\u00c9tapes de l'Exercice","text":""},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/05_Exercice_guid%C3%A9_Deploiement_automatique_avec_les_images_stream_openshift/#1-creer-un-projet","title":"1. Cr\u00e9er un Projet","text":"<p>Cr\u00e9ez un nouveau projet pour cet exercice :</p> <pre><code>oc new-project demo-imagestream\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/05_Exercice_guid%C3%A9_Deploiement_automatique_avec_les_images_stream_openshift/#2-creer-un-imagestream","title":"2. Cr\u00e9er un ImageStream","text":"<p>Cr\u00e9ez un fichier YAML pour l'ImageStream nomm\u00e9 <code>imagestream.yaml</code> :</p> <pre><code>apiVersion: image.openshift.io/v1\nkind: ImageStream\nmetadata:\n  name: my-app\n  namespace: demo-imagestream\n</code></pre> <p>Appliquez ce fichier pour cr\u00e9er l'ImageStream :</p> <pre><code>oc apply -f imagestream.yaml\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/05_Exercice_guid%C3%A9_Deploiement_automatique_avec_les_images_stream_openshift/#3-creer-une-definition-de-deploiement","title":"3. Cr\u00e9er une D\u00e9finition de D\u00e9ploiement","text":"<p>Cr\u00e9ez un fichier YAML pour le d\u00e9ploiement nomm\u00e9 <code>deployment.yaml</code> :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app-deployment\n  namespace: demo-imagestream\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-app-container\n        image: image-registry.openshift-image-registry.svc:5000/demo-imagestream/my-app:latest\n        ports:\n        - containerPort: 8080\n  triggers:\n  - type: ImageChange\n    imageChangeParams:\n      automatic: true\n      containerNames:\n      - my-app-container\n      from:\n        kind: ImageStreamTag\n        name: my-app:latest\n</code></pre> <p>Appliquez ce fichier pour cr\u00e9er le d\u00e9ploiement :</p> <pre><code>oc apply -f deployment.yaml\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/05_Exercice_guid%C3%A9_Deploiement_automatique_avec_les_images_stream_openshift/#4-pousser-une-image-initiale","title":"4. Pousser une Image Initiale","text":"<p>Construisez et poussez une image initiale vers votre registre d'images Docker :</p> <pre><code>docker build -t my-registry.example.com/demo-imagestream/my-app:v1.0 .\ndocker push my-registry.example.com/demo-imagestream/my-app:v1.0\n</code></pre> <p>Mettez \u00e0 jour l'ImageStreamTag <code>latest</code> pour pointer vers cette image :</p> <pre><code>oc tag demo-imagestream/my-app:v1.0 demo-imagestream/my-app:latest\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/05_Exercice_guid%C3%A9_Deploiement_automatique_avec_les_images_stream_openshift/#5-verifier-le-deploiement","title":"5. V\u00e9rifier le D\u00e9ploiement","text":"<p>V\u00e9rifiez que le d\u00e9ploiement a \u00e9t\u00e9 d\u00e9clench\u00e9 automatiquement :</p> <pre><code>oc get deployments\noc get pods\n</code></pre> <p>Obtenez les journaux des pods pour vous assurer qu'ils fonctionnent correctement :</p> <pre><code>oc logs &lt;pod-name&gt;\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/05_Exercice_guid%C3%A9_Deploiement_automatique_avec_les_images_stream_openshift/#6-mettre-a-jour-limage","title":"6. Mettre \u00e0 Jour l'Image","text":"<p>Construisez et poussez une nouvelle version de l'image :</p> <pre><code>docker build -t my-registry.example.com/demo-imagestream/my-app:v2.0 .\ndocker push my-registry.example.com/demo-imagestream/my-app:v2.0\n</code></pre> <p>Mettez \u00e0 jour l'ImageStreamTag <code>latest</code> pour pointer vers la nouvelle image :</p> <pre><code>oc tag demo-imagestream/my-app:v2.0 demo-imagestream/my-app:latest\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/05_Exercice_guid%C3%A9_Deploiement_automatique_avec_les_images_stream_openshift/#7-observer-le-deploiement-automatique","title":"7. Observer le D\u00e9ploiement Automatique","text":"<p>V\u00e9rifiez que le d\u00e9ploiement automatique a \u00e9t\u00e9 d\u00e9clench\u00e9 suite \u00e0 la mise \u00e0 jour de l'ImageStream :</p> <pre><code>oc get deployments\noc get pods\n</code></pre> <p>Obtenez les journaux des nouveaux pods pour vous assurer qu'ils fonctionnent correctement :</p> <pre><code>oc logs &lt;new-pod-name&gt;\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/05_Exercice_guid%C3%A9_Deploiement_automatique_avec_les_images_stream_openshift/#8-nettoyage","title":"8. Nettoyage","text":"<p>Pour nettoyer les ressources cr\u00e9\u00e9es durant cet exercice :</p> <pre><code>oc delete project demo-imagestream\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/05_Exercice_guid%C3%A9_Deploiement_automatique_avec_les_images_stream_openshift/#conclusion","title":"Conclusion","text":"<p>Vous avez appris \u00e0 configurer des d\u00e9ploiements automatiques dans OpenShift en utilisant les ImageStreams. En suivant cet exercice guid\u00e9, vous devriez maintenant \u00eatre capable de cr\u00e9er, g\u00e9rer et mettre \u00e0 jour des d\u00e9ploiements bas\u00e9s sur des modifications d'images de conteneur. Cette fonctionnalit\u00e9 est cruciale pour maintenir des environnements de production \u00e0 jour de mani\u00e8re automatis\u00e9e et fiable.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/06_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/","title":"Mise \u00e0 Jour Automatique avec les Triggers Kubernetes","text":"<p>Dans cette section, nous allons explorer comment configurer et utiliser les triggers Kubernetes pour effectuer des mises \u00e0 jour automatiques des applications d\u00e9ploy\u00e9es. Les triggers permettent d'automatiser des actions sp\u00e9cifiques en r\u00e9ponse \u00e0 des \u00e9v\u00e9nements tels que des changements d'images de conteneur ou des modifications de configuration.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/06_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#objectifs","title":"Objectifs","text":"<ul> <li>Comprendre les diff\u00e9rents types de triggers dans Kubernetes.</li> <li>Configurer des triggers pour les d\u00e9ploiements.</li> <li>Automatiser les mises \u00e0 jour des applications en r\u00e9ponse \u00e0 des \u00e9v\u00e9nements sp\u00e9cifiques.</li> </ul>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/06_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#types-de-triggers-dans-kubernetes","title":"Types de Triggers dans Kubernetes","text":"<p>Kubernetes propose plusieurs types de triggers pour automatiser les mises \u00e0 jour :</p> <ol> <li>ImageChangeTrigger : D\u00e9clenche une mise \u00e0 jour lorsque l'image d'un conteneur est mise \u00e0 jour.</li> <li>ConfigChangeTrigger : D\u00e9clenche une mise \u00e0 jour lorsque la configuration d'une application change.</li> </ol>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/06_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#etapes-de-configuration-des-triggers","title":"\u00c9tapes de Configuration des Triggers","text":""},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/06_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#1-creer-un-projet","title":"1. Cr\u00e9er un Projet","text":"<p>Cr\u00e9ez un nouveau projet pour cet exercice :</p> <pre><code>oc new-project demo-triggers\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/06_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#2-creer-un-deploiement-avec-un-imagechangetrigger","title":"2. Cr\u00e9er un D\u00e9ploiement avec un ImageChangeTrigger","text":"<p>Cr\u00e9ez un fichier YAML pour le d\u00e9ploiement nomm\u00e9 <code>deployment-with-trigger.yaml</code> :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app-deployment\n  namespace: demo-triggers\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-app-container\n        image: image-registry.openshift-image-registry.svc:5000/demo-triggers/my-app:latest\n        ports:\n        - containerPort: 8080\n  triggers:\n  - type: ImageChange\n    imageChangeParams:\n      automatic: true\n      containerNames:\n      - my-app-container\n      from:\n        kind: ImageStreamTag\n        name: my-app:latest\n</code></pre> <p>Appliquez ce fichier pour cr\u00e9er le d\u00e9ploiement :</p> <pre><code>oc apply -f deployment-with-trigger.yaml\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/06_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#3-creer-un-imagestream","title":"3. Cr\u00e9er un ImageStream","text":"<p>Cr\u00e9ez un fichier YAML pour l'ImageStream nomm\u00e9 <code>imagestream.yaml</code> :</p> <pre><code>apiVersion: image.openshift.io/v1\nkind: ImageStream\nmetadata:\n  name: my-app\n  namespace: demo-triggers\n</code></pre> <p>Appliquez ce fichier pour cr\u00e9er l'ImageStream :</p> <pre><code>oc apply -f imagestream.yaml\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/06_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#4-pousser-une-image-initiale","title":"4. Pousser une Image Initiale","text":"<p>Construisez et poussez une image initiale vers votre registre d'images Docker :</p> <pre><code>docker build -t my-registry.example.com/demo-triggers/my-app:v1.0 .\ndocker push my-registry.example.com/demo-triggers/my-app:v1.0\n</code></pre> <p>Mettez \u00e0 jour l'ImageStreamTag <code>latest</code> pour pointer vers cette image :</p> <pre><code>oc tag demo-triggers/my-app:v1.0 demo-triggers/my-app:latest\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/06_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#5-verifier-le-deploiement","title":"5. V\u00e9rifier le D\u00e9ploiement","text":"<p>V\u00e9rifiez que le d\u00e9ploiement a \u00e9t\u00e9 d\u00e9clench\u00e9 automatiquement :</p> <pre><code>oc get deployments\noc get pods\n</code></pre> <p>Obtenez les journaux des pods pour vous assurer qu'ils fonctionnent correctement :</p> <pre><code>oc logs &lt;pod-name&gt;\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/06_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#6-mettre-a-jour-limage","title":"6. Mettre \u00e0 Jour l'Image","text":"<p>Construisez et poussez une nouvelle version de l'image :</p> <pre><code>docker build -t my-registry.example.com/demo-triggers/my-app:v2.0 .\ndocker push my-registry.example.com/demo-triggers/my-app:v2.0\n</code></pre> <p>Mettez \u00e0 jour l'ImageStreamTag <code>latest</code> pour pointer vers la nouvelle image :</p> <pre><code>oc tag demo-triggers/my-app:v2.0 demo-triggers/my-app:latest\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/06_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#7-observer-le-deploiement-automatique","title":"7. Observer le D\u00e9ploiement Automatique","text":"<p>V\u00e9rifiez que le d\u00e9ploiement automatique a \u00e9t\u00e9 d\u00e9clench\u00e9 suite \u00e0 la mise \u00e0 jour de l'ImageStream :</p> <pre><code>oc get deployments\noc get pods\n</code></pre> <p>Obtenez les journaux des nouveaux pods pour vous assurer qu'ils fonctionnent correctement :</p> <pre><code>oc logs &lt;new-pod-name&gt;\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/06_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#8-configurer-un-configchangetrigger","title":"8. Configurer un ConfigChangeTrigger","text":"<p>Modifiez le fichier de d\u00e9ploiement pour ajouter un trigger de changement de configuration :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app-deployment\n  namespace: demo-triggers\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-app-container\n        image: image-registry.openshift-image-registry.svc:5000/demo-triggers/my-app:latest\n        ports:\n        - containerPort: 8080\n  triggers:\n  - type: ImageChange\n    imageChangeParams:\n      automatic: true\n      containerNames:\n      - my-app-container\n      from:\n        kind: ImageStreamTag\n        name: my-app:latest\n  - type: ConfigChange\n</code></pre> <p>Appliquez ce fichier pour mettre \u00e0 jour le d\u00e9ploiement :</p> <pre><code>oc apply -f deployment-with-trigger.yaml\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/06_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#9-modifier-la-configuration","title":"9. Modifier la Configuration","text":"<p>Modifiez la configuration de l'application pour voir le d\u00e9clenchement du d\u00e9ploiement :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app-deployment\n  namespace: demo-triggers\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-app-container\n        image: image-registry.openshift-image-registry.svc:5000/demo-triggers/my-app:latest\n        ports:\n        - containerPort: 8080\n        env:\n        - name: NEW_ENV_VAR\n          value: \"new-value\"\n  triggers:\n  - type: ImageChange\n    imageChangeParams:\n      automatic: true\n      containerNames:\n      - my-app-container\n      from:\n        kind: ImageStreamTag\n        name: my-app:latest\n  - type: ConfigChange\n</code></pre> <p>Appliquez cette modification :</p> <pre><code>oc apply -f deployment-with-trigger.yaml\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/06_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#10-observer-la-mise-a-jour","title":"10. Observer la Mise \u00e0 Jour","text":"<p>V\u00e9rifiez que le d\u00e9ploiement a \u00e9t\u00e9 d\u00e9clench\u00e9 suite \u00e0 la modification de configuration :</p> <pre><code>oc get deployments\noc get pods\n</code></pre> <p>Obtenez les journaux des nouveaux pods pour vous assurer qu'ils fonctionnent correctement :</p> <pre><code>oc logs &lt;new-pod-name&gt;\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/06_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#11-nettoyage","title":"11. Nettoyage","text":"<p>Pour nettoyer les ressources cr\u00e9\u00e9es durant cet exercice :</p> <pre><code>oc delete project demo-triggers\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/06_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#conclusion","title":"Conclusion","text":"<p>Dans cette section, vous avez appris \u00e0 configurer des triggers dans Kubernetes pour automatiser les mises \u00e0 jour de d\u00e9ploiement. Les triggers permettent de maintenir vos applications \u00e0 jour de mani\u00e8re automatique, en r\u00e9ponse \u00e0 des \u00e9v\u00e9nements tels que des changements d'images ou des modifications de configuration. Cette fonctionnalit\u00e9 est essentielle pour des environnements de production dynamiques o\u00f9 la rapidit\u00e9 et l'efficacit\u00e9 des mises \u00e0 jour sont cruciales.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/07_Exercice_guid%C3%A9_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/","title":"Exercice Guid\u00e9 : Mise \u00e0 Jour Automatique avec les Triggers Kubernetes","text":"<p>Dans cet exercice guid\u00e9, nous allons mettre en pratique les concepts appris dans la section pr\u00e9c\u00e9dente en configurant des triggers pour automatiser les mises \u00e0 jour de notre application d\u00e9ploy\u00e9e sur Kubernetes.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/07_Exercice_guid%C3%A9_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#objectifs-de-lexercice","title":"Objectifs de l'Exercice","text":"<ul> <li>Configurer des <code>ImageChangeTrigger</code> et <code>ConfigChangeTrigger</code> pour un d\u00e9ploiement.</li> <li>D\u00e9clencher automatiquement des mises \u00e0 jour en r\u00e9ponse \u00e0 des changements d'images de conteneur et de configurations.</li> <li>Valider les mises \u00e0 jour automatiques en v\u00e9rifiant l'\u00e9tat du d\u00e9ploiement et des pods.</li> </ul>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/07_Exercice_guid%C3%A9_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#pre-requis","title":"Pr\u00e9-requis","text":"<ul> <li>Un cluster OpenShift/Kubernetes fonctionnel.</li> <li><code>oc</code> CLI configur\u00e9 pour acc\u00e9der \u00e0 votre cluster.</li> <li>Docker install\u00e9 et configur\u00e9 pour pousser des images vers votre registre.</li> </ul>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/07_Exercice_guid%C3%A9_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#etapes-de-lexercice","title":"\u00c9tapes de l'Exercice","text":""},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/07_Exercice_guid%C3%A9_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#1-creer-un-projet","title":"1. Cr\u00e9er un Projet","text":"<p>Cr\u00e9ez un nouveau projet pour cet exercice :</p> <pre><code>oc new-project demo-triggers-exercise\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/07_Exercice_guid%C3%A9_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#2-creer-un-deploiement-avec-un-imagechangetrigger","title":"2. Cr\u00e9er un D\u00e9ploiement avec un ImageChangeTrigger","text":"<p>Cr\u00e9ez un fichier YAML pour le d\u00e9ploiement nomm\u00e9 <code>deployment-with-trigger.yaml</code> :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app-deployment\n  namespace: demo-triggers-exercise\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-app-container\n        image: image-registry.openshift-image-registry.svc:5000/demo-triggers-exercise/my-app:latest\n        ports:\n        - containerPort: 8080\n  triggers:\n  - type: ImageChange\n    imageChangeParams:\n      automatic: true\n      containerNames:\n      - my-app-container\n      from:\n        kind: ImageStreamTag\n        name: my-app:latest\n</code></pre> <p>Appliquez ce fichier pour cr\u00e9er le d\u00e9ploiement :</p> <pre><code>oc apply -f deployment-with-trigger.yaml\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/07_Exercice_guid%C3%A9_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#3-creer-un-imagestream","title":"3. Cr\u00e9er un ImageStream","text":"<p>Cr\u00e9ez un fichier YAML pour l'ImageStream nomm\u00e9 <code>imagestream.yaml</code> :</p> <pre><code>apiVersion: image.openshift.io/v1\nkind: ImageStream\nmetadata:\n  name: my-app\n  namespace: demo-triggers-exercise\n</code></pre> <p>Appliquez ce fichier pour cr\u00e9er l'ImageStream :</p> <pre><code>oc apply -f imagestream.yaml\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/07_Exercice_guid%C3%A9_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#4-pousser-une-image-initiale","title":"4. Pousser une Image Initiale","text":"<p>Construisez et poussez une image initiale vers votre registre d'images Docker :</p> <pre><code>docker build -t my-registry.example.com/demo-triggers-exercise/my-app:v1.0 .\ndocker push my-registry.example.com/demo-triggers-exercise/my-app:v1.0\n</code></pre> <p>Mettez \u00e0 jour l'ImageStreamTag <code>latest</code> pour pointer vers cette image :</p> <pre><code>oc tag demo-triggers-exercise/my-app:v1.0 demo-triggers-exercise/my-app:latest\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/07_Exercice_guid%C3%A9_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#5-verifier-le-deploiement","title":"5. V\u00e9rifier le D\u00e9ploiement","text":"<p>V\u00e9rifiez que le d\u00e9ploiement a \u00e9t\u00e9 d\u00e9clench\u00e9 automatiquement :</p> <pre><code>oc get deployments\noc get pods\n</code></pre> <p>Obtenez les journaux des pods pour vous assurer qu'ils fonctionnent correctement :</p> <pre><code>oc logs &lt;pod-name&gt;\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/07_Exercice_guid%C3%A9_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#6-mettre-a-jour-limage","title":"6. Mettre \u00e0 Jour l'Image","text":"<p>Construisez et poussez une nouvelle version de l'image :</p> <pre><code>docker build -t my-registry.example.com/demo-triggers-exercise/my-app:v2.0 .\ndocker push my-registry.example.com/demo-triggers-exercise/my-app:v2.0\n</code></pre> <p>Mettez \u00e0 jour l'ImageStreamTag <code>latest</code> pour pointer vers la nouvelle image :</p> <pre><code>oc tag demo-triggers-exercise/my-app:v2.0 demo-triggers-exercise/my-app:latest\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/07_Exercice_guid%C3%A9_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#7-observer-le-deploiement-automatique","title":"7. Observer le D\u00e9ploiement Automatique","text":"<p>V\u00e9rifiez que le d\u00e9ploiement automatique a \u00e9t\u00e9 d\u00e9clench\u00e9 suite \u00e0 la mise \u00e0 jour de l'ImageStream :</p> <pre><code>oc get deployments\noc get pods\n</code></pre> <p>Obtenez les journaux des nouveaux pods pour vous assurer qu'ils fonctionnent correctement :</p> <pre><code>oc logs &lt;new-pod-name&gt;\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/07_Exercice_guid%C3%A9_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#8-configurer-un-configchangetrigger","title":"8. Configurer un ConfigChangeTrigger","text":"<p>Modifiez le fichier de d\u00e9ploiement pour ajouter un trigger de changement de configuration :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app-deployment\n  namespace: demo-triggers-exercise\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-app-container\n        image: image-registry.openshift-image-registry.svc:5000/demo-triggers-exercise/my-app:latest\n        ports:\n        - containerPort: 8080\n  triggers:\n  - type: ImageChange\n    imageChangeParams:\n      automatic: true\n      containerNames:\n      - my-app-container\n      from:\n        kind: ImageStreamTag\n        name: my-app:latest\n  - type: ConfigChange\n</code></pre> <p>Appliquez ce fichier pour mettre \u00e0 jour le d\u00e9ploiement :</p> <pre><code>oc apply -f deployment-with-trigger.yaml\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/07_Exercice_guid%C3%A9_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#9-modifier-la-configuration","title":"9. Modifier la Configuration","text":"<p>Modifiez la configuration de l'application pour voir le d\u00e9clenchement du d\u00e9ploiement :</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app-deployment\n  namespace: demo-triggers-exercise\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: my-app\n  template:\n    metadata:\n      labels:\n        app: my-app\n    spec:\n      containers:\n      - name: my-app-container\n        image: image-registry.openshift-image-registry.svc:5000/demo-triggers-exercise/my-app:latest\n        ports:\n        - containerPort: 8080\n        env:\n        - name: NEW_ENV_VAR\n          value: \"new-value\"\n  triggers:\n  - type: ImageChange\n    imageChangeParams:\n      automatic: true\n      containerNames:\n      - my-app-container\n      from:\n        kind: ImageStreamTag\n        name: my-app:latest\n  - type: ConfigChange\n</code></pre> <p>Appliquez cette modification :</p> <pre><code>oc apply -f deployment-with-trigger.yaml\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/07_Exercice_guid%C3%A9_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#10-observer-la-mise-a-jour","title":"10. Observer la Mise \u00e0 Jour","text":"<p>V\u00e9rifiez que le d\u00e9ploiement a \u00e9t\u00e9 d\u00e9clench\u00e9 suite \u00e0 la modification de configuration :</p> <pre><code>oc get deployments\noc get pods\n</code></pre> <p>Obtenez les journaux des nouveaux pods pour vous assurer qu'ils fonctionnent correctement :</p> <pre><code>oc logs &lt;new-pod-name&gt;\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/07_Exercice_guid%C3%A9_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#11-nettoyage","title":"11. Nettoyage","text":"<p>Pour nettoyer les ressources cr\u00e9\u00e9es durant cet exercice :</p> <pre><code>oc delete project demo-triggers-exercise\n</code></pre>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/07_Exercice_guid%C3%A9_Mise_a_jour_automatique_avec_les_trigger_Kubernetes/#conclusion","title":"Conclusion","text":"<p>Dans cet exercice, vous avez configur\u00e9 et test\u00e9 des triggers Kubernetes pour automatiser les mises \u00e0 jour des d\u00e9ploiements. Vous avez appris \u00e0 utiliser les <code>ImageChangeTrigger</code> et <code>ConfigChangeTrigger</code> pour d\u00e9clencher des d\u00e9ploiements en r\u00e9ponse \u00e0 des \u00e9v\u00e9nements sp\u00e9cifiques, tels que des changements d'images de conteneur et des modifications de configuration. Cette automatisation est essentielle pour maintenir les applications \u00e0 jour de mani\u00e8re efficace et rapide dans des environnements de production dynamiques.</p>"},{"location":"07_Gestion_des_mises_%C3%A0_jour_des_applications/08_R%C3%A9sum%C3%A9/","title":"R\u00e9sum\u00e9","text":"<p>Dans cette partie, le formateur fera une synth\u00e8se de tout ce qui a \u00e9t\u00e9 vu dans les parties pr\u00e9c\u00e9dentes. Ce sera l'occasion de revoir les points cl\u00e9s, de clarifier les concepts abord\u00e9s et de s'assurer que tous les participants ont bien assimil\u00e9 le contenu.</p> <p>C'est \u00e9galement le moment id\u00e9al pour poser toutes les questions que vous pourriez avoir. Rappelez-vous que m\u00eame les questions qui peuvent sembler simples ou \u00e9videntes sont importantes. Alors, ne soyez pas timide : comme on dit, il n'y a pas de questions b\u00eates, seulement des r\u00e9ponses... parfois un peu longues !</p> <p></p>"}]}